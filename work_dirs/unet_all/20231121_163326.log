2023-11-21 16:33:26,130 - mmseg - INFO - Multi-processing start method is `None`
2023-11-21 16:33:26,238 - mmseg - INFO - OpenCV num_threads is `6
2023-11-21 16:33:26,322 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /environment/miniconda3
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.1
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.1+
------------------------------------------------------------

2023-11-21 16:33:26,322 - mmseg - INFO - Distributed training: False
2023-11-21 16:33:26,536 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='UnetBackbone',
        in_channels=3,
        context_layer='seLayer',
        channel_list=[64, 128, 256, 512]),
    decode_head=dict(
        type='UnetHead',
        num_classes=4,
        channels=64,
        resPath=True,
        attention=True,
        threshold=0.2,
        norm_cfg=dict(type='BN', requires_grad=True),
        loss_decode=[
            dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                class_weight=[0.1, 0.4, 0.3, 0.2],
                loss_weight=2.0),
            dict(
                type='DiceLoss',
                loss_name='loss_dice',
                class_weight=[0.1, 0.4, 0.3, 0.2],
                loss_weight=2.0)
        ]))
train_cfg = dict()
test_cfg = dict(mode='whole')
dataset_type = 'MyDataset'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(600, 600)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=False),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data_root = './datasets/'
data = dict(
    samples_per_gpu=10,
    workers_per_gpu=2,
    train=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='train/images',
        ann_dir='train/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(600, 600)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TensorboardLoggerHook'),
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = False
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.999))
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=1e-05, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=5000)
checkpoint_config = dict(by_epoch=False, save_optimizer=False, interval=5000)
evaluation = dict(interval=500, metric=['mIoU', 'mFscore', 'mDice'])
work_dir = './work_dirs/unet_all'
gpu_ids = [0]
auto_resume = False

2023-11-21 16:33:26,537 - mmseg - INFO - Set random seed to 1317216340, deterministic: False
2023-11-21 16:33:26,656 - mmseg - INFO - initialize UnetHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.inc.conv.conv.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.weight - torch.Size([16, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.weight - torch.Size([64, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.weight - torch.Size([32, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.weight - torch.Size([128, 32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.weight - torch.Size([512, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([4, 64, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.up1.ca.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.conv_h.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.conv_h.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.conv_w.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.ca.conv_w.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.weight - torch.Size([256, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv_h.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv_h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv_w.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.ca.conv_w.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.weight - torch.Size([128, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv_h.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv_h.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv_w.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.ca.conv_w.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv1.weight - torch.Size([32, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv_h.weight - torch.Size([128, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv_h.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv_w.weight - torch.Size([128, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.ca.conv_w.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-11-21 16:33:26,662 - mmseg - INFO - EncoderDecoder(
  (backbone): UnetBackbone(
    (inc): InConv(
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down3): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down4): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (context_layer1_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=64, out_features=16, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=16, out_features=64, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer2_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer3_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=64, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=64, out_features=256, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer4_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=512, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=512, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
  )
  (decode_head): UnetHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): FocalLoss()
      (1): DiceLoss()
    )
    (conv_seg): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (up1): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (ca): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (ca): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up3): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (ca): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up4): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (ca): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-21 16:33:26,671 - mmseg - INFO - Loaded 331 images
2023-11-21 16:33:33,074 - mmseg - INFO - Loaded 83 images
2023-11-21 16:33:33,074 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/work/test/work_dirs/unet_all
2023-11-21 16:33:33,075 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-21 16:33:33,075 - mmseg - INFO - workflow: [('train', 1)], max: 5000 iters
2023-11-21 16:33:33,075 - mmseg - INFO - Checkpoints will be saved to /home/featurize/work/test/work_dirs/unet_all by HardDiskBackend.
2023-11-21 16:34:08,197 - mmseg - INFO - Iter [50/5000]	lr: 9.921e-05, eta: 0:57:12, time: 0.693, data_time: 0.094, memory: 17708, decode.loss_focal: 0.0518, decode.loss_dice: 0.4701, decode.acc_seg: 86.9990, loss: 0.5220
2023-11-21 16:34:44,795 - mmseg - INFO - Iter [100/5000]	lr: 9.839e-05, eta: 0:58:12, time: 0.732, data_time: 0.135, memory: 17708, decode.loss_focal: 0.0395, decode.loss_dice: 0.4647, decode.acc_seg: 99.3216, loss: 0.5041
2023-11-21 16:35:18,446 - mmseg - INFO - Iter [150/5000]	lr: 9.758e-05, eta: 0:56:32, time: 0.673, data_time: 0.076, memory: 17708, decode.loss_focal: 0.0298, decode.loss_dice: 0.4588, decode.acc_seg: 99.4119, loss: 0.4886
2023-11-21 16:35:55,080 - mmseg - INFO - Iter [200/5000]	lr: 9.677e-05, eta: 0:56:37, time: 0.733, data_time: 0.137, memory: 17708, decode.loss_focal: 0.0227, decode.loss_dice: 0.4532, decode.acc_seg: 99.4221, loss: 0.4758
2023-11-21 16:36:28,551 - mmseg - INFO - Iter [250/5000]	lr: 9.596e-05, eta: 0:55:25, time: 0.669, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0177, decode.loss_dice: 0.4457, decode.acc_seg: 99.2540, loss: 0.4634
2023-11-21 16:37:05,702 - mmseg - INFO - Iter [300/5000]	lr: 9.514e-05, eta: 0:55:24, time: 0.743, data_time: 0.156, memory: 17708, decode.loss_focal: 0.0139, decode.loss_dice: 0.4382, decode.acc_seg: 99.2235, loss: 0.4521
2023-11-21 16:37:39,202 - mmseg - INFO - Iter [350/5000]	lr: 9.433e-05, eta: 0:54:23, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0111, decode.loss_dice: 0.4277, decode.acc_seg: 99.3909, loss: 0.4388
2023-11-21 16:38:16,123 - mmseg - INFO - Iter [400/5000]	lr: 9.351e-05, eta: 0:54:09, time: 0.738, data_time: 0.144, memory: 17708, decode.loss_focal: 0.0099, decode.loss_dice: 0.4149, decode.acc_seg: 99.4209, loss: 0.4248
2023-11-21 16:38:49,743 - mmseg - INFO - Iter [450/5000]	lr: 9.269e-05, eta: 0:53:17, time: 0.672, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0085, decode.loss_dice: 0.4015, decode.acc_seg: 99.4405, loss: 0.4100
2023-11-21 16:39:26,965 - mmseg - INFO - Iter [500/5000]	lr: 9.187e-05, eta: 0:53:00, time: 0.744, data_time: 0.155, memory: 17708, decode.loss_focal: 0.0070, decode.loss_dice: 0.3940, decode.acc_seg: 99.4242, loss: 0.4010
2023-11-21 16:39:46,004 - mmseg - INFO - per class results:
2023-11-21 16:39:46,006 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.87 |  70.5 | 72.83 | 70.43 | 99.75 |  99.9  |   99.97   | 99.83  | 99.85 |
|  scratch   |  78.1 | 92.27 | 74.83 | 80.43 | 72.21 | 73.95  |   69.81   | 81.48  | 60.93 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 79.65 | 90.72 | 74.82 | 80.38 | 93.63 | 76.76  |   69.96   | 95.75  | 65.14 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 16:39:46,007 - mmseg - INFO - Summary:
2023-11-21 16:39:46,007 - mmseg - INFO - 
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc | mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.86 | 82.0 | 88.37 | 74.16 | 77.08 | 74.73 |  83.54  |   79.91    |  83.15  | 64.81 |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 16:39:46,022 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9986, mIoU: 0.8200, mVOE: 0.8837, mASD: 0.7416, mMSSD: 0.7708, mAcc: 0.7473, mFscore: 0.8354, mPrecision: 0.7991, mRecall: 0.8315, mDice: 0.6481, IoU.background: 0.9987, IoU.scratch: 0.7810, IoU.stain: 0.7037, IoU.edgeDamage: 0.7965, VOE.background: 0.7050, VOE.scratch: 0.9227, VOE.stain: 1.0000, VOE.edgeDamage: 0.9072, ASD.background: 0.7283, ASD.scratch: 0.7483, ASD.stain: nan, ASD.edgeDamage: 0.7482, MSSD.background: 0.7043, MSSD.scratch: 0.8043, MSSD.stain: nan, MSSD.edgeDamage: 0.8038, Acc.background: 0.9975, Acc.scratch: 0.7221, Acc.stain: 0.3333, Acc.edgeDamage: 0.9363, Fscore.background: 0.9990, Fscore.scratch: 0.7395, Fscore.stain: nan, Fscore.edgeDamage: 0.7676, Precision.background: 0.9997, Precision.scratch: 0.6981, Precision.stain: nan, Precision.edgeDamage: 0.6996, Recall.background: 0.9983, Recall.scratch: 0.8148, Recall.stain: 0.5556, Recall.edgeDamage: 0.9575, Dice.background: 0.9985, Dice.scratch: 0.6093, Dice.stain: 0.3333, Dice.edgeDamage: 0.6514
2023-11-21 16:40:20,153 - mmseg - INFO - Iter [550/5000]	lr: 9.106e-05, eta: 0:54:49, time: 1.064, data_time: 0.467, memory: 17708, decode.loss_focal: 0.0060, decode.loss_dice: 0.3783, decode.acc_seg: 99.4571, loss: 0.3843
2023-11-21 16:40:56,721 - mmseg - INFO - Iter [600/5000]	lr: 9.024e-05, eta: 0:54:10, time: 0.731, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0050, decode.loss_dice: 0.3727, decode.acc_seg: 99.4835, loss: 0.3777
2023-11-21 16:41:30,403 - mmseg - INFO - Iter [650/5000]	lr: 8.941e-05, eta: 0:53:11, time: 0.674, data_time: 0.073, memory: 17708, decode.loss_focal: 0.0042, decode.loss_dice: 0.3669, decode.acc_seg: 99.5852, loss: 0.3712
2023-11-21 16:42:07,088 - mmseg - INFO - Iter [700/5000]	lr: 8.859e-05, eta: 0:52:34, time: 0.734, data_time: 0.134, memory: 17708, decode.loss_focal: 0.0038, decode.loss_dice: 0.3511, decode.acc_seg: 99.6114, loss: 0.3549
2023-11-21 16:42:40,762 - mmseg - INFO - Iter [750/5000]	lr: 8.777e-05, eta: 0:51:40, time: 0.673, data_time: 0.077, memory: 17708, decode.loss_focal: 0.0032, decode.loss_dice: 0.3523, decode.acc_seg: 99.6046, loss: 0.3555
2023-11-21 16:43:17,356 - mmseg - INFO - Iter [800/5000]	lr: 8.695e-05, eta: 0:51:05, time: 0.732, data_time: 0.132, memory: 17708, decode.loss_focal: 0.0031, decode.loss_dice: 0.3478, decode.acc_seg: 99.6137, loss: 0.3509
2023-11-21 16:43:50,966 - mmseg - INFO - Iter [850/5000]	lr: 8.612e-05, eta: 0:50:14, time: 0.672, data_time: 0.074, memory: 17708, decode.loss_focal: 0.0036, decode.loss_dice: 0.3412, decode.acc_seg: 99.6238, loss: 0.3448
2023-11-21 16:44:28,185 - mmseg - INFO - Iter [900/5000]	lr: 8.530e-05, eta: 0:49:42, time: 0.744, data_time: 0.153, memory: 17708, decode.loss_focal: 0.0036, decode.loss_dice: 0.3368, decode.acc_seg: 99.6315, loss: 0.3404
2023-11-21 16:45:01,799 - mmseg - INFO - Iter [950/5000]	lr: 8.447e-05, eta: 0:48:54, time: 0.672, data_time: 0.077, memory: 17708, decode.loss_focal: 0.0030, decode.loss_dice: 0.3342, decode.acc_seg: 99.6213, loss: 0.3371
2023-11-21 16:45:38,597 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 16:45:38,597 - mmseg - INFO - Iter [1000/5000]	lr: 8.364e-05, eta: 0:48:20, time: 0.736, data_time: 0.137, memory: 17708, decode.loss_focal: 0.0026, decode.loss_dice: 0.3264, decode.acc_seg: 99.6626, loss: 0.3290
2023-11-21 16:45:57,374 - mmseg - INFO - per class results:
2023-11-21 16:45:57,375 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 72.83 | 70.42 | 99.78 | 99.91  |   99.97   | 99.85  | 99.87 |
|  scratch   | 80.69 | 89.69 | 74.53 | 78.91 | 77.45 | 78.51  |   74.38   | 84.97  | 67.76 |
|   stain    | 74.01 | 96.36 |  75.4 | 83.28 | 82.35 | 65.29  |   61.28   | 88.23  | 47.94 |
| edgeDamage | 82.67 |  87.7 | 74.45 | 78.51 | 89.42 | 81.63  |   75.57   | 92.95  | 72.44 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 16:45:57,375 - mmseg - INFO - Summary:
2023-11-21 16:45:57,375 - mmseg - INFO - 
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE | mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
| 99.88 | 84.31 | 86.06 | 74.3 | 77.78 | 87.25 |  81.33  |    77.8    |   91.5  |  72.0 |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
2023-11-21 16:45:57,441 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 16:45:57,441 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9988, mIoU: 0.8431, mVOE: 0.8606, mASD: 0.7430, mMSSD: 0.7778, mAcc: 0.8725, mFscore: 0.8133, mPrecision: 0.7780, mRecall: 0.9150, mDice: 0.7200, IoU.background: 0.9988, IoU.scratch: 0.8069, IoU.stain: 0.7401, IoU.edgeDamage: 0.8267, VOE.background: 0.7049, VOE.scratch: 0.8969, VOE.stain: 0.9636, VOE.edgeDamage: 0.8770, ASD.background: 0.7283, ASD.scratch: 0.7453, ASD.stain: 0.7540, ASD.edgeDamage: 0.7445, MSSD.background: 0.7042, MSSD.scratch: 0.7891, MSSD.stain: 0.8328, MSSD.edgeDamage: 0.7851, Acc.background: 0.9978, Acc.scratch: 0.7745, Acc.stain: 0.8235, Acc.edgeDamage: 0.8942, Fscore.background: 0.9991, Fscore.scratch: 0.7851, Fscore.stain: 0.6529, Fscore.edgeDamage: 0.8163, Precision.background: 0.9997, Precision.scratch: 0.7438, Precision.stain: 0.6128, Precision.edgeDamage: 0.7557, Recall.background: 0.9985, Recall.scratch: 0.8497, Recall.stain: 0.8823, Recall.edgeDamage: 0.9295, Dice.background: 0.9987, Dice.scratch: 0.6776, Dice.stain: 0.4794, Dice.edgeDamage: 0.7244
2023-11-21 16:46:30,895 - mmseg - INFO - Iter [1050/5000]	lr: 8.281e-05, eta: 0:48:44, time: 1.046, data_time: 0.447, memory: 17708, decode.loss_focal: 0.0024, decode.loss_dice: 0.3307, decode.acc_seg: 99.6335, loss: 0.3331
2023-11-21 16:47:07,817 - mmseg - INFO - Iter [1100/5000]	lr: 8.198e-05, eta: 0:48:06, time: 0.738, data_time: 0.144, memory: 17708, decode.loss_focal: 0.0021, decode.loss_dice: 0.3169, decode.acc_seg: 99.7031, loss: 0.3190
2023-11-21 16:47:41,577 - mmseg - INFO - Iter [1150/5000]	lr: 8.115e-05, eta: 0:47:19, time: 0.675, data_time: 0.082, memory: 17708, decode.loss_focal: 0.0021, decode.loss_dice: 0.3214, decode.acc_seg: 99.7023, loss: 0.3235
2023-11-21 16:48:18,238 - mmseg - INFO - Iter [1200/5000]	lr: 8.032e-05, eta: 0:46:41, time: 0.733, data_time: 0.139, memory: 17708, decode.loss_focal: 0.0024, decode.loss_dice: 0.3176, decode.acc_seg: 99.6646, loss: 0.3200
2023-11-21 16:48:51,772 - mmseg - INFO - Iter [1250/5000]	lr: 7.949e-05, eta: 0:45:54, time: 0.671, data_time: 0.074, memory: 17708, decode.loss_focal: 0.0017, decode.loss_dice: 0.2932, decode.acc_seg: 99.7245, loss: 0.2949
2023-11-21 16:49:28,617 - mmseg - INFO - Iter [1300/5000]	lr: 7.865e-05, eta: 0:45:18, time: 0.737, data_time: 0.142, memory: 17708, decode.loss_focal: 0.0013, decode.loss_dice: 0.2299, decode.acc_seg: 99.7373, loss: 0.2311
2023-11-21 16:50:02,126 - mmseg - INFO - Iter [1350/5000]	lr: 7.782e-05, eta: 0:44:32, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0012, decode.loss_dice: 0.2235, decode.acc_seg: 99.6965, loss: 0.2246
2023-11-21 16:50:38,737 - mmseg - INFO - Iter [1400/5000]	lr: 7.698e-05, eta: 0:43:56, time: 0.732, data_time: 0.134, memory: 17708, decode.loss_focal: 0.0009, decode.loss_dice: 0.1823, decode.acc_seg: 99.7644, loss: 0.1832
2023-11-21 16:51:12,252 - mmseg - INFO - Iter [1450/5000]	lr: 7.614e-05, eta: 0:43:12, time: 0.670, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0009, decode.loss_dice: 0.1713, decode.acc_seg: 99.7731, loss: 0.1722
2023-11-21 16:51:48,997 - mmseg - INFO - Iter [1500/5000]	lr: 7.530e-05, eta: 0:42:36, time: 0.735, data_time: 0.137, memory: 17708, decode.loss_focal: 0.0009, decode.loss_dice: 0.1627, decode.acc_seg: 99.7710, loss: 0.1636
2023-11-21 16:52:07,899 - mmseg - INFO - per class results:
2023-11-21 16:52:07,901 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.92 | 70.45 | 72.83 |  70.4 | 99.88 | 99.94  |   99.97   | 99.92  | 99.91 |
|  scratch   | 83.91 | 86.46 | 74.12 | 76.87 | 70.73 | 83.43  |   87.16   | 80.49  | 75.14 |
|   stain    | 82.83 | 87.54 | 74.04 | 76.46 | 72.58 | 81.87  |   82.01   | 81.72  |  72.8 |
| edgeDamage | 82.49 | 87.88 | 74.49 |  78.7 | 90.73 | 81.36  |   75.02   | 93.82  | 72.04 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 16:52:07,901 - mmseg - INFO - Summary:
2023-11-21 16:52:07,901 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.92 | 87.29 | 83.08 | 73.87 | 75.61 | 83.48 |  86.65  |   86.04    |  88.99  | 79.97 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 16:52:07,916 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9992, mIoU: 0.8729, mVOE: 0.8308, mASD: 0.7387, mMSSD: 0.7561, mAcc: 0.8348, mFscore: 0.8665, mPrecision: 0.8604, mRecall: 0.8899, mDice: 0.7997, IoU.background: 0.9992, IoU.scratch: 0.8391, IoU.stain: 0.8283, IoU.edgeDamage: 0.8249, VOE.background: 0.7045, VOE.scratch: 0.8646, VOE.stain: 0.8754, VOE.edgeDamage: 0.8788, ASD.background: 0.7283, ASD.scratch: 0.7412, ASD.stain: 0.7404, ASD.edgeDamage: 0.7449, MSSD.background: 0.7040, MSSD.scratch: 0.7687, MSSD.stain: 0.7646, MSSD.edgeDamage: 0.7870, Acc.background: 0.9988, Acc.scratch: 0.7073, Acc.stain: 0.7258, Acc.edgeDamage: 0.9073, Fscore.background: 0.9994, Fscore.scratch: 0.8343, Fscore.stain: 0.8187, Fscore.edgeDamage: 0.8136, Precision.background: 0.9997, Precision.scratch: 0.8716, Precision.stain: 0.8201, Precision.edgeDamage: 0.7502, Recall.background: 0.9992, Recall.scratch: 0.8049, Recall.stain: 0.8172, Recall.edgeDamage: 0.9382, Dice.background: 0.9991, Dice.scratch: 0.7514, Dice.stain: 0.7280, Dice.edgeDamage: 0.7204
2023-11-21 16:52:41,391 - mmseg - INFO - Iter [1550/5000]	lr: 7.446e-05, eta: 0:42:34, time: 1.048, data_time: 0.450, memory: 17708, decode.loss_focal: 0.0009, decode.loss_dice: 0.1696, decode.acc_seg: 99.7565, loss: 0.1705
2023-11-21 16:53:22,138 - mmseg - INFO - Iter [1600/5000]	lr: 7.362e-05, eta: 0:42:05, time: 0.815, data_time: 0.224, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1547, decode.acc_seg: 99.7895, loss: 0.1555
2023-11-21 16:53:55,690 - mmseg - INFO - Iter [1650/5000]	lr: 7.278e-05, eta: 0:41:21, time: 0.671, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1520, decode.acc_seg: 99.7902, loss: 0.1529
2023-11-21 16:54:32,525 - mmseg - INFO - Iter [1700/5000]	lr: 7.194e-05, eta: 0:40:43, time: 0.737, data_time: 0.139, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1501, decode.acc_seg: 99.7913, loss: 0.1509
2023-11-21 16:55:09,184 - mmseg - INFO - Iter [1750/5000]	lr: 7.109e-05, eta: 0:40:06, time: 0.733, data_time: 0.134, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1479, decode.acc_seg: 99.7968, loss: 0.1487
2023-11-21 16:55:42,878 - mmseg - INFO - Iter [1800/5000]	lr: 7.025e-05, eta: 0:39:23, time: 0.674, data_time: 0.080, memory: 17708, decode.loss_focal: 0.0009, decode.loss_dice: 0.1555, decode.acc_seg: 99.7669, loss: 0.1563
2023-11-21 16:56:19,571 - mmseg - INFO - Iter [1850/5000]	lr: 6.940e-05, eta: 0:38:45, time: 0.734, data_time: 0.138, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1491, decode.acc_seg: 99.7903, loss: 0.1499
2023-11-21 16:56:53,201 - mmseg - INFO - Iter [1900/5000]	lr: 6.855e-05, eta: 0:38:03, time: 0.673, data_time: 0.073, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1493, decode.acc_seg: 99.7922, loss: 0.1501
2023-11-21 16:57:29,798 - mmseg - INFO - Iter [1950/5000]	lr: 6.770e-05, eta: 0:37:26, time: 0.732, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1520, decode.acc_seg: 99.7728, loss: 0.1528
2023-11-21 16:58:03,317 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 16:58:03,317 - mmseg - INFO - Iter [2000/5000]	lr: 6.685e-05, eta: 0:36:44, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1465, decode.acc_seg: 99.7866, loss: 0.1473
2023-11-21 16:58:21,207 - mmseg - INFO - per class results:
2023-11-21 16:58:21,209 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.92 | 70.45 | 72.83 |  70.4 | 99.86 | 99.94  |   99.97   | 99.91  | 99.91 |
|  scratch   | 85.68 | 84.69 | 73.92 | 75.87 | 75.26 | 85.83  |   88.59   |  83.5  | 78.75 |
|   stain    | 85.33 | 85.04 | 73.94 | 75.95 | 74.91 | 85.37  |   87.82   | 83.27  | 78.06 |
| edgeDamage | 82.14 | 88.23 | 74.55 | 79.04 | 93.51 | 80.83  |   74.01   | 95.68  | 71.25 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 16:58:21,209 - mmseg - INFO - Summary:
2023-11-21 16:58:21,210 - mmseg - INFO - 
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU | mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
| 99.92 | 88.27 | 82.1 | 73.81 | 75.31 | 85.89 |   88.0  |    87.6    |  90.59  | 81.99 |
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 16:58:21,227 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 16:58:21,227 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9992, mIoU: 0.8827, mVOE: 0.8210, mASD: 0.7381, mMSSD: 0.7531, mAcc: 0.8589, mFscore: 0.8800, mPrecision: 0.8760, mRecall: 0.9059, mDice: 0.8199, IoU.background: 0.9992, IoU.scratch: 0.8568, IoU.stain: 0.8533, IoU.edgeDamage: 0.8214, VOE.background: 0.7045, VOE.scratch: 0.8469, VOE.stain: 0.8504, VOE.edgeDamage: 0.8823, ASD.background: 0.7283, ASD.scratch: 0.7392, ASD.stain: 0.7394, ASD.edgeDamage: 0.7455, MSSD.background: 0.7040, MSSD.scratch: 0.7587, MSSD.stain: 0.7595, MSSD.edgeDamage: 0.7904, Acc.background: 0.9986, Acc.scratch: 0.7526, Acc.stain: 0.7491, Acc.edgeDamage: 0.9351, Fscore.background: 0.9994, Fscore.scratch: 0.8583, Fscore.stain: 0.8537, Fscore.edgeDamage: 0.8083, Precision.background: 0.9997, Precision.scratch: 0.8859, Precision.stain: 0.8782, Precision.edgeDamage: 0.7401, Recall.background: 0.9991, Recall.scratch: 0.8350, Recall.stain: 0.8327, Recall.edgeDamage: 0.9568, Dice.background: 0.9991, Dice.scratch: 0.7875, Dice.stain: 0.7806, Dice.edgeDamage: 0.7125
2023-11-21 16:58:58,288 - mmseg - INFO - Iter [2050/5000]	lr: 6.599e-05, eta: 0:36:34, time: 1.099, data_time: 0.507, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1462, decode.acc_seg: 99.7866, loss: 0.1470
2023-11-21 16:59:31,827 - mmseg - INFO - Iter [2100/5000]	lr: 6.514e-05, eta: 0:35:51, time: 0.671, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1425, decode.acc_seg: 99.7947, loss: 0.1433
2023-11-21 17:00:08,443 - mmseg - INFO - Iter [2150/5000]	lr: 6.428e-05, eta: 0:35:14, time: 0.732, data_time: 0.134, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1393, decode.acc_seg: 99.7921, loss: 0.1401
2023-11-21 17:00:42,055 - mmseg - INFO - Iter [2200/5000]	lr: 6.343e-05, eta: 0:34:32, time: 0.672, data_time: 0.072, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1464, decode.acc_seg: 99.7908, loss: 0.1472
2023-11-21 17:01:18,640 - mmseg - INFO - Iter [2250/5000]	lr: 6.257e-05, eta: 0:33:55, time: 0.732, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1400, decode.acc_seg: 99.7980, loss: 0.1407
2023-11-21 17:01:52,410 - mmseg - INFO - Iter [2300/5000]	lr: 6.171e-05, eta: 0:33:14, time: 0.675, data_time: 0.078, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1435, decode.acc_seg: 99.7873, loss: 0.1443
2023-11-21 17:02:29,182 - mmseg - INFO - Iter [2350/5000]	lr: 6.084e-05, eta: 0:32:37, time: 0.735, data_time: 0.137, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1379, decode.acc_seg: 99.8037, loss: 0.1387
2023-11-21 17:03:02,724 - mmseg - INFO - Iter [2400/5000]	lr: 5.998e-05, eta: 0:31:56, time: 0.671, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1457, decode.acc_seg: 99.7903, loss: 0.1464
2023-11-21 17:03:39,330 - mmseg - INFO - Iter [2450/5000]	lr: 5.911e-05, eta: 0:31:19, time: 0.732, data_time: 0.138, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1427, decode.acc_seg: 99.7766, loss: 0.1435
2023-11-21 17:04:12,950 - mmseg - INFO - Iter [2500/5000]	lr: 5.825e-05, eta: 0:30:39, time: 0.672, data_time: 0.073, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1446, decode.acc_seg: 99.7711, loss: 0.1455
2023-11-21 17:04:30,840 - mmseg - INFO - per class results:
2023-11-21 17:04:30,841 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.95 | 70.42 | 72.82 | 70.39 | 99.93 | 99.96  |   99.97   | 99.96  | 99.94 |
|  scratch   | 85.33 | 85.04 | 74.06 | 76.58 | 72.07 | 85.38  |   90.84   | 81.38  | 78.07 |
|   stain    | 81.62 | 88.75 | 74.58 | 79.19 |  60.3 | 80.02  |   93.83   | 73.53  | 70.03 |
| edgeDamage | 85.99 | 84.38 | 74.04 | 76.48 | 89.11 | 86.24  |   81.68   | 92.74  | 79.36 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:04:30,841 - mmseg - INFO - Summary:
2023-11-21 17:04:30,842 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.95 | 88.22 | 82.15 | 73.88 | 75.66 | 80.35 |   87.9  |   91.58    |   86.9  | 81.85 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:04:30,855 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9995, mIoU: 0.8822, mVOE: 0.8215, mASD: 0.7388, mMSSD: 0.7566, mAcc: 0.8035, mFscore: 0.8790, mPrecision: 0.9158, mRecall: 0.8690, mDice: 0.8185, IoU.background: 0.9995, IoU.scratch: 0.8533, IoU.stain: 0.8162, IoU.edgeDamage: 0.8599, VOE.background: 0.7042, VOE.scratch: 0.8504, VOE.stain: 0.8875, VOE.edgeDamage: 0.8438, ASD.background: 0.7282, ASD.scratch: 0.7406, ASD.stain: 0.7458, ASD.edgeDamage: 0.7404, MSSD.background: 0.7039, MSSD.scratch: 0.7658, MSSD.stain: 0.7919, MSSD.edgeDamage: 0.7648, Acc.background: 0.9993, Acc.scratch: 0.7207, Acc.stain: 0.6030, Acc.edgeDamage: 0.8911, Fscore.background: 0.9996, Fscore.scratch: 0.8538, Fscore.stain: 0.8002, Fscore.edgeDamage: 0.8624, Precision.background: 0.9997, Precision.scratch: 0.9084, Precision.stain: 0.9383, Precision.edgeDamage: 0.8168, Recall.background: 0.9996, Recall.scratch: 0.8138, Recall.stain: 0.7353, Recall.edgeDamage: 0.9274, Dice.background: 0.9994, Dice.scratch: 0.7807, Dice.stain: 0.7003, Dice.edgeDamage: 0.7936
2023-11-21 17:05:07,534 - mmseg - INFO - Iter [2550/5000]	lr: 5.738e-05, eta: 0:30:19, time: 1.092, data_time: 0.495, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1448, decode.acc_seg: 99.7798, loss: 0.1456
2023-11-21 17:05:41,043 - mmseg - INFO - Iter [2600/5000]	lr: 5.651e-05, eta: 0:29:39, time: 0.670, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1420, decode.acc_seg: 99.7748, loss: 0.1428
2023-11-21 17:06:17,588 - mmseg - INFO - Iter [2650/5000]	lr: 5.563e-05, eta: 0:29:01, time: 0.731, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1342, decode.acc_seg: 99.8031, loss: 0.1349
2023-11-21 17:06:51,287 - mmseg - INFO - Iter [2700/5000]	lr: 5.476e-05, eta: 0:28:21, time: 0.674, data_time: 0.074, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1333, decode.acc_seg: 99.8062, loss: 0.1340
2023-11-21 17:07:28,050 - mmseg - INFO - Iter [2750/5000]	lr: 5.388e-05, eta: 0:27:44, time: 0.735, data_time: 0.138, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1362, decode.acc_seg: 99.7867, loss: 0.1370
2023-11-21 17:08:01,541 - mmseg - INFO - Iter [2800/5000]	lr: 5.301e-05, eta: 0:27:04, time: 0.670, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1299, decode.acc_seg: 99.8119, loss: 0.1306
2023-11-21 17:08:38,401 - mmseg - INFO - Iter [2850/5000]	lr: 5.213e-05, eta: 0:26:27, time: 0.737, data_time: 0.144, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1343, decode.acc_seg: 99.8052, loss: 0.1350
2023-11-21 17:09:12,066 - mmseg - INFO - Iter [2900/5000]	lr: 5.124e-05, eta: 0:25:48, time: 0.673, data_time: 0.074, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1321, decode.acc_seg: 99.8037, loss: 0.1327
2023-11-21 17:09:48,921 - mmseg - INFO - Iter [2950/5000]	lr: 5.036e-05, eta: 0:25:11, time: 0.737, data_time: 0.140, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1367, decode.acc_seg: 99.7996, loss: 0.1374
2023-11-21 17:10:35,117 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:10:35,117 - mmseg - INFO - Iter [3000/5000]	lr: 4.947e-05, eta: 0:24:41, time: 0.924, data_time: 0.354, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1340, decode.acc_seg: 99.8135, loss: 0.1346
2023-11-21 17:11:01,702 - mmseg - INFO - per class results:
2023-11-21 17:11:01,703 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.96 | 70.41 | 72.82 | 70.38 | 99.94 | 99.97  |   99.97   | 99.96  | 99.95 |
|  scratch   | 86.23 | 84.14 | 73.82 | 75.39 | 77.41 | 86.54  |   88.33   | 84.94  | 79.82 |
|   stain    | 85.96 | 84.41 | 74.01 | 76.32 | 73.23 | 86.21  |   91.72   | 82.15  | 79.31 |
| edgeDamage | 87.97 |  82.4 |  73.8 | 75.28 | 89.48 | 88.69  |   85.27   | 92.98  | 83.03 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:11:01,703 - mmseg - INFO - Summary:
2023-11-21 17:11:01,703 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.96 | 90.03 | 80.34 | 73.61 | 74.34 | 85.01 |  90.35  |   91.32    |  90.01  | 85.53 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:11:02,018 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:11:02,019 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9996, mIoU: 0.9003, mVOE: 0.8034, mASD: 0.7361, mMSSD: 0.7434, mAcc: 0.8501, mFscore: 0.9035, mPrecision: 0.9132, mRecall: 0.9001, mDice: 0.8553, IoU.background: 0.9996, IoU.scratch: 0.8623, IoU.stain: 0.8596, IoU.edgeDamage: 0.8797, VOE.background: 0.7041, VOE.scratch: 0.8414, VOE.stain: 0.8441, VOE.edgeDamage: 0.8240, ASD.background: 0.7282, ASD.scratch: 0.7382, ASD.stain: 0.7401, ASD.edgeDamage: 0.7380, MSSD.background: 0.7038, MSSD.scratch: 0.7539, MSSD.stain: 0.7632, MSSD.edgeDamage: 0.7528, Acc.background: 0.9994, Acc.scratch: 0.7741, Acc.stain: 0.7323, Acc.edgeDamage: 0.8948, Fscore.background: 0.9997, Fscore.scratch: 0.8654, Fscore.stain: 0.8621, Fscore.edgeDamage: 0.8869, Precision.background: 0.9997, Precision.scratch: 0.8833, Precision.stain: 0.9172, Precision.edgeDamage: 0.8527, Recall.background: 0.9996, Recall.scratch: 0.8494, Recall.stain: 0.8215, Recall.edgeDamage: 0.9298, Dice.background: 0.9995, Dice.scratch: 0.7982, Dice.stain: 0.7931, Dice.edgeDamage: 0.8303
2023-11-21 17:11:39,976 - mmseg - INFO - Iter [3050/5000]	lr: 4.858e-05, eta: 0:24:21, time: 1.297, data_time: 0.710, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1380, decode.acc_seg: 99.8073, loss: 0.1387
2023-11-21 17:12:13,500 - mmseg - INFO - Iter [3100/5000]	lr: 4.769e-05, eta: 0:23:41, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1332, decode.acc_seg: 99.8058, loss: 0.1339
2023-11-21 17:12:50,468 - mmseg - INFO - Iter [3150/5000]	lr: 4.680e-05, eta: 0:23:04, time: 0.739, data_time: 0.145, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1324, decode.acc_seg: 99.7960, loss: 0.1330
2023-11-21 17:13:24,628 - mmseg - INFO - Iter [3200/5000]	lr: 4.590e-05, eta: 0:22:24, time: 0.683, data_time: 0.088, memory: 17708, decode.loss_focal: 0.0008, decode.loss_dice: 0.1403, decode.acc_seg: 99.7739, loss: 0.1411
2023-11-21 17:14:01,443 - mmseg - INFO - Iter [3250/5000]	lr: 4.500e-05, eta: 0:21:47, time: 0.736, data_time: 0.138, memory: 17708, decode.loss_focal: 0.0007, decode.loss_dice: 0.1341, decode.acc_seg: 99.7985, loss: 0.1348
2023-11-21 17:14:34,970 - mmseg - INFO - Iter [3300/5000]	lr: 4.410e-05, eta: 0:21:07, time: 0.671, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1315, decode.acc_seg: 99.8134, loss: 0.1321
2023-11-21 17:15:11,644 - mmseg - INFO - Iter [3350/5000]	lr: 4.320e-05, eta: 0:20:30, time: 0.733, data_time: 0.132, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1301, decode.acc_seg: 99.8242, loss: 0.1307
2023-11-21 17:15:49,075 - mmseg - INFO - Iter [3400/5000]	lr: 4.229e-05, eta: 0:19:53, time: 0.749, data_time: 0.150, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1330, decode.acc_seg: 99.8199, loss: 0.1336
2023-11-21 17:16:22,710 - mmseg - INFO - Iter [3450/5000]	lr: 4.138e-05, eta: 0:19:14, time: 0.673, data_time: 0.074, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1321, decode.acc_seg: 99.8102, loss: 0.1328
2023-11-21 17:17:00,042 - mmseg - INFO - Iter [3500/5000]	lr: 4.047e-05, eta: 0:18:37, time: 0.747, data_time: 0.150, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1296, decode.acc_seg: 99.8052, loss: 0.1303
2023-11-21 17:17:18,119 - mmseg - INFO - per class results:
2023-11-21 17:17:18,120 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.95 | 70.42 | 72.82 | 70.39 | 99.92 | 99.96  |   99.97   | 99.95  | 99.94 |
|  scratch   | 85.52 | 84.85 | 74.04 | 76.48 |  72.5 | 85.63  |   91.02   | 81.67  | 78.45 |
|   stain    | 86.44 | 83.93 | 73.89 |  75.7 | 76.01 | 86.82  |   90.24   | 84.01  | 80.22 |
| edgeDamage | 86.34 | 84.03 |  74.1 | 76.75 |  94.0 | 86.69  |   80.86   |  96.0  | 80.04 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:17:18,122 - mmseg - INFO - Summary:
2023-11-21 17:17:18,122 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.95 | 89.56 | 80.81 | 73.71 | 74.83 | 85.61 |  89.77  |   90.52    |  90.41  | 84.66 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:17:18,137 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9995, mIoU: 0.8956, mVOE: 0.8081, mASD: 0.7371, mMSSD: 0.7483, mAcc: 0.8561, mFscore: 0.8977, mPrecision: 0.9052, mRecall: 0.9041, mDice: 0.8466, IoU.background: 0.9995, IoU.scratch: 0.8552, IoU.stain: 0.8644, IoU.edgeDamage: 0.8634, VOE.background: 0.7042, VOE.scratch: 0.8485, VOE.stain: 0.8393, VOE.edgeDamage: 0.8403, ASD.background: 0.7282, ASD.scratch: 0.7404, ASD.stain: 0.7389, ASD.edgeDamage: 0.7410, MSSD.background: 0.7039, MSSD.scratch: 0.7648, MSSD.stain: 0.7570, MSSD.edgeDamage: 0.7675, Acc.background: 0.9992, Acc.scratch: 0.7250, Acc.stain: 0.7601, Acc.edgeDamage: 0.9400, Fscore.background: 0.9996, Fscore.scratch: 0.8563, Fscore.stain: 0.8682, Fscore.edgeDamage: 0.8669, Precision.background: 0.9997, Precision.scratch: 0.9102, Precision.stain: 0.9024, Precision.edgeDamage: 0.8086, Recall.background: 0.9995, Recall.scratch: 0.8167, Recall.stain: 0.8401, Recall.edgeDamage: 0.9600, Dice.background: 0.9994, Dice.scratch: 0.7845, Dice.stain: 0.8022, Dice.edgeDamage: 0.8004
2023-11-21 17:17:51,749 - mmseg - INFO - Iter [3550/5000]	lr: 3.956e-05, eta: 0:18:05, time: 1.034, data_time: 0.438, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1309, decode.acc_seg: 99.8196, loss: 0.1315
2023-11-21 17:18:28,584 - mmseg - INFO - Iter [3600/5000]	lr: 3.864e-05, eta: 0:17:28, time: 0.737, data_time: 0.142, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1322, decode.acc_seg: 99.8023, loss: 0.1328
2023-11-21 17:19:02,271 - mmseg - INFO - Iter [3650/5000]	lr: 3.772e-05, eta: 0:16:49, time: 0.674, data_time: 0.081, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1320, decode.acc_seg: 99.8169, loss: 0.1326
2023-11-21 17:19:39,083 - mmseg - INFO - Iter [3700/5000]	lr: 3.679e-05, eta: 0:16:11, time: 0.736, data_time: 0.139, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1314, decode.acc_seg: 99.8217, loss: 0.1320
2023-11-21 17:20:12,806 - mmseg - INFO - Iter [3750/5000]	lr: 3.586e-05, eta: 0:15:33, time: 0.674, data_time: 0.077, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1285, decode.acc_seg: 99.8357, loss: 0.1290
2023-11-21 17:20:49,696 - mmseg - INFO - Iter [3800/5000]	lr: 3.493e-05, eta: 0:14:55, time: 0.738, data_time: 0.139, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1298, decode.acc_seg: 99.8265, loss: 0.1304
2023-11-21 17:21:24,146 - mmseg - INFO - Iter [3850/5000]	lr: 3.400e-05, eta: 0:14:17, time: 0.689, data_time: 0.094, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1292, decode.acc_seg: 99.8145, loss: 0.1297
2023-11-21 17:22:00,833 - mmseg - INFO - Iter [3900/5000]	lr: 3.306e-05, eta: 0:13:39, time: 0.734, data_time: 0.140, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1295, decode.acc_seg: 99.8249, loss: 0.1301
2023-11-21 17:22:34,495 - mmseg - INFO - Iter [3950/5000]	lr: 3.211e-05, eta: 0:13:01, time: 0.673, data_time: 0.075, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1248, decode.acc_seg: 99.8373, loss: 0.1254
2023-11-21 17:23:12,097 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:23:12,098 - mmseg - INFO - Iter [4000/5000]	lr: 3.116e-05, eta: 0:12:24, time: 0.752, data_time: 0.164, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1299, decode.acc_seg: 99.8179, loss: 0.1304
2023-11-21 17:23:29,931 - mmseg - INFO - per class results:
2023-11-21 17:23:29,932 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.95 | 70.42 | 72.82 | 70.39 | 99.93 | 99.96  |   99.98   | 99.95  | 99.95 |
|  scratch   | 87.46 | 82.91 | 73.75 |  75.0 | 79.16 | 88.07  |    90.3   |  86.1  |  82.1 |
|   stain    | 87.83 | 82.55 | 73.83 | 75.42 | 77.26 | 88.51  |   93.23   | 84.84  | 82.76 |
| edgeDamage | 86.97 |  83.4 | 74.03 |  76.4 |  94.0 | 87.48  |   81.92   |  96.0  | 81.22 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:23:29,932 - mmseg - INFO - Summary:
2023-11-21 17:23:29,932 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.95 | 90.55 | 79.82 | 73.61 |  74.3 | 87.58 |   91.0  |   91.36    |  91.72  | 86.51 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:23:29,952 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:23:29,952 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9995, mIoU: 0.9055, mVOE: 0.7982, mASD: 0.7361, mMSSD: 0.7430, mAcc: 0.8758, mFscore: 0.9100, mPrecision: 0.9136, mRecall: 0.9172, mDice: 0.8651, IoU.background: 0.9995, IoU.scratch: 0.8746, IoU.stain: 0.8783, IoU.edgeDamage: 0.8697, VOE.background: 0.7042, VOE.scratch: 0.8291, VOE.stain: 0.8255, VOE.edgeDamage: 0.8340, ASD.background: 0.7282, ASD.scratch: 0.7375, ASD.stain: 0.7383, ASD.edgeDamage: 0.7403, MSSD.background: 0.7039, MSSD.scratch: 0.7500, MSSD.stain: 0.7542, MSSD.edgeDamage: 0.7640, Acc.background: 0.9993, Acc.scratch: 0.7916, Acc.stain: 0.7726, Acc.edgeDamage: 0.9400, Fscore.background: 0.9996, Fscore.scratch: 0.8807, Fscore.stain: 0.8851, Fscore.edgeDamage: 0.8748, Precision.background: 0.9998, Precision.scratch: 0.9030, Precision.stain: 0.9323, Precision.edgeDamage: 0.8192, Recall.background: 0.9995, Recall.scratch: 0.8610, Recall.stain: 0.8484, Recall.edgeDamage: 0.9600, Dice.background: 0.9995, Dice.scratch: 0.8210, Dice.stain: 0.8276, Dice.edgeDamage: 0.8122
2023-11-21 17:24:03,432 - mmseg - INFO - Iter [4050/5000]	lr: 3.021e-05, eta: 0:11:50, time: 1.027, data_time: 0.427, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1269, decode.acc_seg: 99.8321, loss: 0.1274
2023-11-21 17:24:40,744 - mmseg - INFO - Iter [4100/5000]	lr: 2.925e-05, eta: 0:11:13, time: 0.746, data_time: 0.157, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1286, decode.acc_seg: 99.8356, loss: 0.1291
2023-11-21 17:25:15,440 - mmseg - INFO - Iter [4150/5000]	lr: 2.829e-05, eta: 0:10:35, time: 0.694, data_time: 0.105, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1288, decode.acc_seg: 99.8308, loss: 0.1293
2023-11-21 17:25:53,953 - mmseg - INFO - Iter [4200/5000]	lr: 2.732e-05, eta: 0:09:58, time: 0.770, data_time: 0.195, memory: 17708, decode.loss_focal: 0.0006, decode.loss_dice: 0.1273, decode.acc_seg: 99.8200, loss: 0.1279
2023-11-21 17:26:28,057 - mmseg - INFO - Iter [4250/5000]	lr: 2.634e-05, eta: 0:09:20, time: 0.682, data_time: 0.083, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1286, decode.acc_seg: 99.8292, loss: 0.1291
2023-11-21 17:27:04,696 - mmseg - INFO - Iter [4300/5000]	lr: 2.536e-05, eta: 0:08:42, time: 0.733, data_time: 0.134, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1250, decode.acc_seg: 99.8367, loss: 0.1255
2023-11-21 17:27:38,195 - mmseg - INFO - Iter [4350/5000]	lr: 2.437e-05, eta: 0:08:04, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1268, decode.acc_seg: 99.8386, loss: 0.1273
2023-11-21 17:28:15,092 - mmseg - INFO - Iter [4400/5000]	lr: 2.337e-05, eta: 0:07:27, time: 0.738, data_time: 0.140, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1256, decode.acc_seg: 99.8390, loss: 0.1261
2023-11-21 17:28:48,580 - mmseg - INFO - Iter [4450/5000]	lr: 2.237e-05, eta: 0:06:49, time: 0.670, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1244, decode.acc_seg: 99.8410, loss: 0.1249
2023-11-21 17:29:25,357 - mmseg - INFO - Iter [4500/5000]	lr: 2.135e-05, eta: 0:06:12, time: 0.736, data_time: 0.138, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1230, decode.acc_seg: 99.8412, loss: 0.1235
2023-11-21 17:29:43,596 - mmseg - INFO - per class results:
2023-11-21 17:29:43,597 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.96 | 70.41 | 72.82 | 70.38 | 99.96 | 99.97  |   99.97   | 99.97  | 99.96 |
|  scratch   | 87.07 |  83.3 | 73.86 | 75.57 | 76.59 | 87.59  |   91.59   | 84.39  | 81.39 |
|   stain    | 87.91 | 82.46 |  73.8 | 75.25 | 78.02 | 88.61  |   92.66   | 85.35  | 82.91 |
| edgeDamage | 90.33 | 80.04 |  73.6 | 74.28 | 92.57 | 91.34  |   88.26   | 95.05  |  87.0 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:29:43,597 - mmseg - INFO - Summary:
2023-11-21 17:29:43,597 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.96 | 91.32 | 79.05 | 73.52 | 73.87 | 86.79 |  91.88  |   93.12    |  91.19  | 87.82 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:29:43,615 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9996, mIoU: 0.9132, mVOE: 0.7905, mASD: 0.7352, mMSSD: 0.7387, mAcc: 0.8679, mFscore: 0.9188, mPrecision: 0.9312, mRecall: 0.9119, mDice: 0.8782, IoU.background: 0.9996, IoU.scratch: 0.8707, IoU.stain: 0.8791, IoU.edgeDamage: 0.9033, VOE.background: 0.7041, VOE.scratch: 0.8330, VOE.stain: 0.8246, VOE.edgeDamage: 0.8004, ASD.background: 0.7282, ASD.scratch: 0.7386, ASD.stain: 0.7380, ASD.edgeDamage: 0.7360, MSSD.background: 0.7038, MSSD.scratch: 0.7557, MSSD.stain: 0.7525, MSSD.edgeDamage: 0.7428, Acc.background: 0.9996, Acc.scratch: 0.7659, Acc.stain: 0.7802, Acc.edgeDamage: 0.9257, Fscore.background: 0.9997, Fscore.scratch: 0.8759, Fscore.stain: 0.8861, Fscore.edgeDamage: 0.9134, Precision.background: 0.9997, Precision.scratch: 0.9159, Precision.stain: 0.9266, Precision.edgeDamage: 0.8826, Recall.background: 0.9997, Recall.scratch: 0.8439, Recall.stain: 0.8535, Recall.edgeDamage: 0.9505, Dice.background: 0.9996, Dice.scratch: 0.8139, Dice.stain: 0.8291, Dice.edgeDamage: 0.8700
2023-11-21 17:30:17,399 - mmseg - INFO - Iter [4550/5000]	lr: 2.033e-05, eta: 0:05:36, time: 1.041, data_time: 0.445, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1247, decode.acc_seg: 99.8430, loss: 0.1251
2023-11-21 17:30:53,995 - mmseg - INFO - Iter [4600/5000]	lr: 1.929e-05, eta: 0:04:59, time: 0.732, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1244, decode.acc_seg: 99.8365, loss: 0.1249
2023-11-21 17:31:27,849 - mmseg - INFO - Iter [4650/5000]	lr: 1.824e-05, eta: 0:04:21, time: 0.677, data_time: 0.081, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1256, decode.acc_seg: 99.8481, loss: 0.1261
2023-11-21 17:32:04,756 - mmseg - INFO - Iter [4700/5000]	lr: 1.718e-05, eta: 0:03:44, time: 0.738, data_time: 0.143, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1241, decode.acc_seg: 99.8437, loss: 0.1246
2023-11-21 17:32:38,628 - mmseg - INFO - Iter [4750/5000]	lr: 1.609e-05, eta: 0:03:06, time: 0.677, data_time: 0.081, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1215, decode.acc_seg: 99.8455, loss: 0.1220
2023-11-21 17:33:15,217 - mmseg - INFO - Iter [4800/5000]	lr: 1.499e-05, eta: 0:02:29, time: 0.732, data_time: 0.133, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1246, decode.acc_seg: 99.8376, loss: 0.1251
2023-11-21 17:33:48,766 - mmseg - INFO - Iter [4850/5000]	lr: 1.386e-05, eta: 0:01:51, time: 0.671, data_time: 0.071, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1250, decode.acc_seg: 99.8500, loss: 0.1254
2023-11-21 17:34:25,576 - mmseg - INFO - Iter [4900/5000]	lr: 1.269e-05, eta: 0:01:14, time: 0.736, data_time: 0.139, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1225, decode.acc_seg: 99.8331, loss: 0.1230
2023-11-21 17:34:59,104 - mmseg - INFO - Iter [4950/5000]	lr: 1.145e-05, eta: 0:00:37, time: 0.671, data_time: 0.070, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1243, decode.acc_seg: 99.8485, loss: 0.1248
2023-11-21 17:35:35,664 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-11-21 17:35:36,165 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:35:36,165 - mmseg - INFO - Iter [5000/5000]	lr: 1.004e-05, eta: 0:00:00, time: 0.743, data_time: 0.136, memory: 17708, decode.loss_focal: 0.0005, decode.loss_dice: 0.1229, decode.acc_seg: 99.8465, loss: 0.1234
2023-11-21 17:35:54,525 - mmseg - INFO - per class results:
2023-11-21 17:35:54,526 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.96 | 70.41 | 72.82 | 70.38 | 99.95 | 99.97  |   99.98   | 99.97  | 99.96 |
|  scratch   | 87.24 | 83.13 | 73.78 | 75.18 | 78.34 |  87.8  |   90.41   | 85.56  |  81.7 |
|   stain    | 87.83 | 82.54 | 73.83 | 75.41 | 77.33 | 88.51  |   93.15   | 84.89  | 82.76 |
| edgeDamage | 89.98 | 80.39 | 73.65 | 74.53 | 92.82 | 90.95  |   87.52   | 95.21  | 86.43 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 17:35:54,526 - mmseg - INFO - Summary:
2023-11-21 17:35:54,526 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.96 | 91.25 | 79.12 | 73.52 | 73.88 | 87.11 |  91.81  |   92.76    |  91.41  | 87.71 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 17:35:54,540 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 17:35:54,541 - mmseg - INFO - Iter(val) [83]	aAcc: 0.9996, mIoU: 0.9125, mVOE: 0.7912, mASD: 0.7352, mMSSD: 0.7388, mAcc: 0.8711, mFscore: 0.9181, mPrecision: 0.9276, mRecall: 0.9141, mDice: 0.8771, IoU.background: 0.9996, IoU.scratch: 0.8724, IoU.stain: 0.8783, IoU.edgeDamage: 0.8998, VOE.background: 0.7041, VOE.scratch: 0.8313, VOE.stain: 0.8254, VOE.edgeDamage: 0.8039, ASD.background: 0.7282, ASD.scratch: 0.7378, ASD.stain: 0.7383, ASD.edgeDamage: 0.7365, MSSD.background: 0.7038, MSSD.scratch: 0.7518, MSSD.stain: 0.7541, MSSD.edgeDamage: 0.7453, Acc.background: 0.9995, Acc.scratch: 0.7834, Acc.stain: 0.7733, Acc.edgeDamage: 0.9282, Fscore.background: 0.9997, Fscore.scratch: 0.8780, Fscore.stain: 0.8851, Fscore.edgeDamage: 0.9095, Precision.background: 0.9998, Precision.scratch: 0.9041, Precision.stain: 0.9315, Precision.edgeDamage: 0.8752, Recall.background: 0.9997, Recall.scratch: 0.8556, Recall.stain: 0.8489, Recall.edgeDamage: 0.9521, Dice.background: 0.9996, Dice.scratch: 0.8170, Dice.stain: 0.8276, Dice.edgeDamage: 0.8643
