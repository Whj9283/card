2023-11-21 02:28:46,963 - mmseg - INFO - Multi-processing start method is `None`
2023-11-21 02:28:46,964 - mmseg - INFO - OpenCV num_threads is `6
2023-11-21 02:28:47,006 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA RTX A4000
CUDA_HOME: /environment/miniconda3
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.1
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.1+
------------------------------------------------------------

2023-11-21 02:28:47,006 - mmseg - INFO - Distributed training: False
2023-11-21 02:28:47,225 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='UnetBackbone',
        in_channels=3,
        context_layer='kernelselect',
        channel_list=[64, 128, 256, 512]),
    decode_head=dict(
        type='UnetHead',
        num_classes=4,
        channels=64,
        threshold=0.2,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        loss_decode=[
            dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                class_weight=[0.1, 0.3, 0.3, 0.3],
                loss_weight=2.0),
            dict(type='DiceLoss', loss_name='loss_dice', loss_weight=2.0)
        ]))
train_cfg = dict()
test_cfg = dict(mode='whole')
dataset_type = 'MyDataset'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(600, 600)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=False),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data_root = './datasets/'
data = dict(
    samples_per_gpu=3,
    workers_per_gpu=2,
    train=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='train/images',
        ann_dir='train/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(600, 600)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TensorboardLoggerHook'),
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = False
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.999))
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=1e-05, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=5000)
checkpoint_config = dict(by_epoch=False, save_optimizer=False, interval=5000)
evaluation = dict(interval=500, metric=['mIoU', 'mFscore', 'mDice'])
work_dir = './work_dirs/unet_all'
gpu_ids = [0]
auto_resume = False

2023-11-21 02:28:47,225 - mmseg - INFO - Set random seed to 1453269058, deterministic: False
2023-11-21 02:28:47,374 - mmseg - INFO - initialize UnetHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.inc.conv.conv.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.weight - torch.Size([16, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.weight - torch.Size([64, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.weight - torch.Size([32, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.weight - torch.Size([128, 32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.weight - torch.Size([512, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([4, 64, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.up1.conv.conv.0.weight - torch.Size([256, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.shortcuts.0.conv1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.shortcuts.0.conv1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.shortcuts.0.batchnorm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.shortcuts.0.batchnorm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.convs.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.convs.0.conv1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.convs.0.batchnorm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.convs.0.batchnorm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.bns.0.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.resPath.bns.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.weight - torch.Size([128, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.0.conv1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.0.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.0.batchnorm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.0.batchnorm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.1.conv1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.1.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.1.batchnorm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.shortcuts.1.batchnorm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.0.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.0.batchnorm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.0.batchnorm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.1.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.1.batchnorm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.convs.1.batchnorm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.bns.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.bns.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.bns.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.resPath.bns.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.0.conv1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.0.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.0.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.0.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.1.conv1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.1.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.1.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.2.conv1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.2.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.shortcuts.2.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.0.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.0.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.0.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.0.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.1.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.1.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.1.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.2.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.2.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.2.batchnorm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.convs.2.batchnorm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.resPath.bns.2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.0.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.0.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.0.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.1.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.1.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.1.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.2.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.2.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.2.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.3.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.3.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.3.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.shortcuts.3.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.0.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.0.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.0.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.1.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.1.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.1.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.2.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.2.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.2.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.2.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.3.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.3.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.3.batchnorm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.convs.3.batchnorm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.resPath.bns.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-11-21 02:28:47,383 - mmseg - INFO - EncoderDecoder(
  (backbone): UnetBackbone(
    (inc): InConv(
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down3): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down4): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (context_layer1_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=64, out_features=16, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=16, out_features=64, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer2_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer3_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=64, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=64, out_features=256, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer4_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=512, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=512, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
  )
  (decode_head): UnetHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): FocalLoss()
      (1): DiceLoss()
    )
    (conv_seg): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (up1): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (resPath): Respath(
        (shortcuts): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (convs): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (bns): ModuleList(
          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (up2): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (resPath): Respath(
        (shortcuts): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (convs): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (bns): ModuleList(
          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (up3): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (resPath): Respath(
        (shortcuts): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (convs): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Conv2d_batchnorm(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (bns): ModuleList(
          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (up4): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (resPath): Respath(
        (shortcuts): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (convs): ModuleList(
          (0): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): Conv2d_batchnorm(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
            (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (bns): ModuleList(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-21 02:28:47,393 - mmseg - INFO - Loaded 467 images
2023-11-21 02:28:53,484 - mmseg - INFO - Loaded 117 images
2023-11-21 02:28:53,484 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/work/test/work_dirs/unet_all
2023-11-21 02:28:53,484 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-21 02:28:53,485 - mmseg - INFO - workflow: [('train', 1)], max: 5000 iters
2023-11-21 02:28:53,485 - mmseg - INFO - Checkpoints will be saved to /home/featurize/work/test/work_dirs/unet_all by HardDiskBackend.
2023-11-21 02:29:24,588 - mmseg - INFO - Iter [50/5000]	lr: 9.921e-05, eta: 0:50:54, time: 0.617, data_time: 0.011, memory: 11840, decode.loss_focal: 0.0498, decode.loss_dice: 1.7156, decode.acc_seg: 92.8318, loss: 1.7654
2023-11-21 02:29:55,296 - mmseg - INFO - Iter [100/5000]	lr: 9.839e-05, eta: 0:50:16, time: 0.614, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0373, decode.loss_dice: 1.6581, decode.acc_seg: 98.9590, loss: 1.6953
2023-11-21 02:30:26,254 - mmseg - INFO - Iter [150/5000]	lr: 9.758e-05, eta: 0:49:51, time: 0.619, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0283, decode.loss_dice: 1.6130, decode.acc_seg: 99.0104, loss: 1.6412
2023-11-21 02:30:59,721 - mmseg - INFO - Iter [200/5000]	lr: 9.677e-05, eta: 0:50:23, time: 0.669, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0215, decode.loss_dice: 1.5712, decode.acc_seg: 99.0895, loss: 1.5926
2023-11-21 02:31:30,779 - mmseg - INFO - Iter [250/5000]	lr: 9.596e-05, eta: 0:49:43, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0171, decode.loss_dice: 1.5417, decode.acc_seg: 98.7499, loss: 1.5588
2023-11-21 02:32:01,869 - mmseg - INFO - Iter [300/5000]	lr: 9.514e-05, eta: 0:49:07, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0134, decode.loss_dice: 1.5174, decode.acc_seg: 98.9893, loss: 1.5308
2023-11-21 02:32:35,263 - mmseg - INFO - Iter [350/5000]	lr: 9.433e-05, eta: 0:49:03, time: 0.668, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0107, decode.loss_dice: 1.4890, decode.acc_seg: 98.8727, loss: 1.4997
2023-11-21 02:33:06,299 - mmseg - INFO - Iter [400/5000]	lr: 9.351e-05, eta: 0:48:24, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0088, decode.loss_dice: 1.4625, decode.acc_seg: 98.9409, loss: 1.4713
2023-11-21 02:33:37,346 - mmseg - INFO - Iter [450/5000]	lr: 9.269e-05, eta: 0:47:47, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0071, decode.loss_dice: 1.4339, decode.acc_seg: 99.0106, loss: 1.4410
2023-11-21 02:34:10,844 - mmseg - INFO - Iter [500/5000]	lr: 9.187e-05, eta: 0:47:33, time: 0.670, data_time: 0.052, memory: 11840, decode.loss_focal: 0.0056, decode.loss_dice: 1.3829, decode.acc_seg: 99.3451, loss: 1.3885
2023-11-21 02:34:38,733 - mmseg - INFO - per class results:
2023-11-21 02:34:38,734 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.77 |  70.6 | 70.69 | 70.47 | 99.57 | 99.82  |   99.93   | 99.71  | 99.74 |
|  scratch   | 72.72 | 97.65 |  73.4 |  84.0 | 38.69 | 62.08  |   93.24   | 59.13  | 43.12 |
|   stain    | 75.39 | 94.98 | 73.04 |  82.2 | 67.63 | 68.44  |   64.52   | 78.42  | 52.66 |
| edgeDamage | 73.69 | 96.68 |  73.3 | 83.49 | 88.64 | 64.51  |   60.65   | 92.43  | 46.76 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 02:34:38,734 - mmseg - INFO - Summary:
2023-11-21 02:34:38,735 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.77 | 80.39 | 89.98 | 72.61 | 80.04 | 73.63 |  73.71  |   79.59    |  82.42  | 60.57 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 02:34:38,749 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9977, mIoU: 0.8039, mVOE: 0.8998, mASD: 0.7261, mMSSD: 0.8004, mAcc: 0.7363, mFscore: 0.7371, mPrecision: 0.7959, mRecall: 0.8242, mDice: 0.6057, IoU.background: 0.9977, IoU.scratch: 0.7272, IoU.stain: 0.7539, IoU.edgeDamage: 0.7369, VOE.background: 0.7060, VOE.scratch: 0.9765, VOE.stain: 0.9498, VOE.edgeDamage: 0.9668, ASD.background: 0.7069, ASD.scratch: 0.7340, ASD.stain: 0.7304, ASD.edgeDamage: 0.7330, MSSD.background: 0.7047, MSSD.scratch: 0.8400, MSSD.stain: 0.8220, MSSD.edgeDamage: 0.8349, Acc.background: 0.9957, Acc.scratch: 0.3869, Acc.stain: 0.6763, Acc.edgeDamage: 0.8864, Fscore.background: 0.9982, Fscore.scratch: 0.6208, Fscore.stain: 0.6844, Fscore.edgeDamage: 0.6451, Precision.background: 0.9993, Precision.scratch: 0.9324, Precision.stain: 0.6452, Precision.edgeDamage: 0.6065, Recall.background: 0.9971, Recall.scratch: 0.5913, Recall.stain: 0.7842, Recall.edgeDamage: 0.9243, Dice.background: 0.9974, Dice.scratch: 0.4312, Dice.stain: 0.5266, Dice.edgeDamage: 0.4676
2023-11-21 02:35:09,555 - mmseg - INFO - Iter [550/5000]	lr: 9.106e-05, eta: 0:50:40, time: 1.174, data_time: 0.561, memory: 11840, decode.loss_focal: 0.0048, decode.loss_dice: 1.3864, decode.acc_seg: 99.2877, loss: 1.3912
2023-11-21 02:35:40,595 - mmseg - INFO - Iter [600/5000]	lr: 9.024e-05, eta: 0:49:43, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0041, decode.loss_dice: 1.3452, decode.acc_seg: 99.4166, loss: 1.3493
2023-11-21 02:36:14,100 - mmseg - INFO - Iter [650/5000]	lr: 8.941e-05, eta: 0:49:07, time: 0.670, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0037, decode.loss_dice: 1.3243, decode.acc_seg: 99.3633, loss: 1.3279
2023-11-21 02:36:45,244 - mmseg - INFO - Iter [700/5000]	lr: 8.859e-05, eta: 0:48:16, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0032, decode.loss_dice: 1.3031, decode.acc_seg: 99.3580, loss: 1.3063
2023-11-21 02:37:16,422 - mmseg - INFO - Iter [750/5000]	lr: 8.777e-05, eta: 0:47:28, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0029, decode.loss_dice: 1.2965, decode.acc_seg: 99.4879, loss: 1.2994
2023-11-21 02:37:49,972 - mmseg - INFO - Iter [800/5000]	lr: 8.695e-05, eta: 0:46:55, time: 0.671, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0027, decode.loss_dice: 1.2642, decode.acc_seg: 99.4781, loss: 1.2669
2023-11-21 02:38:21,117 - mmseg - INFO - Iter [850/5000]	lr: 8.612e-05, eta: 0:46:10, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0025, decode.loss_dice: 1.2653, decode.acc_seg: 99.5099, loss: 1.2678
2023-11-21 02:38:52,302 - mmseg - INFO - Iter [900/5000]	lr: 8.530e-05, eta: 0:45:26, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0025, decode.loss_dice: 1.2696, decode.acc_seg: 99.4620, loss: 1.2721
2023-11-21 02:39:25,891 - mmseg - INFO - Iter [950/5000]	lr: 8.447e-05, eta: 0:44:54, time: 0.672, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 1.2086, decode.acc_seg: 99.6066, loss: 1.2107
2023-11-21 02:39:57,060 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 02:39:57,060 - mmseg - INFO - Iter [1000/5000]	lr: 8.364e-05, eta: 0:44:13, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0020, decode.loss_dice: 1.2439, decode.acc_seg: 99.5740, loss: 1.2459
2023-11-21 02:40:24,526 - mmseg - INFO - per class results:
2023-11-21 02:40:24,527 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.77 |  70.6 | 70.69 | 70.47 | 99.57 | 99.83  |   99.94   | 99.71  | 99.74 |
|  scratch   | 74.92 | 95.45 | 73.16 | 82.79 | 44.12 | 67.38  |   88.83   | 62.74  | 51.07 |
|   stain    | 77.36 | 93.01 | 72.71 | 80.55 | 65.88 | 72.52  |   69.48   | 77.25  | 58.77 |
| edgeDamage | 73.86 | 96.51 | 73.28 | 83.41 | 92.51 | 64.93  |   60.87   | 95.01  | 47.39 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 02:40:24,527 - mmseg - INFO - Summary:
2023-11-21 02:40:24,527 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.77 | 81.48 | 88.89 | 72.46 |  79.3 | 75.52 |  76.16  |   79.78    |  83.68  | 64.24 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 02:40:24,541 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 02:40:24,541 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9977, mIoU: 0.8148, mVOE: 0.8889, mASD: 0.7246, mMSSD: 0.7930, mAcc: 0.7552, mFscore: 0.7616, mPrecision: 0.7978, mRecall: 0.8368, mDice: 0.6424, IoU.background: 0.9977, IoU.scratch: 0.7492, IoU.stain: 0.7736, IoU.edgeDamage: 0.7386, VOE.background: 0.7060, VOE.scratch: 0.9545, VOE.stain: 0.9301, VOE.edgeDamage: 0.9651, ASD.background: 0.7069, ASD.scratch: 0.7316, ASD.stain: 0.7271, ASD.edgeDamage: 0.7328, MSSD.background: 0.7047, MSSD.scratch: 0.8279, MSSD.stain: 0.8055, MSSD.edgeDamage: 0.8341, Acc.background: 0.9957, Acc.scratch: 0.4412, Acc.stain: 0.6588, Acc.edgeDamage: 0.9251, Fscore.background: 0.9983, Fscore.scratch: 0.6738, Fscore.stain: 0.7252, Fscore.edgeDamage: 0.6493, Precision.background: 0.9994, Precision.scratch: 0.8883, Precision.stain: 0.6948, Precision.edgeDamage: 0.6087, Recall.background: 0.9971, Recall.scratch: 0.6274, Recall.stain: 0.7725, Recall.edgeDamage: 0.9501, Dice.background: 0.9974, Dice.scratch: 0.5107, Dice.stain: 0.5877, Dice.edgeDamage: 0.4739
2023-11-21 02:40:55,458 - mmseg - INFO - Iter [1050/5000]	lr: 8.281e-05, eta: 0:45:15, time: 1.168, data_time: 0.552, memory: 11840, decode.loss_focal: 0.0020, decode.loss_dice: 1.2297, decode.acc_seg: 99.5467, loss: 1.2317
2023-11-21 02:41:29,033 - mmseg - INFO - Iter [1100/5000]	lr: 8.198e-05, eta: 0:44:37, time: 0.671, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 1.2319, decode.acc_seg: 99.6599, loss: 1.2337
2023-11-21 02:42:00,215 - mmseg - INFO - Iter [1150/5000]	lr: 8.115e-05, eta: 0:43:52, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 1.2118, decode.acc_seg: 99.6536, loss: 1.2135
2023-11-21 02:42:31,439 - mmseg - INFO - Iter [1200/5000]	lr: 8.032e-05, eta: 0:43:09, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 1.2015, decode.acc_seg: 99.6028, loss: 1.2033
2023-11-21 02:43:05,040 - mmseg - INFO - Iter [1250/5000]	lr: 7.949e-05, eta: 0:42:33, time: 0.672, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 1.1842, decode.acc_seg: 99.6216, loss: 1.1860
2023-11-21 02:43:36,264 - mmseg - INFO - Iter [1300/5000]	lr: 7.865e-05, eta: 0:41:51, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 1.0660, decode.acc_seg: 99.6870, loss: 1.0677
2023-11-21 02:44:07,499 - mmseg - INFO - Iter [1350/5000]	lr: 7.782e-05, eta: 0:41:10, time: 0.625, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.9891, decode.acc_seg: 99.6980, loss: 0.9909
2023-11-21 02:44:41,072 - mmseg - INFO - Iter [1400/5000]	lr: 7.698e-05, eta: 0:40:35, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.8747, decode.acc_seg: 99.7151, loss: 0.8764
2023-11-21 02:45:12,240 - mmseg - INFO - Iter [1450/5000]	lr: 7.614e-05, eta: 0:39:55, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 0.9469, decode.acc_seg: 99.6271, loss: 0.9490
2023-11-21 02:45:43,413 - mmseg - INFO - Iter [1500/5000]	lr: 7.530e-05, eta: 0:39:15, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0019, decode.loss_dice: 0.8759, decode.acc_seg: 99.6984, loss: 0.8778
2023-11-21 02:46:10,630 - mmseg - INFO - per class results:
2023-11-21 02:46:10,631 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.83 | 70.54 | 70.69 | 70.44 | 99.71 | 99.87  |   99.94   |  99.8  | 99.81 |
|  scratch   | 74.59 | 95.78 | 73.19 | 82.94 | 43.44 | 66.64  |   86.88   | 62.29  | 49.97 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 75.16 | 95.21 | 73.15 | 82.74 |  92.6 | 67.93  |   62.89   | 95.07  |  51.9 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 02:46:10,632 - mmseg - INFO - Summary:
2023-11-21 02:46:10,632 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.83 | 79.99 | 90.38 | 72.34 |  78.7 | 67.27 |  78.15  |   83.24    |  78.18  | 58.75 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 02:46:10,647 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9983, mIoU: 0.7999, mVOE: 0.9038, mASD: 0.7234, mMSSD: 0.7870, mAcc: 0.6727, mFscore: 0.7815, mPrecision: 0.8324, mRecall: 0.7818, mDice: 0.5875, IoU.background: 0.9983, IoU.scratch: 0.7459, IoU.stain: 0.7037, IoU.edgeDamage: 0.7516, VOE.background: 0.7054, VOE.scratch: 0.9578, VOE.stain: 1.0000, VOE.edgeDamage: 0.9521, ASD.background: 0.7069, ASD.scratch: 0.7319, ASD.stain: nan, ASD.edgeDamage: 0.7315, MSSD.background: 0.7044, MSSD.scratch: 0.8294, MSSD.stain: nan, MSSD.edgeDamage: 0.8274, Acc.background: 0.9971, Acc.scratch: 0.4344, Acc.stain: 0.3333, Acc.edgeDamage: 0.9260, Fscore.background: 0.9987, Fscore.scratch: 0.6664, Fscore.stain: nan, Fscore.edgeDamage: 0.6793, Precision.background: 0.9994, Precision.scratch: 0.8688, Precision.stain: nan, Precision.edgeDamage: 0.6289, Recall.background: 0.9980, Recall.scratch: 0.6229, Recall.stain: 0.5556, Recall.edgeDamage: 0.9507, Dice.background: 0.9981, Dice.scratch: 0.4997, Dice.stain: 0.3333, Dice.edgeDamage: 0.5190
2023-11-21 02:46:41,514 - mmseg - INFO - Iter [1550/5000]	lr: 7.446e-05, eta: 0:39:36, time: 1.162, data_time: 0.548, memory: 11840, decode.loss_focal: 0.0022, decode.loss_dice: 0.8431, decode.acc_seg: 99.6650, loss: 0.8452
2023-11-21 02:47:14,964 - mmseg - INFO - Iter [1600/5000]	lr: 7.362e-05, eta: 0:39:00, time: 0.669, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0022, decode.loss_dice: 0.8550, decode.acc_seg: 99.6678, loss: 0.8571
2023-11-21 02:47:46,100 - mmseg - INFO - Iter [1650/5000]	lr: 7.278e-05, eta: 0:38:19, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0022, decode.loss_dice: 0.8331, decode.acc_seg: 99.6076, loss: 0.8353
2023-11-21 02:48:17,244 - mmseg - INFO - Iter [1700/5000]	lr: 7.194e-05, eta: 0:37:38, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0022, decode.loss_dice: 0.8719, decode.acc_seg: 99.6494, loss: 0.8740
2023-11-21 02:48:50,710 - mmseg - INFO - Iter [1750/5000]	lr: 7.109e-05, eta: 0:37:02, time: 0.669, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0024, decode.loss_dice: 0.8512, decode.acc_seg: 99.5883, loss: 0.8537
2023-11-21 02:49:21,820 - mmseg - INFO - Iter [1800/5000]	lr: 7.025e-05, eta: 0:36:23, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 0.8245, decode.acc_seg: 99.7003, loss: 0.8265
2023-11-21 02:49:52,905 - mmseg - INFO - Iter [1850/5000]	lr: 6.940e-05, eta: 0:35:43, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0026, decode.loss_dice: 0.8114, decode.acc_seg: 99.5950, loss: 0.8140
2023-11-21 02:50:26,349 - mmseg - INFO - Iter [1900/5000]	lr: 6.855e-05, eta: 0:35:08, time: 0.669, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 0.8264, decode.acc_seg: 99.6301, loss: 0.8285
2023-11-21 02:50:57,393 - mmseg - INFO - Iter [1950/5000]	lr: 6.770e-05, eta: 0:34:30, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.8110, decode.acc_seg: 99.7095, loss: 0.8128
2023-11-21 02:51:28,479 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 02:51:28,479 - mmseg - INFO - Iter [2000/5000]	lr: 6.685e-05, eta: 0:33:52, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 0.8249, decode.acc_seg: 99.6479, loss: 0.8270
2023-11-21 02:51:56,040 - mmseg - INFO - per class results:
2023-11-21 02:51:56,041 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 70.68 | 70.41 | 99.83 | 99.91  |   99.93   | 99.88  | 99.86 |
|  scratch   | 72.49 | 97.88 | 73.42 |  84.1 | 38.22 |  61.5  |   89.45   | 58.81  | 42.25 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 77.38 |  93.0 | 72.91 | 81.56 | 91.37 | 72.55  |   66.45   | 94.24  | 58.83 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 02:51:56,041 - mmseg - INFO - Summary:
2023-11-21 02:51:56,042 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.88 | 80.03 | 90.34 | 72.34 | 78.69 | 65.69 |  77.99  |   85.28    |  77.12  | 58.57 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 02:51:56,056 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 02:51:56,056 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9988, mIoU: 0.8003, mVOE: 0.9034, mASD: 0.7234, mMSSD: 0.7869, mAcc: 0.6569, mFscore: 0.7799, mPrecision: 0.8528, mRecall: 0.7712, mDice: 0.5857, IoU.background: 0.9988, IoU.scratch: 0.7249, IoU.stain: 0.7037, IoU.edgeDamage: 0.7738, VOE.background: 0.7049, VOE.scratch: 0.9788, VOE.stain: 1.0000, VOE.edgeDamage: 0.9300, ASD.background: 0.7068, ASD.scratch: 0.7342, ASD.stain: nan, ASD.edgeDamage: 0.7291, MSSD.background: 0.7041, MSSD.scratch: 0.8410, MSSD.stain: nan, MSSD.edgeDamage: 0.8156, Acc.background: 0.9983, Acc.scratch: 0.3822, Acc.stain: 0.3333, Acc.edgeDamage: 0.9137, Fscore.background: 0.9991, Fscore.scratch: 0.6150, Fscore.stain: nan, Fscore.edgeDamage: 0.7255, Precision.background: 0.9993, Precision.scratch: 0.8945, Precision.stain: nan, Precision.edgeDamage: 0.6645, Recall.background: 0.9988, Recall.scratch: 0.5881, Recall.stain: 0.5556, Recall.edgeDamage: 0.9424, Dice.background: 0.9986, Dice.scratch: 0.4225, Dice.stain: 0.3333, Dice.edgeDamage: 0.5883
2023-11-21 02:52:29,292 - mmseg - INFO - Iter [2050/5000]	lr: 6.599e-05, eta: 0:33:56, time: 1.216, data_time: 0.603, memory: 11840, decode.loss_focal: 0.0019, decode.loss_dice: 0.8178, decode.acc_seg: 99.7222, loss: 0.8197
2023-11-21 02:53:00,357 - mmseg - INFO - Iter [2100/5000]	lr: 6.514e-05, eta: 0:33:17, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.7822, decode.acc_seg: 99.7052, loss: 0.7841
2023-11-21 02:53:31,501 - mmseg - INFO - Iter [2150/5000]	lr: 6.428e-05, eta: 0:32:38, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0019, decode.loss_dice: 0.8318, decode.acc_seg: 99.6632, loss: 0.8336
2023-11-21 02:54:05,008 - mmseg - INFO - Iter [2200/5000]	lr: 6.343e-05, eta: 0:32:03, time: 0.670, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.7791, decode.acc_seg: 99.6929, loss: 0.7809
2023-11-21 02:54:36,151 - mmseg - INFO - Iter [2250/5000]	lr: 6.257e-05, eta: 0:31:25, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.7982, decode.acc_seg: 99.6938, loss: 0.7999
2023-11-21 02:55:07,314 - mmseg - INFO - Iter [2300/5000]	lr: 6.171e-05, eta: 0:30:47, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.8243, decode.acc_seg: 99.6738, loss: 0.8261
2023-11-21 02:55:40,873 - mmseg - INFO - Iter [2350/5000]	lr: 6.084e-05, eta: 0:30:12, time: 0.671, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.8471, decode.acc_seg: 99.6757, loss: 0.8489
2023-11-21 02:56:12,053 - mmseg - INFO - Iter [2400/5000]	lr: 5.998e-05, eta: 0:29:34, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0019, decode.loss_dice: 0.7998, decode.acc_seg: 99.6657, loss: 0.8017
2023-11-21 02:56:43,236 - mmseg - INFO - Iter [2450/5000]	lr: 5.911e-05, eta: 0:28:57, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.7860, decode.acc_seg: 99.6878, loss: 0.7878
2023-11-21 02:57:16,787 - mmseg - INFO - Iter [2500/5000]	lr: 5.825e-05, eta: 0:28:23, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0021, decode.loss_dice: 0.8059, decode.acc_seg: 99.6151, loss: 0.8080
2023-11-21 02:57:44,245 - mmseg - INFO - per class results:
2023-11-21 02:57:44,247 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.87 |  70.5 | 70.68 | 70.41 | 99.82 | 99.91  |   99.93   | 99.88  | 99.86 |
|  scratch   | 72.07 |  98.3 | 73.46 | 84.33 |  37.2 | 60.39  |   94.01   | 58.13  | 40.58 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 77.42 | 92.95 | 72.91 | 81.58 | 94.24 | 72.65  |   66.38   | 96.16  | 58.97 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 02:57:44,247 - mmseg - INFO - Summary:
2023-11-21 02:57:44,247 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.87 | 79.94 | 90.43 | 72.35 | 78.77 | 66.15 |  77.65  |   86.77    |  77.43  | 58.19 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 02:57:44,262 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9987, mIoU: 0.7994, mVOE: 0.9043, mASD: 0.7235, mMSSD: 0.7877, mAcc: 0.6615, mFscore: 0.7765, mPrecision: 0.8677, mRecall: 0.7743, mDice: 0.5819, IoU.background: 0.9987, IoU.scratch: 0.7207, IoU.stain: 0.7037, IoU.edgeDamage: 0.7742, VOE.background: 0.7050, VOE.scratch: 0.9830, VOE.stain: 1.0000, VOE.edgeDamage: 0.9295, ASD.background: 0.7068, ASD.scratch: 0.7346, ASD.stain: nan, ASD.edgeDamage: 0.7291, MSSD.background: 0.7041, MSSD.scratch: 0.8433, MSSD.stain: nan, MSSD.edgeDamage: 0.8158, Acc.background: 0.9982, Acc.scratch: 0.3720, Acc.stain: 0.3333, Acc.edgeDamage: 0.9424, Fscore.background: 0.9991, Fscore.scratch: 0.6039, Fscore.stain: nan, Fscore.edgeDamage: 0.7265, Precision.background: 0.9993, Precision.scratch: 0.9401, Precision.stain: nan, Precision.edgeDamage: 0.6638, Recall.background: 0.9988, Recall.scratch: 0.5813, Recall.stain: 0.5556, Recall.edgeDamage: 0.9616, Dice.background: 0.9986, Dice.scratch: 0.4058, Dice.stain: 0.3333, Dice.edgeDamage: 0.5897
2023-11-21 02:58:15,163 - mmseg - INFO - Iter [2550/5000]	lr: 5.738e-05, eta: 0:28:12, time: 1.168, data_time: 0.552, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.8040, decode.acc_seg: 99.6719, loss: 0.8057
2023-11-21 02:58:46,289 - mmseg - INFO - Iter [2600/5000]	lr: 5.651e-05, eta: 0:27:34, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.8104, decode.acc_seg: 99.6597, loss: 0.8122
2023-11-21 02:59:19,827 - mmseg - INFO - Iter [2650/5000]	lr: 5.563e-05, eta: 0:26:59, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0016, decode.loss_dice: 0.7797, decode.acc_seg: 99.7007, loss: 0.7813
2023-11-21 02:59:51,007 - mmseg - INFO - Iter [2700/5000]	lr: 5.476e-05, eta: 0:26:22, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0018, decode.loss_dice: 0.8216, decode.acc_seg: 99.6439, loss: 0.8234
2023-11-21 03:00:22,199 - mmseg - INFO - Iter [2750/5000]	lr: 5.388e-05, eta: 0:25:45, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7888, decode.acc_seg: 99.7158, loss: 0.7903
2023-11-21 03:00:55,769 - mmseg - INFO - Iter [2800/5000]	lr: 5.301e-05, eta: 0:25:10, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0016, decode.loss_dice: 0.7908, decode.acc_seg: 99.7177, loss: 0.7924
2023-11-21 03:01:26,924 - mmseg - INFO - Iter [2850/5000]	lr: 5.213e-05, eta: 0:24:33, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7478, decode.acc_seg: 99.7369, loss: 0.7493
2023-11-21 03:01:58,096 - mmseg - INFO - Iter [2900/5000]	lr: 5.124e-05, eta: 0:23:56, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.7830, decode.acc_seg: 99.6727, loss: 0.7848
2023-11-21 03:02:31,668 - mmseg - INFO - Iter [2950/5000]	lr: 5.036e-05, eta: 0:23:22, time: 0.671, data_time: 0.052, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7781, decode.acc_seg: 99.7264, loss: 0.7796
2023-11-21 03:03:02,784 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:03:02,784 - mmseg - INFO - Iter [3000/5000]	lr: 4.947e-05, eta: 0:22:46, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7366, decode.acc_seg: 99.7121, loss: 0.7381
2023-11-21 03:03:30,210 - mmseg - INFO - per class results:
2023-11-21 03:03:30,211 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.91 | 70.46 | 70.68 | 70.39 |  99.9 | 99.93  |   99.93   | 99.93  |  99.9 |
|  scratch   | 73.58 | 96.79 | 73.31 | 83.53 | 40.76 | 64.26  |   91.22   | 60.51  | 46.38 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 80.26 | 90.11 | 72.59 | 79.94 |  90.3 |  77.8  |   71.29   | 93.53  | 66.71 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 03:03:30,211 - mmseg - INFO - Summary:
2023-11-21 03:03:30,211 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.91 | 81.03 | 89.34 | 72.19 | 77.96 | 66.07 |  80.66  |   87.48    |  77.38  | 61.58 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 03:03:30,224 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:03:30,225 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9991, mIoU: 0.8103, mVOE: 0.8934, mASD: 0.7219, mMSSD: 0.7796, mAcc: 0.6607, mFscore: 0.8066, mPrecision: 0.8748, mRecall: 0.7738, mDice: 0.6158, IoU.background: 0.9991, IoU.scratch: 0.7358, IoU.stain: 0.7037, IoU.edgeDamage: 0.8026, VOE.background: 0.7046, VOE.scratch: 0.9679, VOE.stain: 1.0000, VOE.edgeDamage: 0.9011, ASD.background: 0.7068, ASD.scratch: 0.7331, ASD.stain: nan, ASD.edgeDamage: 0.7259, MSSD.background: 0.7039, MSSD.scratch: 0.8353, MSSD.stain: nan, MSSD.edgeDamage: 0.7994, Acc.background: 0.9990, Acc.scratch: 0.4076, Acc.stain: 0.3333, Acc.edgeDamage: 0.9030, Fscore.background: 0.9993, Fscore.scratch: 0.6426, Fscore.stain: nan, Fscore.edgeDamage: 0.7780, Precision.background: 0.9993, Precision.scratch: 0.9122, Precision.stain: nan, Precision.edgeDamage: 0.7129, Recall.background: 0.9993, Recall.scratch: 0.6051, Recall.stain: 0.5556, Recall.edgeDamage: 0.9353, Dice.background: 0.9990, Dice.scratch: 0.4638, Dice.stain: 0.3333, Dice.edgeDamage: 0.6671
2023-11-21 03:04:01,049 - mmseg - INFO - Iter [3050/5000]	lr: 4.858e-05, eta: 0:22:27, time: 1.165, data_time: 0.552, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.8026, decode.acc_seg: 99.7003, loss: 0.8041
2023-11-21 03:04:32,106 - mmseg - INFO - Iter [3100/5000]	lr: 4.769e-05, eta: 0:21:50, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7838, decode.acc_seg: 99.7445, loss: 0.7851
2023-11-21 03:05:05,576 - mmseg - INFO - Iter [3150/5000]	lr: 4.680e-05, eta: 0:21:15, time: 0.669, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7550, decode.acc_seg: 99.7217, loss: 0.7564
2023-11-21 03:05:36,706 - mmseg - INFO - Iter [3200/5000]	lr: 4.590e-05, eta: 0:20:39, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7641, decode.acc_seg: 99.6988, loss: 0.7655
2023-11-21 03:06:07,858 - mmseg - INFO - Iter [3250/5000]	lr: 4.500e-05, eta: 0:20:02, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7817, decode.acc_seg: 99.7148, loss: 0.7832
2023-11-21 03:06:41,386 - mmseg - INFO - Iter [3300/5000]	lr: 4.410e-05, eta: 0:19:28, time: 0.671, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.8046, decode.acc_seg: 99.7346, loss: 0.8059
2023-11-21 03:07:12,560 - mmseg - INFO - Iter [3350/5000]	lr: 4.320e-05, eta: 0:18:52, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7702, decode.acc_seg: 99.7145, loss: 0.7717
2023-11-21 03:07:43,772 - mmseg - INFO - Iter [3400/5000]	lr: 4.229e-05, eta: 0:18:16, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.7431, decode.acc_seg: 99.6796, loss: 0.7448
2023-11-21 03:08:17,304 - mmseg - INFO - Iter [3450/5000]	lr: 4.138e-05, eta: 0:17:41, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7857, decode.acc_seg: 99.7509, loss: 0.7870
2023-11-21 03:08:48,491 - mmseg - INFO - Iter [3500/5000]	lr: 4.047e-05, eta: 0:17:06, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7423, decode.acc_seg: 99.7215, loss: 0.7438
2023-11-21 03:09:15,938 - mmseg - INFO - per class results:
2023-11-21 03:09:15,939 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.89 | 70.48 | 70.68 | 70.41 | 99.83 | 99.92  |   99.94   | 99.89  | 99.87 |
|  scratch   | 76.24 | 94.13 | 73.01 | 82.05 | 47.44 | 70.26  |   89.23   | 64.96  | 55.39 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage |  78.1 | 92.27 | 72.85 | 81.24 | 94.97 | 73.95  |   67.41   | 96.64  | 60.93 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 03:09:15,939 - mmseg - INFO - Summary:
2023-11-21 03:09:15,940 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.89 | 81.15 | 89.22 | 72.18 |  77.9 | 68.89 |  81.37  |   85.53    |  79.26  | 62.38 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 03:09:15,953 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9989, mIoU: 0.8115, mVOE: 0.8922, mASD: 0.7218, mMSSD: 0.7790, mAcc: 0.6889, mFscore: 0.8137, mPrecision: 0.8553, mRecall: 0.7926, mDice: 0.6238, IoU.background: 0.9989, IoU.scratch: 0.7624, IoU.stain: 0.7037, IoU.edgeDamage: 0.7810, VOE.background: 0.7048, VOE.scratch: 0.9413, VOE.stain: 1.0000, VOE.edgeDamage: 0.9227, ASD.background: 0.7068, ASD.scratch: 0.7301, ASD.stain: nan, ASD.edgeDamage: 0.7285, MSSD.background: 0.7041, MSSD.scratch: 0.8205, MSSD.stain: nan, MSSD.edgeDamage: 0.8124, Acc.background: 0.9983, Acc.scratch: 0.4744, Acc.stain: 0.3333, Acc.edgeDamage: 0.9497, Fscore.background: 0.9992, Fscore.scratch: 0.7026, Fscore.stain: nan, Fscore.edgeDamage: 0.7395, Precision.background: 0.9994, Precision.scratch: 0.8923, Precision.stain: nan, Precision.edgeDamage: 0.6741, Recall.background: 0.9989, Recall.scratch: 0.6496, Recall.stain: 0.5556, Recall.edgeDamage: 0.9664, Dice.background: 0.9987, Dice.scratch: 0.5539, Dice.stain: 0.3333, Dice.edgeDamage: 0.6093
2023-11-21 03:09:46,881 - mmseg - INFO - Iter [3550/5000]	lr: 3.956e-05, eta: 0:16:41, time: 1.168, data_time: 0.552, memory: 11840, decode.loss_focal: 0.0017, decode.loss_dice: 0.7687, decode.acc_seg: 99.6984, loss: 0.7705
2023-11-21 03:10:20,381 - mmseg - INFO - Iter [3600/5000]	lr: 3.864e-05, eta: 0:16:07, time: 0.670, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7588, decode.acc_seg: 99.7408, loss: 0.7603
2023-11-21 03:10:51,583 - mmseg - INFO - Iter [3650/5000]	lr: 3.772e-05, eta: 0:15:31, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7962, decode.acc_seg: 99.7141, loss: 0.7976
2023-11-21 03:11:22,816 - mmseg - INFO - Iter [3700/5000]	lr: 3.679e-05, eta: 0:14:55, time: 0.625, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7377, decode.acc_seg: 99.7409, loss: 0.7390
2023-11-21 03:11:56,388 - mmseg - INFO - Iter [3750/5000]	lr: 3.586e-05, eta: 0:14:20, time: 0.671, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7260, decode.acc_seg: 99.7414, loss: 0.7274
2023-11-21 03:12:27,621 - mmseg - INFO - Iter [3800/5000]	lr: 3.493e-05, eta: 0:13:45, time: 0.625, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7385, decode.acc_seg: 99.7313, loss: 0.7400
2023-11-21 03:12:58,878 - mmseg - INFO - Iter [3850/5000]	lr: 3.400e-05, eta: 0:13:10, time: 0.625, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7706, decode.acc_seg: 99.7504, loss: 0.7718
2023-11-21 03:13:32,532 - mmseg - INFO - Iter [3900/5000]	lr: 3.306e-05, eta: 0:12:35, time: 0.673, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0016, decode.loss_dice: 0.7754, decode.acc_seg: 99.6724, loss: 0.7770
2023-11-21 03:14:03,721 - mmseg - INFO - Iter [3950/5000]	lr: 3.211e-05, eta: 0:12:00, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7716, decode.acc_seg: 99.7114, loss: 0.7731
2023-11-21 03:14:34,929 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:14:34,930 - mmseg - INFO - Iter [4000/5000]	lr: 3.116e-05, eta: 0:11:25, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7458, decode.acc_seg: 99.7400, loss: 0.7471
2023-11-21 03:15:02,550 - mmseg - INFO - per class results:
2023-11-21 03:15:02,551 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background |  99.9 | 70.47 | 70.68 |  70.4 | 99.85 | 99.92  |   99.94   |  99.9  | 99.88 |
|  scratch   | 76.18 | 94.19 | 73.01 | 82.07 | 47.34 | 70.12  |   88.62   | 64.89  | 55.18 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 78.85 | 91.52 | 72.77 | 80.85 | 95.13 | 75.34  |   68.57   | 96.75  | 63.01 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 03:15:02,551 - mmseg - INFO - Summary:
2023-11-21 03:15:02,551 - mmseg - INFO - 
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.9 | 81.32 | 89.05 | 72.15 | 77.77 | 68.91 |  81.79  |   85.71    |  79.28  | 62.85 |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 03:15:02,564 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:15:02,564 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9990, mIoU: 0.8132, mVOE: 0.8905, mASD: 0.7215, mMSSD: 0.7777, mAcc: 0.6891, mFscore: 0.8179, mPrecision: 0.8571, mRecall: 0.7928, mDice: 0.6285, IoU.background: 0.9990, IoU.scratch: 0.7618, IoU.stain: 0.7037, IoU.edgeDamage: 0.7885, VOE.background: 0.7047, VOE.scratch: 0.9419, VOE.stain: 1.0000, VOE.edgeDamage: 0.9152, ASD.background: 0.7068, ASD.scratch: 0.7301, ASD.stain: nan, ASD.edgeDamage: 0.7277, MSSD.background: 0.7040, MSSD.scratch: 0.8207, MSSD.stain: nan, MSSD.edgeDamage: 0.8085, Acc.background: 0.9985, Acc.scratch: 0.4734, Acc.stain: 0.3333, Acc.edgeDamage: 0.9513, Fscore.background: 0.9992, Fscore.scratch: 0.7012, Fscore.stain: nan, Fscore.edgeDamage: 0.7534, Precision.background: 0.9994, Precision.scratch: 0.8862, Precision.stain: nan, Precision.edgeDamage: 0.6857, Recall.background: 0.9990, Recall.scratch: 0.6489, Recall.stain: 0.5556, Recall.edgeDamage: 0.9675, Dice.background: 0.9988, Dice.scratch: 0.5518, Dice.stain: 0.3333, Dice.edgeDamage: 0.6301
2023-11-21 03:15:35,850 - mmseg - INFO - Iter [4050/5000]	lr: 3.021e-05, eta: 0:10:57, time: 1.218, data_time: 0.603, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7659, decode.acc_seg: 99.7303, loss: 0.7672
2023-11-21 03:16:06,990 - mmseg - INFO - Iter [4100/5000]	lr: 2.925e-05, eta: 0:10:21, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0016, decode.loss_dice: 0.7298, decode.acc_seg: 99.7086, loss: 0.7314
2023-11-21 03:16:38,187 - mmseg - INFO - Iter [4150/5000]	lr: 2.829e-05, eta: 0:09:46, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7579, decode.acc_seg: 99.7411, loss: 0.7592
2023-11-21 03:17:11,812 - mmseg - INFO - Iter [4200/5000]	lr: 2.732e-05, eta: 0:09:12, time: 0.672, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.8051, decode.acc_seg: 99.7463, loss: 0.8064
2023-11-21 03:17:43,027 - mmseg - INFO - Iter [4250/5000]	lr: 2.634e-05, eta: 0:08:36, time: 0.624, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7510, decode.acc_seg: 99.7586, loss: 0.7522
2023-11-21 03:18:14,259 - mmseg - INFO - Iter [4300/5000]	lr: 2.536e-05, eta: 0:08:01, time: 0.625, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7323, decode.acc_seg: 99.7290, loss: 0.7336
2023-11-21 03:18:47,854 - mmseg - INFO - Iter [4350/5000]	lr: 2.437e-05, eta: 0:07:27, time: 0.672, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7793, decode.acc_seg: 99.6965, loss: 0.7808
2023-11-21 03:19:19,005 - mmseg - INFO - Iter [4400/5000]	lr: 2.337e-05, eta: 0:06:52, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7447, decode.acc_seg: 99.7288, loss: 0.7459
2023-11-21 03:19:50,163 - mmseg - INFO - Iter [4450/5000]	lr: 2.237e-05, eta: 0:06:17, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7656, decode.acc_seg: 99.7481, loss: 0.7668
2023-11-21 03:20:23,650 - mmseg - INFO - Iter [4500/5000]	lr: 2.135e-05, eta: 0:05:43, time: 0.670, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7123, decode.acc_seg: 99.7517, loss: 0.7137
2023-11-21 03:20:50,946 - mmseg - INFO - per class results:
2023-11-21 03:20:50,947 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.84 | 70.54 | 70.69 | 70.43 | 99.72 | 99.88  |   99.94   | 99.81  | 99.81 |
|  scratch   | 74.78 | 95.59 | 73.18 | 82.88 |  43.7 | 67.07  |   90.07   | 62.46  |  50.6 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 75.55 | 94.82 | 73.11 | 82.56 |  95.5 | 68.79  |   63.43   |  97.0  | 53.18 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 03:20:50,947 - mmseg - INFO - Summary:
2023-11-21 03:20:50,947 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.84 | 80.13 | 90.24 | 72.32 | 78.63 | 68.06 |  78.58  |   84.48    |  78.71  | 59.23 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 03:20:50,961 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9984, mIoU: 0.8013, mVOE: 0.9024, mASD: 0.7232, mMSSD: 0.7863, mAcc: 0.6806, mFscore: 0.7858, mPrecision: 0.8448, mRecall: 0.7871, mDice: 0.5923, IoU.background: 0.9984, IoU.scratch: 0.7478, IoU.stain: 0.7037, IoU.edgeDamage: 0.7555, VOE.background: 0.7054, VOE.scratch: 0.9559, VOE.stain: 1.0000, VOE.edgeDamage: 0.9482, ASD.background: 0.7069, ASD.scratch: 0.7318, ASD.stain: nan, ASD.edgeDamage: 0.7311, MSSD.background: 0.7043, MSSD.scratch: 0.8288, MSSD.stain: nan, MSSD.edgeDamage: 0.8256, Acc.background: 0.9972, Acc.scratch: 0.4370, Acc.stain: 0.3333, Acc.edgeDamage: 0.9550, Fscore.background: 0.9988, Fscore.scratch: 0.6707, Fscore.stain: nan, Fscore.edgeDamage: 0.6879, Precision.background: 0.9994, Precision.scratch: 0.9007, Precision.stain: nan, Precision.edgeDamage: 0.6343, Recall.background: 0.9981, Recall.scratch: 0.6246, Recall.stain: 0.5556, Recall.edgeDamage: 0.9700, Dice.background: 0.9981, Dice.scratch: 0.5060, Dice.stain: 0.3333, Dice.edgeDamage: 0.5318
2023-11-21 03:21:21,764 - mmseg - INFO - Iter [4550/5000]	lr: 2.033e-05, eta: 0:05:11, time: 1.162, data_time: 0.549, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7588, decode.acc_seg: 99.7277, loss: 0.7602
2023-11-21 03:21:52,795 - mmseg - INFO - Iter [4600/5000]	lr: 1.929e-05, eta: 0:04:36, time: 0.621, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7595, decode.acc_seg: 99.7071, loss: 0.7609
2023-11-21 03:22:23,875 - mmseg - INFO - Iter [4650/5000]	lr: 1.824e-05, eta: 0:04:01, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0013, decode.loss_dice: 0.7226, decode.acc_seg: 99.7494, loss: 0.7239
2023-11-21 03:22:57,356 - mmseg - INFO - Iter [4700/5000]	lr: 1.718e-05, eta: 0:03:27, time: 0.670, data_time: 0.051, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7559, decode.acc_seg: 99.7490, loss: 0.7571
2023-11-21 03:23:28,461 - mmseg - INFO - Iter [4750/5000]	lr: 1.609e-05, eta: 0:02:52, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7461, decode.acc_seg: 99.7350, loss: 0.7472
2023-11-21 03:23:59,572 - mmseg - INFO - Iter [4800/5000]	lr: 1.499e-05, eta: 0:02:17, time: 0.622, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7308, decode.acc_seg: 99.7232, loss: 0.7322
2023-11-21 03:24:33,024 - mmseg - INFO - Iter [4850/5000]	lr: 1.386e-05, eta: 0:01:43, time: 0.669, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0012, decode.loss_dice: 0.7522, decode.acc_seg: 99.7580, loss: 0.7534
2023-11-21 03:25:04,160 - mmseg - INFO - Iter [4900/5000]	lr: 1.269e-05, eta: 0:01:08, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7544, decode.acc_seg: 99.7148, loss: 0.7558
2023-11-21 03:25:35,326 - mmseg - INFO - Iter [4950/5000]	lr: 1.145e-05, eta: 0:00:34, time: 0.623, data_time: 0.003, memory: 11840, decode.loss_focal: 0.0015, decode.loss_dice: 0.7515, decode.acc_seg: 99.7078, loss: 0.7529
2023-11-21 03:26:08,853 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-11-21 03:26:09,218 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:26:09,218 - mmseg - INFO - Iter [5000/5000]	lr: 1.004e-05, eta: 0:00:00, time: 0.678, data_time: 0.050, memory: 11840, decode.loss_focal: 0.0014, decode.loss_dice: 0.7584, decode.acc_seg: 99.7051, loss: 0.7599
2023-11-21 03:26:36,378 - mmseg - INFO - per class results:
2023-11-21 03:26:36,379 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 70.68 | 70.41 | 99.83 | 99.91  |   99.94   | 99.89  | 99.87 |
|  scratch   | 74.04 | 96.33 | 73.25 | 83.27 | 41.94 | 65.35  |   88.94   | 61.29  | 48.02 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 77.78 | 92.59 | 72.87 | 81.37 | 93.18 | 73.34  |    67.0   | 95.46  | 60.01 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-21 03:26:36,379 - mmseg - INFO - Summary:
2023-11-21 03:26:36,380 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.88 | 80.52 | 89.85 | 72.27 | 78.35 | 67.07 |  79.53  |   85.29    |  78.05  | 60.31 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-21 03:26:36,393 - mmseg - INFO - Exp name: unet_all.py
2023-11-21 03:26:36,393 - mmseg - INFO - Iter(val) [117]	aAcc: 0.9988, mIoU: 0.8052, mVOE: 0.8985, mASD: 0.7227, mMSSD: 0.7835, mAcc: 0.6707, mFscore: 0.7953, mPrecision: 0.8529, mRecall: 0.7805, mDice: 0.6031, IoU.background: 0.9988, IoU.scratch: 0.7404, IoU.stain: 0.7037, IoU.edgeDamage: 0.7778, VOE.background: 0.7049, VOE.scratch: 0.9633, VOE.stain: 1.0000, VOE.edgeDamage: 0.9259, ASD.background: 0.7068, ASD.scratch: 0.7325, ASD.stain: nan, ASD.edgeDamage: 0.7287, MSSD.background: 0.7041, MSSD.scratch: 0.8327, MSSD.stain: nan, MSSD.edgeDamage: 0.8137, Acc.background: 0.9983, Acc.scratch: 0.4194, Acc.stain: 0.3333, Acc.edgeDamage: 0.9318, Fscore.background: 0.9991, Fscore.scratch: 0.6535, Fscore.stain: nan, Fscore.edgeDamage: 0.7334, Precision.background: 0.9994, Precision.scratch: 0.8894, Precision.stain: nan, Precision.edgeDamage: 0.6700, Recall.background: 0.9989, Recall.scratch: 0.6129, Recall.stain: 0.5556, Recall.edgeDamage: 0.9546, Dice.background: 0.9987, Dice.scratch: 0.4802, Dice.stain: 0.3333, Dice.edgeDamage: 0.6001
