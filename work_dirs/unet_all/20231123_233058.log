2023-11-23 23:30:58,518 - mmseg - INFO - Multi-processing start method is `None`
2023-11-23 23:30:58,520 - mmseg - INFO - OpenCV num_threads is `6
2023-11-23 23:30:58,564 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /environment/miniconda3
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.1
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.1+
------------------------------------------------------------

2023-11-23 23:30:58,564 - mmseg - INFO - Distributed training: False
2023-11-23 23:30:58,852 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='UnetBackbone',
        in_channels=3,
        context_layer='seLayer',
        channel_list=[64, 128, 256, 512]),
    decode_head=dict(
        type='UnetHead',
        num_classes=4,
        channels=64,
        threshold=0.2,
        norm_cfg=dict(type='BN', requires_grad=True),
        loss_decode=[
            dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                class_weight=[0.1, 0.5, 0.2, 0.2],
                loss_weight=2.0),
            dict(
                type='DiceLoss',
                loss_name='loss_dice',
                class_weight=[0.1, 0.5, 0.2, 0.2],
                loss_weight=2.0)
        ]))
train_cfg = dict()
test_cfg = dict(mode='whole')
dataset_type = 'MyDataset'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(600, 600)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=False),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data_root = './datasets/'
data = dict(
    samples_per_gpu=5,
    workers_per_gpu=2,
    train=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='train/images',
        ann_dir='train/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(600, 600)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TensorboardLoggerHook'),
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = False
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.999))
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=1e-05, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, save_optimizer=False, interval=5000)
evaluation = dict(interval=500, metric=['mIoU', 'mFscore', 'mDice'])
work_dir = './work_dirs/unet_all'
gpu_ids = [0]
auto_resume = False

2023-11-23 23:30:58,853 - mmseg - INFO - Set random seed to 1149932442, deterministic: False
2023-11-23 23:30:59,002 - mmseg - INFO - initialize UnetHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.inc.conv.conv.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.weight - torch.Size([16, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.0.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.weight - torch.Size([64, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer1_1.fc.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.weight - torch.Size([32, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.weight - torch.Size([128, 32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer2_1.fc.2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer3_1.fc.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.weight - torch.Size([512, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.context_layer4_1.fc.2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([4, 64, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.up1.atrous_conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.atrous_conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.weight - torch.Size([256, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.atrous_conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.atrous_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.weight - torch.Size([128, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.atrous_conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.atrous_conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.atrous_conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.atrous_conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-11-23 23:30:59,008 - mmseg - INFO - EncoderDecoder(
  (backbone): UnetBackbone(
    (inc): InConv(
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (down1): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down3): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (down4): Down(
      (down_conv): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): DoubleConv(
          (conv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
    )
    (context_layer1_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=64, out_features=16, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=16, out_features=64, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer2_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer3_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=64, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=64, out_features=256, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (context_layer4_1): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=512, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=512, bias=True)
        (3): Hswish(
          (relu): ReLU6(inplace=True)
        )
      )
    )
  )
  (decode_head): UnetHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): FocalLoss()
      (1): DiceLoss()
    )
    (conv_seg): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (up1): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up3): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up4): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-23 23:30:59,018 - mmseg - INFO - Loaded 474 images
2023-11-23 23:31:06,472 - mmseg - INFO - Loaded 105 images
2023-11-23 23:31:06,472 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/work/test/work_dirs/unet_all
2023-11-23 23:31:06,473 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-23 23:31:06,473 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-11-23 23:31:06,473 - mmseg - INFO - Checkpoints will be saved to /home/featurize/work/test/work_dirs/unet_all by HardDiskBackend.
2023-11-23 23:31:40,531 - mmseg - INFO - Iter [50/10000]	lr: 9.960e-05, eta: 1:51:45, time: 0.674, data_time: 0.387, memory: 7767, decode.loss_focal: 0.0484, decode.loss_dice: 0.4672, decode.acc_seg: 94.2831, loss: 0.5156
2023-11-23 23:32:12,368 - mmseg - INFO - Iter [100/10000]	lr: 9.920e-05, eta: 1:48:07, time: 0.637, data_time: 0.388, memory: 7767, decode.loss_focal: 0.0367, decode.loss_dice: 0.4617, decode.acc_seg: 99.3083, loss: 0.4984
2023-11-23 23:32:27,585 - mmseg - INFO - Iter [150/10000]	lr: 9.879e-05, eta: 1:28:22, time: 0.304, data_time: 0.007, memory: 7767, decode.loss_focal: 0.0278, decode.loss_dice: 0.4543, decode.acc_seg: 98.8838, loss: 0.4821
2023-11-23 23:32:45,544 - mmseg - INFO - Iter [200/10000]	lr: 9.839e-05, eta: 1:20:36, time: 0.359, data_time: 0.066, memory: 7767, decode.loss_focal: 0.0208, decode.loss_dice: 0.4463, decode.acc_seg: 98.7057, loss: 0.4671
2023-11-23 23:33:00,758 - mmseg - INFO - Iter [250/10000]	lr: 9.798e-05, eta: 1:14:02, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0160, decode.loss_dice: 0.4360, decode.acc_seg: 98.8774, loss: 0.4520
2023-11-23 23:33:18,638 - mmseg - INFO - Iter [300/10000]	lr: 9.757e-05, eta: 1:11:01, time: 0.358, data_time: 0.062, memory: 7767, decode.loss_focal: 0.0122, decode.loss_dice: 0.4264, decode.acc_seg: 99.0293, loss: 0.4387
2023-11-23 23:33:33,873 - mmseg - INFO - Iter [350/10000]	lr: 9.717e-05, eta: 1:07:34, time: 0.305, data_time: 0.007, memory: 7767, decode.loss_focal: 0.0097, decode.loss_dice: 0.4096, decode.acc_seg: 99.1657, loss: 0.4193
2023-11-23 23:33:51,573 - mmseg - INFO - Iter [400/10000]	lr: 9.676e-05, eta: 1:05:53, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0074, decode.loss_dice: 0.3934, decode.acc_seg: 99.3588, loss: 0.4008
2023-11-23 23:34:06,760 - mmseg - INFO - Iter [450/10000]	lr: 9.635e-05, eta: 1:03:38, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0057, decode.loss_dice: 0.3772, decode.acc_seg: 99.4251, loss: 0.3829
2023-11-23 23:34:24,567 - mmseg - INFO - Iter [500/10000]	lr: 9.595e-05, eta: 1:02:36, time: 0.356, data_time: 0.065, memory: 7767, decode.loss_focal: 0.0046, decode.loss_dice: 0.3576, decode.acc_seg: 99.5106, loss: 0.3621
2023-11-23 23:34:54,072 - mmseg - INFO - per class results:
2023-11-23 23:34:54,073 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background |  99.7 | 70.67 | 72.21 | 70.49 | 99.46 | 99.77  |   99.91   | 99.64  | 99.66 |
|  scratch   | 78.42 | 91.95 | 74.03 | 79.61 |  58.4 | 74.54  |   77.53   | 72.27  | 61.81 |
|   stain    | 70.37 | 100.0 |  nan  |  nan  | 33.33 |  nan   |    nan    | 55.56  | 33.33 |
| edgeDamage | 74.35 | 96.02 | 74.74 | 83.16 | 93.35 | 66.08  |   61.62   | 95.57  | 49.12 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:34:54,073 - mmseg - INFO - Summary:
2023-11-23 23:34:54,074 - mmseg - INFO - 
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.7 | 80.71 | 89.66 | 73.66 | 77.76 | 71.14 |  80.13  |   79.69    |  80.76  | 60.98 |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:34:54,093 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9970, mIoU: 0.8071, mVOE: 0.8966, mASD: 0.7366, mMSSD: 0.7776, mAcc: 0.7114, mFscore: 0.8013, mPrecision: 0.7969, mRecall: 0.8076, mDice: 0.6098, IoU.background: 0.9970, IoU.scratch: 0.7842, IoU.stain: 0.7037, IoU.edgeDamage: 0.7435, VOE.background: 0.7067, VOE.scratch: 0.9195, VOE.stain: 1.0000, VOE.edgeDamage: 0.9602, ASD.background: 0.7221, ASD.scratch: 0.7403, ASD.stain: nan, ASD.edgeDamage: 0.7474, MSSD.background: 0.7049, MSSD.scratch: 0.7961, MSSD.stain: nan, MSSD.edgeDamage: 0.8316, Acc.background: 0.9946, Acc.scratch: 0.5840, Acc.stain: 0.3333, Acc.edgeDamage: 0.9335, Fscore.background: 0.9977, Fscore.scratch: 0.7454, Fscore.stain: nan, Fscore.edgeDamage: 0.6608, Precision.background: 0.9991, Precision.scratch: 0.7753, Precision.stain: nan, Precision.edgeDamage: 0.6162, Recall.background: 0.9964, Recall.scratch: 0.7227, Recall.stain: 0.5556, Recall.edgeDamage: 0.9557, Dice.background: 0.9966, Dice.scratch: 0.6181, Dice.stain: 0.3333, Dice.edgeDamage: 0.4912
2023-11-23 23:35:09,318 - mmseg - INFO - Iter [550/10000]	lr: 9.554e-05, eta: 1:09:26, time: 0.895, data_time: 0.596, memory: 7767, decode.loss_focal: 0.0038, decode.loss_dice: 0.3486, decode.acc_seg: 99.5754, loss: 0.3524
2023-11-23 23:35:26,935 - mmseg - INFO - Iter [600/10000]	lr: 9.513e-05, eta: 1:07:54, time: 0.352, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0032, decode.loss_dice: 0.3449, decode.acc_seg: 99.5383, loss: 0.3481
2023-11-23 23:35:42,137 - mmseg - INFO - Iter [650/10000]	lr: 9.473e-05, eta: 1:06:00, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0027, decode.loss_dice: 0.3310, decode.acc_seg: 99.5457, loss: 0.3338
2023-11-23 23:35:59,972 - mmseg - INFO - Iter [700/10000]	lr: 9.432e-05, eta: 1:04:54, time: 0.357, data_time: 0.067, memory: 7767, decode.loss_focal: 0.0024, decode.loss_dice: 0.3159, decode.acc_seg: 99.5980, loss: 0.3183
2023-11-23 23:36:15,142 - mmseg - INFO - Iter [750/10000]	lr: 9.391e-05, eta: 1:03:22, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0021, decode.loss_dice: 0.3160, decode.acc_seg: 99.5969, loss: 0.3182
2023-11-23 23:36:32,857 - mmseg - INFO - Iter [800/10000]	lr: 9.350e-05, eta: 1:02:29, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0020, decode.loss_dice: 0.3009, decode.acc_seg: 99.5835, loss: 0.3029
2023-11-23 23:36:50,518 - mmseg - INFO - Iter [850/10000]	lr: 9.309e-05, eta: 1:01:39, time: 0.353, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0017, decode.loss_dice: 0.2971, decode.acc_seg: 99.5978, loss: 0.2989
2023-11-23 23:37:05,725 - mmseg - INFO - Iter [900/10000]	lr: 9.268e-05, eta: 1:00:28, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0017, decode.loss_dice: 0.2947, decode.acc_seg: 99.5718, loss: 0.2964
2023-11-23 23:37:23,432 - mmseg - INFO - Iter [950/10000]	lr: 9.228e-05, eta: 0:59:47, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0015, decode.loss_dice: 0.2887, decode.acc_seg: 99.6263, loss: 0.2902
2023-11-23 23:37:38,608 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:37:38,608 - mmseg - INFO - Iter [1000/10000]	lr: 9.187e-05, eta: 0:58:45, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0014, decode.loss_dice: 0.2842, decode.acc_seg: 99.6233, loss: 0.2856
2023-11-23 23:38:01,279 - mmseg - INFO - per class results:
2023-11-23 23:38:01,280 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.92 | 70.45 | 72.19 |  70.4 | 99.95 | 99.94  |   99.92   | 99.96  | 99.91 |
|  scratch   | 80.84 | 89.53 | 73.88 | 78.85 | 61.85 | 78.76  |   85.32   | 74.57  | 68.14 |
|   stain    | 86.34 | 84.03 | 73.46 | 76.72 | 71.43 | 86.68  |   95.75   | 80.95  | 80.02 |
| edgeDamage | 84.91 | 85.46 |  73.3 | 75.93 | 74.97 | 84.82  |    86.5   | 83.31  | 77.23 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:38:01,281 - mmseg - INFO - Summary:
2023-11-23 23:38:01,281 - mmseg - INFO - 
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc | mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.92 | 88.0 | 82.37 | 73.21 | 75.47 | 77.05 |  87.55  |   91.87    |   84.7  | 81.33 |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:38:01,295 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:38:01,295 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9992, mIoU: 0.8800, mVOE: 0.8237, mASD: 0.7321, mMSSD: 0.7547, mAcc: 0.7705, mFscore: 0.8755, mPrecision: 0.9187, mRecall: 0.8470, mDice: 0.8133, IoU.background: 0.9992, IoU.scratch: 0.8084, IoU.stain: 0.8634, IoU.edgeDamage: 0.8491, VOE.background: 0.7045, VOE.scratch: 0.8953, VOE.stain: 0.8403, VOE.edgeDamage: 0.8546, ASD.background: 0.7219, ASD.scratch: 0.7388, ASD.stain: 0.7346, ASD.edgeDamage: 0.7330, MSSD.background: 0.7040, MSSD.scratch: 0.7885, MSSD.stain: 0.7672, MSSD.edgeDamage: 0.7593, Acc.background: 0.9995, Acc.scratch: 0.6185, Acc.stain: 0.7143, Acc.edgeDamage: 0.7497, Fscore.background: 0.9994, Fscore.scratch: 0.7876, Fscore.stain: 0.8668, Fscore.edgeDamage: 0.8482, Precision.background: 0.9992, Precision.scratch: 0.8532, Precision.stain: 0.9575, Precision.edgeDamage: 0.8650, Recall.background: 0.9996, Recall.scratch: 0.7457, Recall.stain: 0.8095, Recall.edgeDamage: 0.8331, Dice.background: 0.9991, Dice.scratch: 0.6814, Dice.stain: 0.8002, Dice.edgeDamage: 0.7723
2023-11-23 23:38:19,021 - mmseg - INFO - Iter [1050/10000]	lr: 9.146e-05, eta: 1:01:23, time: 0.808, data_time: 0.520, memory: 7767, decode.loss_focal: 0.0013, decode.loss_dice: 0.2813, decode.acc_seg: 99.6170, loss: 0.2826
2023-11-23 23:38:34,432 - mmseg - INFO - Iter [1100/10000]	lr: 9.105e-05, eta: 1:00:21, time: 0.308, data_time: 0.023, memory: 7767, decode.loss_focal: 0.0012, decode.loss_dice: 0.2695, decode.acc_seg: 99.6545, loss: 0.2707
2023-11-23 23:38:52,410 - mmseg - INFO - Iter [1150/10000]	lr: 9.064e-05, eta: 0:59:42, time: 0.360, data_time: 0.073, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2651, decode.acc_seg: 99.6756, loss: 0.2662
2023-11-23 23:39:07,588 - mmseg - INFO - Iter [1200/10000]	lr: 9.023e-05, eta: 0:58:45, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2573, decode.acc_seg: 99.6824, loss: 0.2584
2023-11-23 23:39:25,234 - mmseg - INFO - Iter [1250/10000]	lr: 8.982e-05, eta: 0:58:08, time: 0.353, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2514, decode.acc_seg: 99.7079, loss: 0.2524
2023-11-23 23:39:40,415 - mmseg - INFO - Iter [1300/10000]	lr: 8.941e-05, eta: 0:57:16, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2489, decode.acc_seg: 99.6732, loss: 0.2500
2023-11-23 23:39:58,096 - mmseg - INFO - Iter [1350/10000]	lr: 8.900e-05, eta: 0:56:43, time: 0.354, data_time: 0.059, memory: 7767, decode.loss_focal: 0.0012, decode.loss_dice: 0.2441, decode.acc_seg: 99.6227, loss: 0.2452
2023-11-23 23:40:13,262 - mmseg - INFO - Iter [1400/10000]	lr: 8.858e-05, eta: 0:55:56, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2468, decode.acc_seg: 99.6814, loss: 0.2479
2023-11-23 23:40:31,055 - mmseg - INFO - Iter [1450/10000]	lr: 8.817e-05, eta: 0:55:26, time: 0.356, data_time: 0.066, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2499, decode.acc_seg: 99.6338, loss: 0.2510
2023-11-23 23:40:46,268 - mmseg - INFO - Iter [1500/10000]	lr: 8.776e-05, eta: 0:54:43, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2338, decode.acc_seg: 99.6829, loss: 0.2348
2023-11-23 23:41:07,938 - mmseg - INFO - per class results:
2023-11-23 23:41:07,940 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.92 | 70.45 | 72.19 | 70.39 | 99.91 | 99.94  |   99.94   | 99.94  | 99.91 |
|  scratch   | 82.18 | 88.19 | 73.62 | 77.53 |  67.8 | 80.88  |   83.77   | 78.53  | 71.32 |
|   stain    | 87.69 | 82.68 | 73.08 | 74.86 |  79.8 | 88.35  |   90.38   | 86.54  | 82.52 |
| edgeDamage | 85.82 | 84.55 | 73.29 | 75.91 | 83.84 | 86.02  |   83.37   | 89.23  | 79.03 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:41:07,940 - mmseg - INFO - Summary:
2023-11-23 23:41:07,941 - mmseg - INFO - 
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc | mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.92 | 88.9 | 81.47 | 73.05 | 74.67 | 82.84 |   88.8  |   89.36    |  88.56  |  83.2 |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:41:07,959 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9992, mIoU: 0.8890, mVOE: 0.8147, mASD: 0.7305, mMSSD: 0.7467, mAcc: 0.8284, mFscore: 0.8880, mPrecision: 0.8936, mRecall: 0.8856, mDice: 0.8320, IoU.background: 0.9992, IoU.scratch: 0.8218, IoU.stain: 0.8769, IoU.edgeDamage: 0.8582, VOE.background: 0.7045, VOE.scratch: 0.8819, VOE.stain: 0.8268, VOE.edgeDamage: 0.8455, ASD.background: 0.7219, ASD.scratch: 0.7362, ASD.stain: 0.7308, ASD.edgeDamage: 0.7329, MSSD.background: 0.7039, MSSD.scratch: 0.7753, MSSD.stain: 0.7486, MSSD.edgeDamage: 0.7591, Acc.background: 0.9991, Acc.scratch: 0.6780, Acc.stain: 0.7980, Acc.edgeDamage: 0.8384, Fscore.background: 0.9994, Fscore.scratch: 0.8088, Fscore.stain: 0.8835, Fscore.edgeDamage: 0.8602, Precision.background: 0.9994, Precision.scratch: 0.8377, Precision.stain: 0.9038, Precision.edgeDamage: 0.8337, Recall.background: 0.9994, Recall.scratch: 0.7853, Recall.stain: 0.8654, Recall.edgeDamage: 0.8923, Dice.background: 0.9991, Dice.scratch: 0.7132, Dice.stain: 0.8252, Dice.edgeDamage: 0.7903
2023-11-23 23:41:25,674 - mmseg - INFO - Iter [1550/10000]	lr: 8.735e-05, eta: 0:56:13, time: 0.788, data_time: 0.494, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2373, decode.acc_seg: 99.6758, loss: 0.2384
2023-11-23 23:41:43,275 - mmseg - INFO - Iter [1600/10000]	lr: 8.694e-05, eta: 0:55:41, time: 0.352, data_time: 0.056, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2415, decode.acc_seg: 99.6612, loss: 0.2425
2023-11-23 23:41:58,459 - mmseg - INFO - Iter [1650/10000]	lr: 8.653e-05, eta: 0:54:57, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0011, decode.loss_dice: 0.2336, decode.acc_seg: 99.6474, loss: 0.2347
2023-11-23 23:42:16,103 - mmseg - INFO - Iter [1700/10000]	lr: 8.611e-05, eta: 0:54:27, time: 0.353, data_time: 0.059, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2353, decode.acc_seg: 99.6845, loss: 0.2362
2023-11-23 23:42:31,288 - mmseg - INFO - Iter [1750/10000]	lr: 8.570e-05, eta: 0:53:46, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2404, decode.acc_seg: 99.6750, loss: 0.2414
2023-11-23 23:42:49,011 - mmseg - INFO - Iter [1800/10000]	lr: 8.529e-05, eta: 0:53:18, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2284, decode.acc_seg: 99.6683, loss: 0.2294
2023-11-23 23:43:04,205 - mmseg - INFO - Iter [1850/10000]	lr: 8.487e-05, eta: 0:52:40, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2227, decode.acc_seg: 99.6945, loss: 0.2236
2023-11-23 23:43:22,206 - mmseg - INFO - Iter [1900/10000]	lr: 8.446e-05, eta: 0:52:14, time: 0.360, data_time: 0.067, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2255, decode.acc_seg: 99.6488, loss: 0.2265
2023-11-23 23:43:37,386 - mmseg - INFO - Iter [1950/10000]	lr: 8.405e-05, eta: 0:51:38, time: 0.304, data_time: 0.005, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2262, decode.acc_seg: 99.6921, loss: 0.2271
2023-11-23 23:43:55,361 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:43:55,362 - mmseg - INFO - Iter [2000/10000]	lr: 8.363e-05, eta: 0:51:14, time: 0.359, data_time: 0.078, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2254, decode.acc_seg: 99.6678, loss: 0.2264
2023-11-23 23:44:18,849 - mmseg - INFO - per class results:
2023-11-23 23:44:18,850 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.91 | 70.46 | 72.19 |  70.4 | 99.88 | 99.93  |   99.95   | 99.92  |  99.9 |
|  scratch   | 81.83 | 88.54 | 73.59 | 77.38 | 72.82 | 80.35  |   78.98   | 81.88  | 70.52 |
|   stain    | 88.92 | 81.45 | 73.16 | 75.22 | 78.17 | 89.78  |   95.58   | 85.44  | 84.67 |
| edgeDamage | 85.47 |  84.9 | 73.43 | 76.59 | 87.14 | 85.56  |   81.34   | 91.43  | 78.34 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:44:18,850 - mmseg - INFO - Summary:
2023-11-23 23:44:18,851 - mmseg - INFO - 
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD | mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
| 99.91 | 89.03 | 81.34 | 73.09 |  74.9 | 84.5 |   88.9  |   88.96    |  89.67  | 83.36 |
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
2023-11-23 23:44:18,865 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:44:18,865 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9991, mIoU: 0.8903, mVOE: 0.8134, mASD: 0.7309, mMSSD: 0.7490, mAcc: 0.8450, mFscore: 0.8890, mPrecision: 0.8896, mRecall: 0.8967, mDice: 0.8336, IoU.background: 0.9991, IoU.scratch: 0.8183, IoU.stain: 0.8892, IoU.edgeDamage: 0.8547, VOE.background: 0.7046, VOE.scratch: 0.8854, VOE.stain: 0.8145, VOE.edgeDamage: 0.8490, ASD.background: 0.7219, ASD.scratch: 0.7359, ASD.stain: 0.7316, ASD.edgeDamage: 0.7343, MSSD.background: 0.7040, MSSD.scratch: 0.7738, MSSD.stain: 0.7522, MSSD.edgeDamage: 0.7659, Acc.background: 0.9988, Acc.scratch: 0.7282, Acc.stain: 0.7817, Acc.edgeDamage: 0.8714, Fscore.background: 0.9993, Fscore.scratch: 0.8035, Fscore.stain: 0.8978, Fscore.edgeDamage: 0.8556, Precision.background: 0.9995, Precision.scratch: 0.7898, Precision.stain: 0.9558, Precision.edgeDamage: 0.8134, Recall.background: 0.9992, Recall.scratch: 0.8188, Recall.stain: 0.8544, Recall.edgeDamage: 0.9143, Dice.background: 0.9990, Dice.scratch: 0.7052, Dice.stain: 0.8467, Dice.edgeDamage: 0.7834
2023-11-23 23:44:33,994 - mmseg - INFO - Iter [2050/10000]	lr: 8.322e-05, eta: 0:52:10, time: 0.773, data_time: 0.476, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2214, decode.acc_seg: 99.6691, loss: 0.2224
2023-11-23 23:44:51,653 - mmseg - INFO - Iter [2100/10000]	lr: 8.280e-05, eta: 0:51:42, time: 0.353, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2193, decode.acc_seg: 99.7171, loss: 0.2202
2023-11-23 23:45:06,806 - mmseg - INFO - Iter [2150/10000]	lr: 8.239e-05, eta: 0:51:06, time: 0.303, data_time: 0.005, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2216, decode.acc_seg: 99.6418, loss: 0.2226
2023-11-23 23:45:24,512 - mmseg - INFO - Iter [2200/10000]	lr: 8.197e-05, eta: 0:50:40, time: 0.354, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2330, decode.acc_seg: 99.6774, loss: 0.2339
2023-11-23 23:45:39,749 - mmseg - INFO - Iter [2250/10000]	lr: 8.156e-05, eta: 0:50:06, time: 0.305, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2276, decode.acc_seg: 99.6849, loss: 0.2286
2023-11-23 23:45:57,659 - mmseg - INFO - Iter [2300/10000]	lr: 8.114e-05, eta: 0:49:42, time: 0.358, data_time: 0.070, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2264, decode.acc_seg: 99.6825, loss: 0.2274
2023-11-23 23:46:12,872 - mmseg - INFO - Iter [2350/10000]	lr: 8.073e-05, eta: 0:49:09, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2200, decode.acc_seg: 99.6578, loss: 0.2210
2023-11-23 23:46:30,648 - mmseg - INFO - Iter [2400/10000]	lr: 8.031e-05, eta: 0:48:45, time: 0.356, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2221, decode.acc_seg: 99.7009, loss: 0.2229
2023-11-23 23:46:48,397 - mmseg - INFO - Iter [2450/10000]	lr: 7.990e-05, eta: 0:48:21, time: 0.355, data_time: 0.062, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2149, decode.acc_seg: 99.6753, loss: 0.2158
2023-11-23 23:47:03,594 - mmseg - INFO - Iter [2500/10000]	lr: 7.948e-05, eta: 0:47:50, time: 0.304, data_time: 0.011, memory: 7767, decode.loss_focal: 0.0010, decode.loss_dice: 0.2246, decode.acc_seg: 99.6394, loss: 0.2256
2023-11-23 23:47:25,203 - mmseg - INFO - per class results:
2023-11-23 23:47:25,204 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.91 | 70.46 | 72.19 | 70.39 | 99.91 | 99.94  |   99.93   | 99.94  |  99.9 |
|  scratch   | 81.59 | 88.78 | 73.78 | 78.33 | 64.16 | 79.96  |   85.59   | 76.11  | 69.94 |
|   stain    | 89.32 | 81.05 | 72.98 | 74.37 | 82.02 | 90.23  |   92.78   | 88.01  | 85.35 |
| edgeDamage |  84.0 | 86.37 | 73.58 | 77.36 | 85.33 | 83.56  |   79.04   | 90.22  | 75.34 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:47:25,204 - mmseg - INFO - Summary:
2023-11-23 23:47:25,205 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.91 | 88.71 | 81.66 | 73.13 | 75.11 | 82.85 |  88.42  |   89.34    |  88.57  | 82.63 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:47:25,223 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9991, mIoU: 0.8871, mVOE: 0.8166, mASD: 0.7313, mMSSD: 0.7511, mAcc: 0.8285, mFscore: 0.8842, mPrecision: 0.8934, mRecall: 0.8857, mDice: 0.8263, IoU.background: 0.9991, IoU.scratch: 0.8159, IoU.stain: 0.8932, IoU.edgeDamage: 0.8400, VOE.background: 0.7046, VOE.scratch: 0.8878, VOE.stain: 0.8105, VOE.edgeDamage: 0.8637, ASD.background: 0.7219, ASD.scratch: 0.7378, ASD.stain: 0.7298, ASD.edgeDamage: 0.7358, MSSD.background: 0.7039, MSSD.scratch: 0.7833, MSSD.stain: 0.7437, MSSD.edgeDamage: 0.7736, Acc.background: 0.9991, Acc.scratch: 0.6416, Acc.stain: 0.8202, Acc.edgeDamage: 0.8533, Fscore.background: 0.9994, Fscore.scratch: 0.7996, Fscore.stain: 0.9023, Fscore.edgeDamage: 0.8356, Precision.background: 0.9993, Precision.scratch: 0.8559, Precision.stain: 0.9278, Precision.edgeDamage: 0.7904, Recall.background: 0.9994, Recall.scratch: 0.7611, Recall.stain: 0.8801, Recall.edgeDamage: 0.9022, Dice.background: 0.9990, Dice.scratch: 0.6994, Dice.stain: 0.8535, Dice.edgeDamage: 0.7534
2023-11-23 23:47:43,138 - mmseg - INFO - Iter [2550/10000]	lr: 7.906e-05, eta: 0:48:30, time: 0.791, data_time: 0.498, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2181, decode.acc_seg: 99.6919, loss: 0.2190
2023-11-23 23:47:58,328 - mmseg - INFO - Iter [2600/10000]	lr: 7.864e-05, eta: 0:47:58, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2280, decode.acc_seg: 99.6765, loss: 0.2289
2023-11-23 23:48:16,160 - mmseg - INFO - Iter [2650/10000]	lr: 7.823e-05, eta: 0:47:34, time: 0.357, data_time: 0.065, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2263, decode.acc_seg: 99.6823, loss: 0.2272
2023-11-23 23:48:31,352 - mmseg - INFO - Iter [2700/10000]	lr: 7.781e-05, eta: 0:47:03, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2142, decode.acc_seg: 99.6905, loss: 0.2151
2023-11-23 23:48:49,040 - mmseg - INFO - Iter [2750/10000]	lr: 7.739e-05, eta: 0:46:40, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2331, decode.acc_seg: 99.6764, loss: 0.2339
2023-11-23 23:49:04,253 - mmseg - INFO - Iter [2800/10000]	lr: 7.697e-05, eta: 0:46:10, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2291, decode.acc_seg: 99.6645, loss: 0.2300
2023-11-23 23:49:22,003 - mmseg - INFO - Iter [2850/10000]	lr: 7.655e-05, eta: 0:45:47, time: 0.355, data_time: 0.059, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2254, decode.acc_seg: 99.6763, loss: 0.2263
2023-11-23 23:49:37,247 - mmseg - INFO - Iter [2900/10000]	lr: 7.613e-05, eta: 0:45:18, time: 0.305, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2120, decode.acc_seg: 99.6826, loss: 0.2130
2023-11-23 23:49:55,048 - mmseg - INFO - Iter [2950/10000]	lr: 7.572e-05, eta: 0:44:56, time: 0.356, data_time: 0.061, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2260, decode.acc_seg: 99.6662, loss: 0.2270
2023-11-23 23:50:10,240 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:50:10,240 - mmseg - INFO - Iter [3000/10000]	lr: 7.530e-05, eta: 0:44:27, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2085, decode.acc_seg: 99.6928, loss: 0.2093
2023-11-23 23:50:31,323 - mmseg - INFO - per class results:
2023-11-23 23:50:31,324 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.91 | 70.46 | 72.19 | 70.39 | 99.89 | 99.93  |   99.94   | 99.93  |  99.9 |
|  scratch   | 82.44 | 87.93 | 73.64 | 77.63 | 67.32 | 81.29  |   85.33   | 78.21  | 71.93 |
|   stain    | 87.15 | 83.22 | 73.36 | 76.26 | 73.51 |  87.7  |   95.73   | 82.34  | 81.55 |
| edgeDamage |  83.7 | 86.67 | 73.67 | 77.78 | 87.88 | 83.13  |   77.76   | 91.92  |  74.7 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:50:31,324 - mmseg - INFO - Summary:
2023-11-23 23:50:31,325 - mmseg - INFO - 
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc | mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.91 | 88.3 | 82.07 | 73.21 | 75.52 | 82.15 |  88.01  |   89.69    |   88.1  | 82.02 |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:50:31,344 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:50:31,344 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9991, mIoU: 0.8830, mVOE: 0.8207, mASD: 0.7321, mMSSD: 0.7552, mAcc: 0.8215, mFscore: 0.8801, mPrecision: 0.8969, mRecall: 0.8810, mDice: 0.8202, IoU.background: 0.9991, IoU.scratch: 0.8244, IoU.stain: 0.8715, IoU.edgeDamage: 0.8370, VOE.background: 0.7046, VOE.scratch: 0.8793, VOE.stain: 0.8322, VOE.edgeDamage: 0.8667, ASD.background: 0.7219, ASD.scratch: 0.7364, ASD.stain: 0.7336, ASD.edgeDamage: 0.7367, MSSD.background: 0.7039, MSSD.scratch: 0.7763, MSSD.stain: 0.7626, MSSD.edgeDamage: 0.7778, Acc.background: 0.9989, Acc.scratch: 0.6732, Acc.stain: 0.7351, Acc.edgeDamage: 0.8788, Fscore.background: 0.9993, Fscore.scratch: 0.8129, Fscore.stain: 0.8770, Fscore.edgeDamage: 0.8313, Precision.background: 0.9994, Precision.scratch: 0.8533, Precision.stain: 0.9573, Precision.edgeDamage: 0.7776, Recall.background: 0.9993, Recall.scratch: 0.7821, Recall.stain: 0.8234, Recall.edgeDamage: 0.9192, Dice.background: 0.9990, Dice.scratch: 0.7193, Dice.stain: 0.8155, Dice.edgeDamage: 0.7470
2023-11-23 23:50:49,078 - mmseg - INFO - Iter [3050/10000]	lr: 7.488e-05, eta: 0:44:53, time: 0.777, data_time: 0.484, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2125, decode.acc_seg: 99.6764, loss: 0.2134
2023-11-23 23:51:04,243 - mmseg - INFO - Iter [3100/10000]	lr: 7.446e-05, eta: 0:44:25, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2207, decode.acc_seg: 99.7094, loss: 0.2215
2023-11-23 23:51:21,981 - mmseg - INFO - Iter [3150/10000]	lr: 7.404e-05, eta: 0:44:02, time: 0.355, data_time: 0.059, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2171, decode.acc_seg: 99.6989, loss: 0.2180
2023-11-23 23:51:39,803 - mmseg - INFO - Iter [3200/10000]	lr: 7.361e-05, eta: 0:43:39, time: 0.356, data_time: 0.063, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2221, decode.acc_seg: 99.6713, loss: 0.2230
2023-11-23 23:51:55,013 - mmseg - INFO - Iter [3250/10000]	lr: 7.319e-05, eta: 0:43:12, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2149, decode.acc_seg: 99.6667, loss: 0.2158
2023-11-23 23:52:12,763 - mmseg - INFO - Iter [3300/10000]	lr: 7.277e-05, eta: 0:42:50, time: 0.355, data_time: 0.060, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2112, decode.acc_seg: 99.7198, loss: 0.2119
2023-11-23 23:52:27,958 - mmseg - INFO - Iter [3350/10000]	lr: 7.235e-05, eta: 0:42:23, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2017, decode.acc_seg: 99.6858, loss: 0.2026
2023-11-23 23:52:45,615 - mmseg - INFO - Iter [3400/10000]	lr: 7.193e-05, eta: 0:42:01, time: 0.353, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2031, decode.acc_seg: 99.7451, loss: 0.2038
2023-11-23 23:53:00,818 - mmseg - INFO - Iter [3450/10000]	lr: 7.151e-05, eta: 0:41:34, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2108, decode.acc_seg: 99.6972, loss: 0.2116
2023-11-23 23:53:18,751 - mmseg - INFO - Iter [3500/10000]	lr: 7.108e-05, eta: 0:41:13, time: 0.359, data_time: 0.074, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2005, decode.acc_seg: 99.7333, loss: 0.2013
2023-11-23 23:53:41,766 - mmseg - INFO - per class results:
2023-11-23 23:53:41,767 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.87 |  70.5 |  72.2 | 70.42 | 99.77 |  99.9  |   99.96   | 99.85  | 99.85 |
|  scratch   | 83.41 | 86.96 | 73.36 | 76.23 | 73.63 | 82.72  |   83.02   | 82.42  | 74.07 |
|   stain    | 90.16 | 80.21 | 72.88 | 73.82 | 84.47 | 91.15  |   92.78   | 89.65  | 86.72 |
| edgeDamage | 79.41 | 90.96 | 74.22 | 80.53 | 94.06 | 76.34  |   69.53   | 96.04  |  64.5 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:53:41,767 - mmseg - INFO - Summary:
2023-11-23 23:53:41,768 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.87 | 88.21 | 82.16 | 73.16 | 75.25 | 87.99 |  87.52  |   86.32    |  91.99  | 81.29 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:53:41,784 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9987, mIoU: 0.8821, mVOE: 0.8216, mASD: 0.7316, mMSSD: 0.7525, mAcc: 0.8799, mFscore: 0.8752, mPrecision: 0.8632, mRecall: 0.9199, mDice: 0.8129, IoU.background: 0.9987, IoU.scratch: 0.8341, IoU.stain: 0.9016, IoU.edgeDamage: 0.7941, VOE.background: 0.7050, VOE.scratch: 0.8696, VOE.stain: 0.8021, VOE.edgeDamage: 0.9096, ASD.background: 0.7220, ASD.scratch: 0.7336, ASD.stain: 0.7288, ASD.edgeDamage: 0.7422, MSSD.background: 0.7042, MSSD.scratch: 0.7623, MSSD.stain: 0.7382, MSSD.edgeDamage: 0.8053, Acc.background: 0.9977, Acc.scratch: 0.7363, Acc.stain: 0.8447, Acc.edgeDamage: 0.9406, Fscore.background: 0.9990, Fscore.scratch: 0.8272, Fscore.stain: 0.9115, Fscore.edgeDamage: 0.7634, Precision.background: 0.9996, Precision.scratch: 0.8302, Precision.stain: 0.9278, Precision.edgeDamage: 0.6953, Recall.background: 0.9985, Recall.scratch: 0.8242, Recall.stain: 0.8965, Recall.edgeDamage: 0.9604, Dice.background: 0.9985, Dice.scratch: 0.7407, Dice.stain: 0.8672, Dice.edgeDamage: 0.6450
2023-11-23 23:53:56,941 - mmseg - INFO - Iter [3550/10000]	lr: 7.066e-05, eta: 0:41:29, time: 0.764, data_time: 0.466, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.1977, decode.acc_seg: 99.7151, loss: 0.1984
2023-11-23 23:54:14,614 - mmseg - INFO - Iter [3600/10000]	lr: 7.024e-05, eta: 0:41:07, time: 0.353, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2004, decode.acc_seg: 99.7014, loss: 0.2012
2023-11-23 23:54:29,772 - mmseg - INFO - Iter [3650/10000]	lr: 6.981e-05, eta: 0:40:40, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2123, decode.acc_seg: 99.6968, loss: 0.2131
2023-11-23 23:54:47,452 - mmseg - INFO - Iter [3700/10000]	lr: 6.939e-05, eta: 0:40:18, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0006, decode.loss_dice: 0.2039, decode.acc_seg: 99.7507, loss: 0.2046
2023-11-23 23:55:02,637 - mmseg - INFO - Iter [3750/10000]	lr: 6.897e-05, eta: 0:39:52, time: 0.304, data_time: 0.005, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2173, decode.acc_seg: 99.6873, loss: 0.2181
2023-11-23 23:55:20,310 - mmseg - INFO - Iter [3800/10000]	lr: 6.854e-05, eta: 0:39:31, time: 0.353, data_time: 0.057, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2099, decode.acc_seg: 99.6488, loss: 0.2108
2023-11-23 23:55:35,493 - mmseg - INFO - Iter [3850/10000]	lr: 6.812e-05, eta: 0:39:05, time: 0.304, data_time: 0.005, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2103, decode.acc_seg: 99.6992, loss: 0.2111
2023-11-23 23:55:53,226 - mmseg - INFO - Iter [3900/10000]	lr: 6.769e-05, eta: 0:38:44, time: 0.355, data_time: 0.065, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2043, decode.acc_seg: 99.7105, loss: 0.2050
2023-11-23 23:56:10,997 - mmseg - INFO - Iter [3950/10000]	lr: 6.726e-05, eta: 0:38:23, time: 0.355, data_time: 0.059, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.2135, decode.acc_seg: 99.6728, loss: 0.2144
2023-11-23 23:56:26,169 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:56:26,169 - mmseg - INFO - Iter [4000/10000]	lr: 6.684e-05, eta: 0:37:58, time: 0.303, data_time: 0.008, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2011, decode.acc_seg: 99.6897, loss: 0.2019
2023-11-23 23:56:47,683 - mmseg - INFO - per class results:
2023-11-23 23:56:47,684 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.93 | 70.44 | 72.19 | 70.39 | 99.92 | 99.95  |   99.95   | 99.94  | 99.92 |
|  scratch   | 83.69 | 86.69 | 73.38 | 76.34 | 73.12 | 83.12  |   84.23   | 82.08  | 74.67 |
|   stain    | 90.61 | 79.76 | 72.92 | 74.05 | 83.42 | 91.63  |   94.78   | 88.95  | 87.44 |
| edgeDamage | 86.87 |  83.5 | 73.23 | 75.59 | 86.59 | 87.34  |   84.33   | 91.06  | 81.02 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:56:47,684 - mmseg - INFO - Summary:
2023-11-23 23:56:47,684 - mmseg - INFO - 
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU | mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
| 99.93 | 90.27 | 80.1 | 72.93 | 74.09 | 85.76 |  90.51  |   90.82    |  90.51  | 85.76 |
+-------+-------+------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:56:47,701 - mmseg - INFO - Exp name: unet_all.py
2023-11-23 23:56:47,701 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9993, mIoU: 0.9027, mVOE: 0.8010, mASD: 0.7293, mMSSD: 0.7409, mAcc: 0.8576, mFscore: 0.9051, mPrecision: 0.9082, mRecall: 0.9051, mDice: 0.8576, IoU.background: 0.9993, IoU.scratch: 0.8369, IoU.stain: 0.9061, IoU.edgeDamage: 0.8687, VOE.background: 0.7044, VOE.scratch: 0.8669, VOE.stain: 0.7976, VOE.edgeDamage: 0.8350, ASD.background: 0.7219, ASD.scratch: 0.7338, ASD.stain: 0.7292, ASD.edgeDamage: 0.7323, MSSD.background: 0.7039, MSSD.scratch: 0.7634, MSSD.stain: 0.7405, MSSD.edgeDamage: 0.7559, Acc.background: 0.9992, Acc.scratch: 0.7312, Acc.stain: 0.8342, Acc.edgeDamage: 0.8659, Fscore.background: 0.9995, Fscore.scratch: 0.8312, Fscore.stain: 0.9163, Fscore.edgeDamage: 0.8734, Precision.background: 0.9995, Precision.scratch: 0.8423, Precision.stain: 0.9478, Precision.edgeDamage: 0.8433, Recall.background: 0.9994, Recall.scratch: 0.8208, Recall.stain: 0.8895, Recall.edgeDamage: 0.9106, Dice.background: 0.9992, Dice.scratch: 0.7467, Dice.stain: 0.8744, Dice.edgeDamage: 0.8102
2023-11-23 23:57:05,406 - mmseg - INFO - Iter [4050/10000]	lr: 6.641e-05, eta: 0:38:09, time: 0.785, data_time: 0.489, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2075, decode.acc_seg: 99.7019, loss: 0.2082
2023-11-23 23:57:20,583 - mmseg - INFO - Iter [4100/10000]	lr: 6.599e-05, eta: 0:37:44, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2127, decode.acc_seg: 99.7214, loss: 0.2135
2023-11-23 23:57:38,470 - mmseg - INFO - Iter [4150/10000]	lr: 6.556e-05, eta: 0:37:23, time: 0.358, data_time: 0.064, memory: 7767, decode.loss_focal: 0.0009, decode.loss_dice: 0.1996, decode.acc_seg: 99.6897, loss: 0.2005
2023-11-23 23:57:53,643 - mmseg - INFO - Iter [4200/10000]	lr: 6.513e-05, eta: 0:36:58, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2034, decode.acc_seg: 99.7061, loss: 0.2042
2023-11-23 23:58:11,379 - mmseg - INFO - Iter [4250/10000]	lr: 6.470e-05, eta: 0:36:37, time: 0.355, data_time: 0.062, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1959, decode.acc_seg: 99.7118, loss: 0.1966
2023-11-23 23:58:26,569 - mmseg - INFO - Iter [4300/10000]	lr: 6.427e-05, eta: 0:36:13, time: 0.304, data_time: 0.005, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2008, decode.acc_seg: 99.7029, loss: 0.2015
2023-11-23 23:58:44,268 - mmseg - INFO - Iter [4350/10000]	lr: 6.385e-05, eta: 0:35:52, time: 0.354, data_time: 0.061, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2003, decode.acc_seg: 99.7253, loss: 0.2010
2023-11-23 23:58:59,463 - mmseg - INFO - Iter [4400/10000]	lr: 6.342e-05, eta: 0:35:28, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2002, decode.acc_seg: 99.6831, loss: 0.2010
2023-11-23 23:59:17,162 - mmseg - INFO - Iter [4450/10000]	lr: 6.299e-05, eta: 0:35:08, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1976, decode.acc_seg: 99.7261, loss: 0.1983
2023-11-23 23:59:32,413 - mmseg - INFO - Iter [4500/10000]	lr: 6.256e-05, eta: 0:34:44, time: 0.305, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2089, decode.acc_seg: 99.6967, loss: 0.2097
2023-11-23 23:59:53,713 - mmseg - INFO - per class results:
2023-11-23 23:59:53,714 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.91 | 70.46 | 72.19 |  70.4 | 99.88 | 99.93  |   99.95   | 99.92  |  99.9 |
|  scratch   | 82.26 | 88.11 |  73.5 | 76.94 | 70.45 | 81.02  |   81.77   |  80.3  | 71.52 |
|   stain    | 90.92 | 79.45 |  72.9 | 73.94 | 83.93 | 91.96  |    95.1   | 89.29  | 87.94 |
| edgeDamage | 84.59 | 85.78 | 73.61 | 77.49 | 90.82 | 84.38  |   78.65   | 93.88  | 76.56 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-23 23:59:53,714 - mmseg - INFO - Summary:
2023-11-23 23:59:53,714 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.91 | 89.42 | 80.95 | 73.05 | 74.69 | 86.27 |  89.32  |   88.87    |  90.85  | 83.98 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-23 23:59:53,732 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9991, mIoU: 0.8942, mVOE: 0.8095, mASD: 0.7305, mMSSD: 0.7469, mAcc: 0.8627, mFscore: 0.8932, mPrecision: 0.8887, mRecall: 0.9085, mDice: 0.8398, IoU.background: 0.9991, IoU.scratch: 0.8226, IoU.stain: 0.9092, IoU.edgeDamage: 0.8459, VOE.background: 0.7046, VOE.scratch: 0.8811, VOE.stain: 0.7945, VOE.edgeDamage: 0.8578, ASD.background: 0.7219, ASD.scratch: 0.7350, ASD.stain: 0.7290, ASD.edgeDamage: 0.7361, MSSD.background: 0.7040, MSSD.scratch: 0.7694, MSSD.stain: 0.7394, MSSD.edgeDamage: 0.7749, Acc.background: 0.9988, Acc.scratch: 0.7045, Acc.stain: 0.8393, Acc.edgeDamage: 0.9082, Fscore.background: 0.9993, Fscore.scratch: 0.8102, Fscore.stain: 0.9196, Fscore.edgeDamage: 0.8438, Precision.background: 0.9995, Precision.scratch: 0.8177, Precision.stain: 0.9510, Precision.edgeDamage: 0.7865, Recall.background: 0.9992, Recall.scratch: 0.8030, Recall.stain: 0.8929, Recall.edgeDamage: 0.9388, Dice.background: 0.9990, Dice.scratch: 0.7152, Dice.stain: 0.8794, Dice.edgeDamage: 0.7656
2023-11-24 00:00:11,421 - mmseg - INFO - Iter [4550/10000]	lr: 6.213e-05, eta: 0:34:49, time: 0.780, data_time: 0.487, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.2003, decode.acc_seg: 99.7182, loss: 0.2010
2023-11-24 00:00:26,580 - mmseg - INFO - Iter [4600/10000]	lr: 6.170e-05, eta: 0:34:25, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1971, decode.acc_seg: 99.6972, loss: 0.1978
2023-11-24 00:00:44,317 - mmseg - INFO - Iter [4650/10000]	lr: 6.127e-05, eta: 0:34:05, time: 0.355, data_time: 0.060, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1974, decode.acc_seg: 99.7214, loss: 0.1981
2023-11-24 00:00:59,516 - mmseg - INFO - Iter [4700/10000]	lr: 6.084e-05, eta: 0:33:41, time: 0.304, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.2066, decode.acc_seg: 99.7139, loss: 0.2074
2023-11-24 00:01:17,373 - mmseg - INFO - Iter [4750/10000]	lr: 6.040e-05, eta: 0:33:21, time: 0.357, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.1932, decode.acc_seg: 99.7032, loss: 0.1940
2023-11-24 00:01:35,107 - mmseg - INFO - Iter [4800/10000]	lr: 5.997e-05, eta: 0:33:00, time: 0.355, data_time: 0.060, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1987, decode.acc_seg: 99.7178, loss: 0.1994
2023-11-24 00:01:50,273 - mmseg - INFO - Iter [4850/10000]	lr: 5.954e-05, eta: 0:32:37, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1945, decode.acc_seg: 99.7348, loss: 0.1951
2023-11-24 00:02:07,966 - mmseg - INFO - Iter [4900/10000]	lr: 5.911e-05, eta: 0:32:17, time: 0.354, data_time: 0.058, memory: 7767, decode.loss_focal: 0.0008, decode.loss_dice: 0.1937, decode.acc_seg: 99.7029, loss: 0.1945
2023-11-24 00:02:23,132 - mmseg - INFO - Iter [4950/10000]	lr: 5.867e-05, eta: 0:31:54, time: 0.303, data_time: 0.006, memory: 7767, decode.loss_focal: 0.0007, decode.loss_dice: 0.1871, decode.acc_seg: 99.7194, loss: 0.1878
2023-11-24 00:02:41,181 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-11-24 00:02:41,812 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 00:02:41,812 - mmseg - INFO - Iter [5000/10000]	lr: 5.824e-05, eta: 0:31:35, time: 0.375, data_time: 0.073, memory: 7767, decode.loss_focal: 0.0006, decode.loss_dice: 0.1968, decode.acc_seg: 99.7504, loss: 0.1974
2023-11-24 00:03:03,164 - mmseg - INFO - per class results:
2023-11-24 00:03:03,165 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 72.19 | 70.41 |  99.8 | 99.91  |   99.95   | 99.87  | 99.87 |
|  scratch   | 83.72 | 86.65 | 73.45 | 76.67 | 71.66 | 83.16  |   85.58   | 81.11  | 74.75 |
|   stain    | 90.83 | 79.54 | 72.79 |  73.4 | 86.39 | 91.86  |   92.85   | 90.92  |  87.8 |
| edgeDamage | 79.88 | 90.49 | 74.16 | 80.24 | 92.95 | 77.15  |   70.38   |  95.3  | 65.73 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 00:03:03,165 - mmseg - INFO - Summary:
2023-11-24 00:03:03,166 - mmseg - INFO - 
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD | mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
| 99.88 | 88.58 | 81.79 | 73.15 | 75.18 | 87.7 |  88.02  |   87.19    |   91.8  | 82.03 |
+-------+-------+-------+-------+-------+------+---------+------------+---------+-------+
2023-11-24 00:03:03,181 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 00:03:03,182 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9988, mIoU: 0.8858, mVOE: 0.8179, mASD: 0.7315, mMSSD: 0.7518, mAcc: 0.8770, mFscore: 0.8802, mPrecision: 0.8719, mRecall: 0.9180, mDice: 0.8203, IoU.background: 0.9988, IoU.scratch: 0.8372, IoU.stain: 0.9083, IoU.edgeDamage: 0.7988, VOE.background: 0.7049, VOE.scratch: 0.8665, VOE.stain: 0.7954, VOE.edgeDamage: 0.9049, ASD.background: 0.7219, ASD.scratch: 0.7345, ASD.stain: 0.7279, ASD.edgeDamage: 0.7416, MSSD.background: 0.7041, MSSD.scratch: 0.7667, MSSD.stain: 0.7340, MSSD.edgeDamage: 0.8024, Acc.background: 0.9980, Acc.scratch: 0.7166, Acc.stain: 0.8639, Acc.edgeDamage: 0.9295, Fscore.background: 0.9991, Fscore.scratch: 0.8316, Fscore.stain: 0.9186, Fscore.edgeDamage: 0.7715, Precision.background: 0.9995, Precision.scratch: 0.8558, Precision.stain: 0.9285, Precision.edgeDamage: 0.7038, Recall.background: 0.9987, Recall.scratch: 0.8111, Recall.stain: 0.9092, Recall.edgeDamage: 0.9530, Dice.background: 0.9987, Dice.scratch: 0.7475, Dice.stain: 0.8780, Dice.edgeDamage: 0.6573
