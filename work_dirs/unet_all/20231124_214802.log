2023-11-24 21:48:02,832 - mmseg - INFO - Multi-processing start method is `None`
2023-11-24 21:48:02,894 - mmseg - INFO - OpenCV num_threads is `6
2023-11-24 21:48:03,054 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /environment/miniconda3
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.1
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.1+
------------------------------------------------------------

2023-11-24 21:48:03,054 - mmseg - INFO - Distributed training: False
2023-11-24 21:48:03,415 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='UnetBackbone',
        in_channels=3,
        context_layer='',
        conv_down=True,
        channel_list=[64, 128, 256, 512]),
    decode_head=dict(
        type='UnetHead',
        num_classes=4,
        channels=64,
        threshold=0.2,
        norm_cfg=dict(type='BN', requires_grad=True),
        loss_decode=[
            dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                class_weight=[0.1, 0.5, 0.2, 0.2],
                loss_weight=2.0),
            dict(
                type='DiceLoss',
                loss_name='loss_dice',
                class_weight=[0.1, 0.5, 0.2, 0.2],
                loss_weight=2.0)
        ]))
train_cfg = dict()
test_cfg = dict(mode='whole')
dataset_type = 'MyDataset'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(600, 600)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=False),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data_root = './datasets/'
data = dict(
    samples_per_gpu=5,
    workers_per_gpu=2,
    train=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='train/images',
        ann_dir='train/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(600, 600)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TensorboardLoggerHook'),
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = False
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.999))
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=1e-05, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, save_optimizer=False, interval=5000)
evaluation = dict(interval=500, metric=['mIoU', 'mFscore', 'mDice'])
work_dir = './work_dirs/unet_all'
gpu_ids = [0]
auto_resume = False

2023-11-24 21:48:03,416 - mmseg - INFO - Set random seed to 1449222381, deterministic: False
2023-11-24 21:48:03,620 - mmseg - INFO - initialize UnetHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.inc.conv.conv1_1.0.weight - torch.Size([64, 3, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_2.0.weight - torch.Size([64, 64, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv1_2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_1.0.weight - torch.Size([64, 3, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_2.0.weight - torch.Size([64, 64, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv2_2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_1.0.weight - torch.Size([64, 3, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_1.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_1.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_2.0.weight - torch.Size([64, 64, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.inc.conv.conv3_2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.0.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_1.0.weight - torch.Size([128, 64, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_1.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_2.0.weight - torch.Size([128, 128, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv1_2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_1.0.weight - torch.Size([128, 64, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_1.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_2.0.weight - torch.Size([128, 128, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv2_2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_1.0.weight - torch.Size([128, 64, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_1.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_2.0.weight - torch.Size([128, 128, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down1.down_conv.1.conv3_2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.0.weight - torch.Size([128, 128, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_1.0.weight - torch.Size([256, 128, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_2.0.weight - torch.Size([256, 256, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv1_2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_1.0.weight - torch.Size([256, 128, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_2.0.weight - torch.Size([256, 256, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv2_2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_1.0.weight - torch.Size([256, 128, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_2.0.weight - torch.Size([256, 256, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down2.down_conv.1.conv3_2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.0.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_1.0.weight - torch.Size([512, 256, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv1_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_1.0.weight - torch.Size([512, 256, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv2_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_1.0.weight - torch.Size([512, 256, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down3.down_conv.1.conv3_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.0.weight - torch.Size([512, 512, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_1.0.weight - torch.Size([512, 512, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv1_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_1.0.weight - torch.Size([512, 512, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv2_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_1.0.weight - torch.Size([512, 512, 1, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_1.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_1.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_2.0.weight - torch.Size([512, 512, 3, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_2.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.down4.down_conv.1.conv3_2.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([4, 64, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.up1.up.weight - torch.Size([512, 512, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.up.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv_h.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv_h.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv_w.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.coord.conv_w.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.weight - torch.Size([256, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up1.conv.conv.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.up.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.up.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv_h.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv_h.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv_w.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.coord.conv_w.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.weight - torch.Size([128, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up2.conv.conv.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.up.weight - torch.Size([128, 128, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.up.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv_h.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv_h.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv_w.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.coord.conv_w.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up3.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv1.weight - torch.Size([32, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv_h.weight - torch.Size([128, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv_h.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv_w.weight - torch.Size([128, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.coord.conv_w.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.up4.conv.conv.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-11-24 21:48:03,628 - mmseg - INFO - EncoderDecoder(
  (backbone): UnetBackbone(
    (inc): MACInConv(
      (conv): MAC(
        (conv1_1): Sequential(
          (0): Conv2d(3, 64, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv1_2): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2_1): Sequential(
          (0): Conv2d(3, 64, kernel_size=(1, 3), stride=(1, 1), padding=(1, 2), dilation=(1, 2))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2_2): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(2, 1), dilation=(2, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv3_1): Sequential(
          (0): Conv2d(3, 64, kernel_size=(1, 3), stride=(1, 1), padding=(1, 3), dilation=(1, 3))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv3_2): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(3, 1), dilation=(3, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (down1): Conv_Down(
      (down_conv): Sequential(
        (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): MAC(
          (conv1_1): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv1_2): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_1): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(1, 2), dilation=(1, 2))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_2): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(2, 1), dilation=(2, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_1): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(1, 3), dilation=(1, 3))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_2): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(3, 1), dilation=(3, 1))
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (down2): Conv_Down(
      (down_conv): Sequential(
        (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))
        (1): MAC(
          (conv1_1): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv1_2): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_1): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 3), stride=(1, 1), padding=(1, 2), dilation=(1, 2))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_2): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(2, 1), dilation=(2, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_1): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 3), stride=(1, 1), padding=(1, 3), dilation=(1, 3))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_2): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(3, 1), dilation=(3, 1))
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (down3): Conv_Down(
      (down_conv): Sequential(
        (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
        (1): MAC(
          (conv1_1): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv1_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_1): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 2), dilation=(1, 2))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(2, 1), dilation=(2, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_1): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 3), dilation=(1, 3))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(3, 1), dilation=(3, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
    (down4): Conv_Down(
      (down_conv): Sequential(
        (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
        (1): MAC(
          (conv1_1): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv1_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_1): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 2), dilation=(1, 2))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv2_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(2, 1), dilation=(2, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_1): Sequential(
            (0): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(1, 3), dilation=(1, 3))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (conv3_2): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(3, 1), dilation=(3, 1))
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
  )
  (decode_head): UnetHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): FocalLoss()
      (1): DiceLoss()
    )
    (conv_seg): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (up1): Up(
      (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
      (coord): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up2): Up(
      (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (coord): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up3): Up(
      (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))
      (coord): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
    (up4): Up(
      (up): Upsample(scale_factor=2.0, mode=bilinear)
      (coord): CoordAtt(
        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (conv_h): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
        (conv_w): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): DoubleConv(
        (conv): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-24 21:48:04,565 - mmseg - INFO - Loaded 474 images
2023-11-24 21:49:41,134 - mmseg - INFO - Loaded 105 images
2023-11-24 21:49:41,135 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/work/test/work_dirs/unet_all
2023-11-24 21:49:41,135 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-24 21:49:41,136 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-11-24 21:49:41,136 - mmseg - INFO - Checkpoints will be saved to /home/featurize/work/test/work_dirs/unet_all by HardDiskBackend.
2023-11-24 21:50:12,460 - mmseg - INFO - Iter [50/10000]	lr: 9.960e-05, eta: 1:37:31, time: 0.588, data_time: 0.054, memory: 13918, decode.loss_focal: 0.0520, decode.loss_dice: 0.4682, decode.acc_seg: 92.3674, loss: 0.5202
2023-11-24 21:50:38,044 - mmseg - INFO - Iter [100/10000]	lr: 9.920e-05, eta: 1:30:44, time: 0.512, data_time: 0.060, memory: 13918, decode.loss_focal: 0.0388, decode.loss_dice: 0.4616, decode.acc_seg: 99.0713, loss: 0.5003
2023-11-24 21:51:00,838 - mmseg - INFO - Iter [150/10000]	lr: 9.879e-05, eta: 1:25:07, time: 0.456, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0286, decode.loss_dice: 0.4551, decode.acc_seg: 99.4937, loss: 0.4836
2023-11-24 21:51:26,275 - mmseg - INFO - Iter [200/10000]	lr: 9.839e-05, eta: 1:24:17, time: 0.509, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0216, decode.loss_dice: 0.4498, decode.acc_seg: 99.4622, loss: 0.4714
2023-11-24 21:51:49,065 - mmseg - INFO - Iter [250/10000]	lr: 9.798e-05, eta: 1:21:54, time: 0.456, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0167, decode.loss_dice: 0.4448, decode.acc_seg: 99.4254, loss: 0.4615
2023-11-24 21:52:14,499 - mmseg - INFO - Iter [300/10000]	lr: 9.757e-05, eta: 1:21:36, time: 0.509, data_time: 0.055, memory: 13918, decode.loss_focal: 0.0134, decode.loss_dice: 0.4399, decode.acc_seg: 99.4667, loss: 0.4533
2023-11-24 21:52:37,444 - mmseg - INFO - Iter [350/10000]	lr: 9.717e-05, eta: 1:20:08, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0106, decode.loss_dice: 0.4346, decode.acc_seg: 99.4652, loss: 0.4451
2023-11-24 21:53:02,946 - mmseg - INFO - Iter [400/10000]	lr: 9.676e-05, eta: 1:19:57, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0087, decode.loss_dice: 0.4227, decode.acc_seg: 99.2791, loss: 0.4314
2023-11-24 21:53:25,951 - mmseg - INFO - Iter [450/10000]	lr: 9.635e-05, eta: 1:18:50, time: 0.460, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0065, decode.loss_dice: 0.4028, decode.acc_seg: 99.2876, loss: 0.4093
2023-11-24 21:53:51,505 - mmseg - INFO - Iter [500/10000]	lr: 9.595e-05, eta: 1:18:40, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0049, decode.loss_dice: 0.3762, decode.acc_seg: 99.4002, loss: 0.3811
2023-11-24 21:54:17,861 - mmseg - INFO - per class results:
2023-11-24 21:54:17,863 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.86 | 70.51 | 71.96 | 70.41 | 99.82 |  99.9  |   99.91   | 99.88  | 99.84 |
|  scratch   | 74.77 |  95.6 | 74.25 | 81.83 | 48.41 | 67.04  |   68.96   | 65.61  | 50.57 |
|   stain    | 83.24 | 87.13 | 73.27 | 76.94 | 77.61 | 82.47  |   80.28   | 85.07  |  73.7 |
| edgeDamage | 81.47 |  88.9 | 73.68 |  79.0 | 85.66 | 79.78  |   74.12   | 90.44  | 69.68 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 21:54:17,863 - mmseg - INFO - Summary:
2023-11-24 21:54:17,863 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.86 | 84.83 | 85.54 | 73.29 | 77.05 | 77.87 |   82.3  |   80.82    |  85.25  | 73.45 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-24 21:54:17,879 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9986, mIoU: 0.8483, mVOE: 0.8554, mASD: 0.7329, mMSSD: 0.7705, mAcc: 0.7787, mFscore: 0.8230, mPrecision: 0.8082, mRecall: 0.8525, mDice: 0.7345, IoU.background: 0.9986, IoU.scratch: 0.7477, IoU.stain: 0.8324, IoU.edgeDamage: 0.8147, VOE.background: 0.7051, VOE.scratch: 0.9560, VOE.stain: 0.8713, VOE.edgeDamage: 0.8890, ASD.background: 0.7196, ASD.scratch: 0.7425, ASD.stain: 0.7327, ASD.edgeDamage: 0.7368, MSSD.background: 0.7041, MSSD.scratch: 0.8183, MSSD.stain: 0.7694, MSSD.edgeDamage: 0.7900, Acc.background: 0.9982, Acc.scratch: 0.4841, Acc.stain: 0.7761, Acc.edgeDamage: 0.8566, Fscore.background: 0.9990, Fscore.scratch: 0.6704, Fscore.stain: 0.8247, Fscore.edgeDamage: 0.7978, Precision.background: 0.9991, Precision.scratch: 0.6896, Precision.stain: 0.8028, Precision.edgeDamage: 0.7412, Recall.background: 0.9988, Recall.scratch: 0.6561, Recall.stain: 0.8507, Recall.edgeDamage: 0.9044, Dice.background: 0.9984, Dice.scratch: 0.5057, Dice.stain: 0.7370, Dice.edgeDamage: 0.6968
2023-11-24 21:54:40,720 - mmseg - INFO - Iter [550/10000]	lr: 9.554e-05, eta: 1:25:14, time: 0.984, data_time: 0.531, memory: 13918, decode.loss_focal: 0.0038, decode.loss_dice: 0.3592, decode.acc_seg: 99.4735, loss: 0.3630
2023-11-24 21:55:06,148 - mmseg - INFO - Iter [600/10000]	lr: 9.513e-05, eta: 1:24:21, time: 0.509, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0031, decode.loss_dice: 0.3408, decode.acc_seg: 99.5027, loss: 0.3439
2023-11-24 21:55:29,054 - mmseg - INFO - Iter [650/10000]	lr: 9.473e-05, eta: 1:22:57, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0026, decode.loss_dice: 0.3259, decode.acc_seg: 99.5296, loss: 0.3286
2023-11-24 21:55:54,672 - mmseg - INFO - Iter [700/10000]	lr: 9.432e-05, eta: 1:22:17, time: 0.512, data_time: 0.057, memory: 13918, decode.loss_focal: 0.0023, decode.loss_dice: 0.3170, decode.acc_seg: 99.5827, loss: 0.3193
2023-11-24 21:56:17,534 - mmseg - INFO - Iter [750/10000]	lr: 9.391e-05, eta: 1:21:05, time: 0.457, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0020, decode.loss_dice: 0.3126, decode.acc_seg: 99.5977, loss: 0.3146
2023-11-24 21:56:43,074 - mmseg - INFO - Iter [800/10000]	lr: 9.350e-05, eta: 1:20:30, time: 0.511, data_time: 0.057, memory: 13918, decode.loss_focal: 0.0019, decode.loss_dice: 0.3145, decode.acc_seg: 99.5855, loss: 0.3164
2023-11-24 21:57:08,540 - mmseg - INFO - Iter [850/10000]	lr: 9.309e-05, eta: 1:19:55, time: 0.509, data_time: 0.055, memory: 13918, decode.loss_focal: 0.0017, decode.loss_dice: 0.2936, decode.acc_seg: 99.6347, loss: 0.2953
2023-11-24 21:57:31,495 - mmseg - INFO - Iter [900/10000]	lr: 9.268e-05, eta: 1:18:56, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0016, decode.loss_dice: 0.3007, decode.acc_seg: 99.6478, loss: 0.3023
2023-11-24 21:57:57,022 - mmseg - INFO - Iter [950/10000]	lr: 9.228e-05, eta: 1:18:25, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0015, decode.loss_dice: 0.2843, decode.acc_seg: 99.6328, loss: 0.2858
2023-11-24 21:58:19,949 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 21:58:19,949 - mmseg - INFO - Iter [1000/10000]	lr: 9.187e-05, eta: 1:17:31, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0013, decode.loss_dice: 0.2895, decode.acc_seg: 99.6806, loss: 0.2908
2023-11-24 21:58:42,855 - mmseg - INFO - per class results:
2023-11-24 21:58:42,856 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 71.96 | 70.41 | 99.82 | 99.91  |   99.94   | 99.88  | 99.86 |
|  scratch   | 80.59 | 89.78 | 73.56 | 78.41 |  63.8 | 78.35  |   81.53   | 75.87  | 67.53 |
|   stain    | 88.01 | 82.36 | 73.04 | 75.79 | 75.61 | 88.73  |   95.87   | 83.74  | 83.09 |
| edgeDamage | 80.56 | 89.81 | 73.85 | 79.84 | 92.11 | 78.31  |   71.59   | 94.74  | 67.46 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 21:58:42,856 - mmseg - INFO - Summary:
2023-11-24 21:58:42,857 - mmseg - INFO - 
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE | mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
| 99.88 | 87.26 | 83.11 | 73.1 | 76.11 | 82.83 |  86.33  |   87.23    |  88.56  | 79.49 |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
2023-11-24 21:58:42,871 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 21:58:42,871 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9988, mIoU: 0.8726, mVOE: 0.8311, mASD: 0.7310, mMSSD: 0.7611, mAcc: 0.8283, mFscore: 0.8633, mPrecision: 0.8723, mRecall: 0.8856, mDice: 0.7949, IoU.background: 0.9988, IoU.scratch: 0.8059, IoU.stain: 0.8801, IoU.edgeDamage: 0.8056, VOE.background: 0.7049, VOE.scratch: 0.8978, VOE.stain: 0.8236, VOE.edgeDamage: 0.8981, ASD.background: 0.7196, ASD.scratch: 0.7356, ASD.stain: 0.7304, ASD.edgeDamage: 0.7385, MSSD.background: 0.7041, MSSD.scratch: 0.7841, MSSD.stain: 0.7579, MSSD.edgeDamage: 0.7984, Acc.background: 0.9982, Acc.scratch: 0.6380, Acc.stain: 0.7561, Acc.edgeDamage: 0.9211, Fscore.background: 0.9991, Fscore.scratch: 0.7835, Fscore.stain: 0.8873, Fscore.edgeDamage: 0.7831, Precision.background: 0.9994, Precision.scratch: 0.8153, Precision.stain: 0.9587, Precision.edgeDamage: 0.7159, Recall.background: 0.9988, Recall.scratch: 0.7587, Recall.stain: 0.8374, Recall.edgeDamage: 0.9474, Dice.background: 0.9986, Dice.scratch: 0.6753, Dice.stain: 0.8309, Dice.edgeDamage: 0.6746
2023-11-24 21:59:08,363 - mmseg - INFO - Iter [1050/10000]	lr: 9.146e-05, eta: 1:20:18, time: 0.968, data_time: 0.516, memory: 13918, decode.loss_focal: 0.0013, decode.loss_dice: 0.2869, decode.acc_seg: 99.6385, loss: 0.2883
2023-11-24 21:59:31,269 - mmseg - INFO - Iter [1100/10000]	lr: 9.105e-05, eta: 1:19:19, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0013, decode.loss_dice: 0.2800, decode.acc_seg: 99.6564, loss: 0.2813
2023-11-24 21:59:56,830 - mmseg - INFO - Iter [1150/10000]	lr: 9.064e-05, eta: 1:18:43, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2702, decode.acc_seg: 99.7182, loss: 0.2713
2023-11-24 22:00:19,732 - mmseg - INFO - Iter [1200/10000]	lr: 9.023e-05, eta: 1:17:48, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0012, decode.loss_dice: 0.2684, decode.acc_seg: 99.6709, loss: 0.2696
2023-11-24 22:00:45,274 - mmseg - INFO - Iter [1250/10000]	lr: 8.982e-05, eta: 1:17:15, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0012, decode.loss_dice: 0.2544, decode.acc_seg: 99.6812, loss: 0.2556
2023-11-24 22:01:08,207 - mmseg - INFO - Iter [1300/10000]	lr: 8.941e-05, eta: 1:16:25, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0012, decode.loss_dice: 0.2688, decode.acc_seg: 99.6794, loss: 0.2700
2023-11-24 22:01:33,733 - mmseg - INFO - Iter [1350/10000]	lr: 8.900e-05, eta: 1:15:53, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0012, decode.loss_dice: 0.2463, decode.acc_seg: 99.6738, loss: 0.2474
2023-11-24 22:01:56,715 - mmseg - INFO - Iter [1400/10000]	lr: 8.858e-05, eta: 1:15:06, time: 0.460, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0012, decode.loss_dice: 0.2568, decode.acc_seg: 99.6717, loss: 0.2580
2023-11-24 22:02:22,271 - mmseg - INFO - Iter [1450/10000]	lr: 8.817e-05, eta: 1:14:36, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2424, decode.acc_seg: 99.6545, loss: 0.2435
2023-11-24 22:02:45,227 - mmseg - INFO - Iter [1500/10000]	lr: 8.776e-05, eta: 1:13:52, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2471, decode.acc_seg: 99.7001, loss: 0.2482
2023-11-24 22:03:08,755 - mmseg - INFO - per class results:
2023-11-24 22:03:08,756 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.88 | 70.49 | 71.96 | 70.41 | 99.84 | 99.91  |   99.93   | 99.89  | 99.87 |
|  scratch   | 80.96 | 89.41 | 73.71 | 79.15 | 60.48 | 78.96  |   88.68   | 73.65  | 68.44 |
|   stain    | 89.09 | 81.28 | 72.84 |  74.8 | 80.05 | 89.98  |   94.02   |  86.7  | 84.96 |
| edgeDamage | 80.16 | 90.21 | 73.88 | 79.98 | 89.82 | 77.63  |   71.17   | 93.21  | 66.45 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 22:03:08,756 - mmseg - INFO - Summary:
2023-11-24 22:03:08,756 - mmseg - INFO - 
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE | mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
| 99.89 | 87.53 | 82.85 | 73.1 | 76.09 | 82.55 |  86.62  |   88.45    |  88.36  | 79.93 |
+-------+-------+-------+------+-------+-------+---------+------------+---------+-------+
2023-11-24 22:03:08,775 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9989, mIoU: 0.8753, mVOE: 0.8285, mASD: 0.7310, mMSSD: 0.7609, mAcc: 0.8255, mFscore: 0.8662, mPrecision: 0.8845, mRecall: 0.8836, mDice: 0.7993, IoU.background: 0.9988, IoU.scratch: 0.8096, IoU.stain: 0.8909, IoU.edgeDamage: 0.8016, VOE.background: 0.7049, VOE.scratch: 0.8941, VOE.stain: 0.8128, VOE.edgeDamage: 0.9021, ASD.background: 0.7196, ASD.scratch: 0.7371, ASD.stain: 0.7284, ASD.edgeDamage: 0.7388, MSSD.background: 0.7041, MSSD.scratch: 0.7915, MSSD.stain: 0.7480, MSSD.edgeDamage: 0.7998, Acc.background: 0.9984, Acc.scratch: 0.6048, Acc.stain: 0.8005, Acc.edgeDamage: 0.8982, Fscore.background: 0.9991, Fscore.scratch: 0.7896, Fscore.stain: 0.8998, Fscore.edgeDamage: 0.7763, Precision.background: 0.9993, Precision.scratch: 0.8868, Precision.stain: 0.9402, Precision.edgeDamage: 0.7117, Recall.background: 0.9989, Recall.scratch: 0.7365, Recall.stain: 0.8670, Recall.edgeDamage: 0.9321, Dice.background: 0.9987, Dice.scratch: 0.6844, Dice.stain: 0.8496, Dice.edgeDamage: 0.6645
2023-11-24 22:03:34,348 - mmseg - INFO - Iter [1550/10000]	lr: 8.735e-05, eta: 1:15:31, time: 0.982, data_time: 0.529, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2384, decode.acc_seg: 99.6906, loss: 0.2394
2023-11-24 22:03:59,831 - mmseg - INFO - Iter [1600/10000]	lr: 8.694e-05, eta: 1:14:58, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2351, decode.acc_seg: 99.7021, loss: 0.2362
2023-11-24 22:04:22,701 - mmseg - INFO - Iter [1650/10000]	lr: 8.653e-05, eta: 1:14:11, time: 0.457, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2370, decode.acc_seg: 99.7132, loss: 0.2380
2023-11-24 22:04:48,213 - mmseg - INFO - Iter [1700/10000]	lr: 8.611e-05, eta: 1:13:39, time: 0.510, data_time: 0.055, memory: 13918, decode.loss_focal: 0.0011, decode.loss_dice: 0.2313, decode.acc_seg: 99.6779, loss: 0.2323
2023-11-24 22:05:11,143 - mmseg - INFO - Iter [1750/10000]	lr: 8.570e-05, eta: 1:12:55, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2324, decode.acc_seg: 99.6937, loss: 0.2334
2023-11-24 22:05:36,663 - mmseg - INFO - Iter [1800/10000]	lr: 8.529e-05, eta: 1:12:24, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2297, decode.acc_seg: 99.7192, loss: 0.2307
2023-11-24 22:05:59,587 - mmseg - INFO - Iter [1850/10000]	lr: 8.487e-05, eta: 1:11:41, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2250, decode.acc_seg: 99.7236, loss: 0.2259
2023-11-24 22:06:25,355 - mmseg - INFO - Iter [1900/10000]	lr: 8.446e-05, eta: 1:11:12, time: 0.515, data_time: 0.058, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2312, decode.acc_seg: 99.6776, loss: 0.2322
2023-11-24 22:06:48,286 - mmseg - INFO - Iter [1950/10000]	lr: 8.405e-05, eta: 1:10:32, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2299, decode.acc_seg: 99.6922, loss: 0.2309
2023-11-24 22:07:13,855 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 22:07:13,855 - mmseg - INFO - Iter [2000/10000]	lr: 8.363e-05, eta: 1:10:03, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2207, decode.acc_seg: 99.7324, loss: 0.2217
2023-11-24 22:07:38,250 - mmseg - INFO - per class results:
2023-11-24 22:07:38,251 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background |  99.9 | 70.47 | 71.96 |  70.4 | 99.87 | 99.93  |   99.94   | 99.91  | 99.89 |
|  scratch   | 81.75 | 88.62 | 73.47 | 77.95 |  65.9 | 80.23  |   84.11   | 77.27  | 70.34 |
|   stain    | 89.28 | 81.09 | 72.62 | 73.71 | 84.98 | 90.19  |   90.39   | 89.99  | 85.28 |
| edgeDamage | 82.96 | 87.41 | 73.57 | 78.46 | 91.29 | 82.07  |   75.73   |  94.2  |  73.1 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 22:07:38,251 - mmseg - INFO - Summary:
2023-11-24 22:07:38,251 - mmseg - INFO - 
+------+-------+------+------+-------+-------+---------+------------+---------+-------+
| aAcc |  mIoU | mVOE | mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+------+-------+------+------+-------+-------+---------+------------+---------+-------+
| 99.9 | 88.47 | 81.9 | 72.9 | 75.13 | 85.51 |   88.1  |   87.54    |  90.34  | 82.15 |
+------+-------+------+------+-------+-------+---------+------------+---------+-------+
2023-11-24 22:07:38,267 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 22:07:38,267 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9990, mIoU: 0.8847, mVOE: 0.8190, mASD: 0.7290, mMSSD: 0.7513, mAcc: 0.8551, mFscore: 0.8810, mPrecision: 0.8754, mRecall: 0.9034, mDice: 0.8215, IoU.background: 0.9990, IoU.scratch: 0.8175, IoU.stain: 0.8928, IoU.edgeDamage: 0.8296, VOE.background: 0.7047, VOE.scratch: 0.8862, VOE.stain: 0.8109, VOE.edgeDamage: 0.8741, ASD.background: 0.7196, ASD.scratch: 0.7347, ASD.stain: 0.7262, ASD.edgeDamage: 0.7357, MSSD.background: 0.7040, MSSD.scratch: 0.7795, MSSD.stain: 0.7371, MSSD.edgeDamage: 0.7846, Acc.background: 0.9987, Acc.scratch: 0.6590, Acc.stain: 0.8498, Acc.edgeDamage: 0.9129, Fscore.background: 0.9993, Fscore.scratch: 0.8023, Fscore.stain: 0.9019, Fscore.edgeDamage: 0.8207, Precision.background: 0.9994, Precision.scratch: 0.8411, Precision.stain: 0.9039, Precision.edgeDamage: 0.7573, Recall.background: 0.9991, Recall.scratch: 0.7727, Recall.stain: 0.8999, Recall.edgeDamage: 0.9420, Dice.background: 0.9989, Dice.scratch: 0.7034, Dice.stain: 0.8528, Dice.edgeDamage: 0.7310
2023-11-24 22:08:01,176 - mmseg - INFO - Iter [2050/10000]	lr: 8.322e-05, eta: 1:10:58, time: 0.946, data_time: 0.493, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2312, decode.acc_seg: 99.6956, loss: 0.2321
2023-11-24 22:08:26,743 - mmseg - INFO - Iter [2100/10000]	lr: 8.280e-05, eta: 1:10:27, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2410, decode.acc_seg: 99.6740, loss: 0.2420
2023-11-24 22:08:49,761 - mmseg - INFO - Iter [2150/10000]	lr: 8.239e-05, eta: 1:09:46, time: 0.460, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2258, decode.acc_seg: 99.7201, loss: 0.2267
2023-11-24 22:09:15,285 - mmseg - INFO - Iter [2200/10000]	lr: 8.197e-05, eta: 1:09:16, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2129, decode.acc_seg: 99.6979, loss: 0.2138
2023-11-24 22:09:38,174 - mmseg - INFO - Iter [2250/10000]	lr: 8.156e-05, eta: 1:08:36, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2200, decode.acc_seg: 99.7267, loss: 0.2209
2023-11-24 22:10:03,650 - mmseg - INFO - Iter [2300/10000]	lr: 8.114e-05, eta: 1:08:06, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2215, decode.acc_seg: 99.7298, loss: 0.2224
2023-11-24 22:10:26,532 - mmseg - INFO - Iter [2350/10000]	lr: 8.073e-05, eta: 1:07:27, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2283, decode.acc_seg: 99.6831, loss: 0.2293
2023-11-24 22:10:52,232 - mmseg - INFO - Iter [2400/10000]	lr: 8.031e-05, eta: 1:06:58, time: 0.514, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2299, decode.acc_seg: 99.6995, loss: 0.2308
2023-11-24 22:11:17,905 - mmseg - INFO - Iter [2450/10000]	lr: 7.990e-05, eta: 1:06:30, time: 0.513, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2175, decode.acc_seg: 99.6933, loss: 0.2184
2023-11-24 22:11:40,790 - mmseg - INFO - Iter [2500/10000]	lr: 7.948e-05, eta: 1:05:53, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2236, decode.acc_seg: 99.7151, loss: 0.2245
2023-11-24 22:12:04,449 - mmseg - INFO - per class results:
2023-11-24 22:12:04,450 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.93 | 70.44 | 71.96 | 70.39 | 99.94 | 99.95  |   99.93   | 99.96  | 99.92 |
|  scratch   | 81.02 | 89.35 |  73.7 | 79.13 |  60.6 | 79.05  |   88.77   | 73.74  | 68.58 |
|   stain    | 88.84 | 81.53 | 72.67 | 73.93 | 83.98 | 89.69  |   90.07   | 89.32  | 84.54 |
| edgeDamage | 87.61 | 82.76 | 72.93 | 75.24 | 87.62 | 88.25  |   85.38   | 91.74  | 82.38 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 22:12:04,450 - mmseg - INFO - Summary:
2023-11-24 22:12:04,451 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.93 | 89.35 | 81.02 | 72.81 | 74.67 | 83.03 |  89.24  |   91.04    |  88.69  | 83.85 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-24 22:12:04,467 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9993, mIoU: 0.8935, mVOE: 0.8102, mASD: 0.7281, mMSSD: 0.7467, mAcc: 0.8303, mFscore: 0.8924, mPrecision: 0.9104, mRecall: 0.8869, mDice: 0.8385, IoU.background: 0.9993, IoU.scratch: 0.8102, IoU.stain: 0.8884, IoU.edgeDamage: 0.8761, VOE.background: 0.7044, VOE.scratch: 0.8935, VOE.stain: 0.8153, VOE.edgeDamage: 0.8276, ASD.background: 0.7196, ASD.scratch: 0.7370, ASD.stain: 0.7267, ASD.edgeDamage: 0.7293, MSSD.background: 0.7039, MSSD.scratch: 0.7913, MSSD.stain: 0.7393, MSSD.edgeDamage: 0.7524, Acc.background: 0.9994, Acc.scratch: 0.6060, Acc.stain: 0.8398, Acc.edgeDamage: 0.8762, Fscore.background: 0.9995, Fscore.scratch: 0.7905, Fscore.stain: 0.8969, Fscore.edgeDamage: 0.8825, Precision.background: 0.9993, Precision.scratch: 0.8877, Precision.stain: 0.9007, Precision.edgeDamage: 0.8538, Recall.background: 0.9996, Recall.scratch: 0.7374, Recall.stain: 0.8932, Recall.edgeDamage: 0.9174, Dice.background: 0.9992, Dice.scratch: 0.6858, Dice.stain: 0.8454, Dice.edgeDamage: 0.8238
2023-11-24 22:12:29,973 - mmseg - INFO - Iter [2550/10000]	lr: 7.906e-05, eta: 1:06:33, time: 0.984, data_time: 0.531, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2145, decode.acc_seg: 99.7208, loss: 0.2154
2023-11-24 22:12:52,932 - mmseg - INFO - Iter [2600/10000]	lr: 7.864e-05, eta: 1:05:55, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2165, decode.acc_seg: 99.6967, loss: 0.2174
2023-11-24 22:13:18,425 - mmseg - INFO - Iter [2650/10000]	lr: 7.823e-05, eta: 1:05:25, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2221, decode.acc_seg: 99.7156, loss: 0.2229
2023-11-24 22:13:41,414 - mmseg - INFO - Iter [2700/10000]	lr: 7.781e-05, eta: 1:04:48, time: 0.460, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2204, decode.acc_seg: 99.7344, loss: 0.2213
2023-11-24 22:14:07,029 - mmseg - INFO - Iter [2750/10000]	lr: 7.739e-05, eta: 1:04:19, time: 0.512, data_time: 0.057, memory: 13918, decode.loss_focal: 0.0010, decode.loss_dice: 0.2150, decode.acc_seg: 99.6875, loss: 0.2160
2023-11-24 22:14:29,949 - mmseg - INFO - Iter [2800/10000]	lr: 7.697e-05, eta: 1:03:43, time: 0.458, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2108, decode.acc_seg: 99.7205, loss: 0.2117
2023-11-24 22:14:55,441 - mmseg - INFO - Iter [2850/10000]	lr: 7.655e-05, eta: 1:03:14, time: 0.510, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2210, decode.acc_seg: 99.7146, loss: 0.2218
2023-11-24 22:15:18,368 - mmseg - INFO - Iter [2900/10000]	lr: 7.613e-05, eta: 1:02:38, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2271, decode.acc_seg: 99.6892, loss: 0.2281
2023-11-24 22:15:43,904 - mmseg - INFO - Iter [2950/10000]	lr: 7.572e-05, eta: 1:02:10, time: 0.511, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0008, decode.loss_dice: 0.2191, decode.acc_seg: 99.7124, loss: 0.2200
2023-11-24 22:16:06,871 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 22:16:06,872 - mmseg - INFO - Iter [3000/10000]	lr: 7.530e-05, eta: 1:01:35, time: 0.459, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2066, decode.acc_seg: 99.7096, loss: 0.2075
2023-11-24 22:16:30,437 - mmseg - INFO - per class results:
2023-11-24 22:16:30,438 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background |  99.9 | 70.47 | 71.96 |  70.4 | 99.87 | 99.92  |   99.94   | 99.91  | 99.89 |
|  scratch   | 81.71 | 88.66 | 73.58 |  78.5 |  63.4 | 80.16  |   87.42   |  75.6  | 70.24 |
|   stain    | 89.02 | 81.35 | 72.73 | 74.28 | 82.42 | 89.89  |   91.66   | 88.28  | 84.83 |
| edgeDamage | 81.93 | 88.44 | 73.68 | 79.01 | 90.63 |  80.5  |   74.07   | 93.76  | 70.75 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-24 22:16:30,438 - mmseg - INFO - Summary:
2023-11-24 22:16:30,439 - mmseg - INFO - 
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.9 | 88.14 | 82.23 | 72.99 | 75.55 | 84.08 |  87.62  |   88.27    |  89.39  | 81.43 |
+------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-24 22:16:30,454 - mmseg - INFO - Exp name: unet_all.py
2023-11-24 22:16:30,454 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9990, mIoU: 0.8814, mVOE: 0.8223, mASD: 0.7299, mMSSD: 0.7555, mAcc: 0.8408, mFscore: 0.8762, mPrecision: 0.8827, mRecall: 0.8939, mDice: 0.8143, IoU.background: 0.9990, IoU.scratch: 0.8171, IoU.stain: 0.8902, IoU.edgeDamage: 0.8193, VOE.background: 0.7047, VOE.scratch: 0.8866, VOE.stain: 0.8135, VOE.edgeDamage: 0.8844, ASD.background: 0.7196, ASD.scratch: 0.7358, ASD.stain: 0.7273, ASD.edgeDamage: 0.7368, MSSD.background: 0.7040, MSSD.scratch: 0.7850, MSSD.stain: 0.7428, MSSD.edgeDamage: 0.7901, Acc.background: 0.9987, Acc.scratch: 0.6340, Acc.stain: 0.8242, Acc.edgeDamage: 0.9063, Fscore.background: 0.9992, Fscore.scratch: 0.8016, Fscore.stain: 0.8989, Fscore.edgeDamage: 0.8050, Precision.background: 0.9994, Precision.scratch: 0.8742, Precision.stain: 0.9166, Precision.edgeDamage: 0.7407, Recall.background: 0.9991, Recall.scratch: 0.7560, Recall.stain: 0.8828, Recall.edgeDamage: 0.9376, Dice.background: 0.9989, Dice.scratch: 0.7024, Dice.stain: 0.8483, Dice.edgeDamage: 0.7075
2023-11-24 22:16:55,898 - mmseg - INFO - Iter [3050/10000]	lr: 7.488e-05, eta: 1:02:00, time: 0.981, data_time: 0.528, memory: 13918, decode.loss_focal: 0.0009, decode.loss_dice: 0.2136, decode.acc_seg: 99.6924, loss: 0.2145
2023-11-24 22:17:18,904 - mmseg - INFO - Iter [3100/10000]	lr: 7.446e-05, eta: 1:01:25, time: 0.460, data_time: 0.004, memory: 13918, decode.loss_focal: 0.0008, decode.loss_dice: 0.2154, decode.acc_seg: 99.7437, loss: 0.2161
2023-11-24 22:17:44,589 - mmseg - INFO - Iter [3150/10000]	lr: 7.404e-05, eta: 1:00:56, time: 0.514, data_time: 0.056, memory: 13918, decode.loss_focal: 0.0007, decode.loss_dice: 0.2048, decode.acc_seg: 99.7550, loss: 0.2055
