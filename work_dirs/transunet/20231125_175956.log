2023-11-25 17:59:56,977 - mmseg - INFO - Multi-processing start method is `None`
2023-11-25 17:59:57,004 - mmseg - INFO - OpenCV num_threads is `6
2023-11-25 17:59:57,134 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /environment/miniconda3
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.1
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.1+
------------------------------------------------------------

2023-11-25 17:59:57,135 - mmseg - INFO - Distributed training: False
2023-11-25 17:59:57,470 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
backbone_norm_cfg = dict(type='LN', requires_grad=True)
model = dict(
    type='EncoderDecoderFull',
    pretrained=None,
    decode_head=dict(
        type='TransUNet',
        img_dim=512,
        in_channels=3,
        out_channels=128,
        head_num=4,
        mlp_dim=512,
        block_num=8,
        patch_dim=16,
        class_num=4,
        loss_decode=[
            dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                loss_weight=2.0),
            dict(type='DiceLoss', loss_name='loss_dice', loss_weight=2.0)
        ]))
train_cfg = dict()
test_cfg = dict(mode='whole')
dataset_type = 'MyDataset'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(600, 600)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=False),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data_root = './datasets/'
data = dict(
    samples_per_gpu=5,
    workers_per_gpu=2,
    train=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='train/images',
        ann_dir='train/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(600, 600)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='Normalize', mean=[0, 0, 0], std=[1, 1, 1], to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='MyDataset',
        data_root='./datasets/',
        img_dir='test/images',
        ann_dir='test/labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=False),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[1, 1, 1],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TensorboardLoggerHook'),
        dict(type='TextLoggerHook', by_epoch=False)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = False
find_unused_parameters = True
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.999))
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=1e-05, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=5000)
checkpoint_config = dict(by_epoch=False, save_optimizer=False, interval=5000)
evaluation = dict(interval=500, metric=['mIoU', 'mFscore', 'mDice'])
work_dir = './work_dirs/transunet'
gpu_ids = [0]
auto_resume = False

2023-11-25 17:59:57,470 - mmseg - INFO - Set random seed to 1130878302, deterministic: False
2023-11-25 17:59:58,029 - mmseg - INFO - initialize TransUNet with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

decode_head.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([2]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.encoder.conv1.weight - torch.Size([128, 3, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.conv1.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.conv3.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder1.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.conv1.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.conv3.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder2.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.conv1.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.conv2.weight - torch.Size([1024, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.conv3.weight - torch.Size([1024, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.encoder3.norm3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.embedding - torch.Size([1025, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.cls_token - torch.Size([1, 1, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.projection.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.projection.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.0.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.1.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.2.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.3.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.4.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.5.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.6.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.multi_head_attention.qkv_layer.weight - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.multi_head_attention.out_attention.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.mlp.mlp_layers.0.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.mlp.mlp_layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.mlp.mlp_layers.3.weight - torch.Size([1024, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.mlp.mlp_layers.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.layer_norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.layer_norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.layer_norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.vit.transformer.layer_blocks.7.layer_norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.conv2.weight - torch.Size([512, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.conv2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.encoder.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.0.weight - torch.Size([256, 1024, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder1.layer.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.0.weight - torch.Size([128, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder2.layer.4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder3.layer.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.0.weight - torch.Size([16, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.0.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.3.weight - torch.Size([16, 16, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.3.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.4.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.decoder4.layer.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.conv1.weight - torch.Size([4, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  

decode_head.decoder.conv1.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of EncoderDecoderFull  
2023-11-25 17:59:58,053 - mmseg - INFO - EncoderDecoderFull(
  (decode_head): TransUNet(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): FocalLoss()
      (1): DiceLoss()
    )
    (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (encoder): Encoder(
      (conv1): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (encoder1): EncoderBottleneck(
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (encoder2): EncoderBottleneck(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (encoder3): EncoderBottleneck(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (vit): ViT(
        (projection): Linear(in_features=1024, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (transformer): TransformerEncoder(
          (layer_blocks): ModuleList(
            (0): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (6): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (7): TransformerEncoderBlock(
              (multi_head_attention): MultiHeadAttention(
                (qkv_layer): Linear(in_features=1024, out_features=3072, bias=False)
                (out_attention): Linear(in_features=1024, out_features=1024, bias=False)
              )
              (mlp): MLP(
                (mlp_layers): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (decoder): Decoder(
      (decoder1): DecoderBottleneck(
        (upsample): Upsample(scale_factor=2.0, mode=bilinear)
        (layer): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (decoder2): DecoderBottleneck(
        (upsample): Upsample(scale_factor=2.0, mode=bilinear)
        (layer): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (decoder3): DecoderBottleneck(
        (upsample): Upsample(scale_factor=2.0, mode=bilinear)
        (layer): Sequential(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (decoder4): DecoderBottleneck(
        (upsample): Upsample(scale_factor=2.0, mode=bilinear)
        (layer): Sequential(
          (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (conv1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-25 17:59:58,520 - mmseg - INFO - Loaded 474 images
2023-11-25 18:00:39,617 - mmseg - INFO - Loaded 105 images
2023-11-25 18:00:39,618 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/work/test/work_dirs/transunet
2023-11-25 18:00:39,619 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-25 18:00:39,620 - mmseg - INFO - workflow: [('train', 1)], max: 5000 iters
2023-11-25 18:00:39,620 - mmseg - INFO - Checkpoints will be saved to /home/featurize/work/test/work_dirs/transunet by HardDiskBackend.
2023-11-25 18:01:06,366 - mmseg - INFO - Iter [50/5000]	lr: 9.921e-05, eta: 0:40:47, time: 0.494, data_time: 0.168, memory: 7443, decode.loss_focal: 0.2510, decode.loss_dice: 1.6807, decode.acc_seg: 89.8366, loss: 1.9317
2023-11-25 18:01:29,301 - mmseg - INFO - Iter [100/5000]	lr: 9.839e-05, eta: 0:38:55, time: 0.459, data_time: 0.181, memory: 7443, decode.loss_focal: 0.2157, decode.loss_dice: 1.6439, decode.acc_seg: 98.6707, loss: 1.8595
2023-11-25 18:01:43,301 - mmseg - INFO - Iter [150/5000]	lr: 9.758e-05, eta: 0:33:13, time: 0.280, data_time: 0.004, memory: 7443, decode.loss_focal: 0.2026, decode.loss_dice: 1.6310, decode.acc_seg: 99.2466, loss: 1.8335
2023-11-25 18:01:59,930 - mmseg - INFO - Iter [200/5000]	lr: 9.677e-05, eta: 0:31:18, time: 0.333, data_time: 0.057, memory: 7443, decode.loss_focal: 0.1936, decode.loss_dice: 1.6158, decode.acc_seg: 98.8655, loss: 1.8094
2023-11-25 18:02:14,251 - mmseg - INFO - Iter [250/5000]	lr: 9.596e-05, eta: 0:29:19, time: 0.286, data_time: 0.007, memory: 7443, decode.loss_focal: 0.1863, decode.loss_dice: 1.6052, decode.acc_seg: 99.0051, loss: 1.7915
2023-11-25 18:02:31,214 - mmseg - INFO - Iter [300/5000]	lr: 9.514e-05, eta: 0:28:36, time: 0.339, data_time: 0.062, memory: 7443, decode.loss_focal: 0.1794, decode.loss_dice: 1.5971, decode.acc_seg: 99.1486, loss: 1.7765
2023-11-25 18:02:45,565 - mmseg - INFO - Iter [350/5000]	lr: 9.433e-05, eta: 0:27:26, time: 0.287, data_time: 0.009, memory: 7443, decode.loss_focal: 0.1730, decode.loss_dice: 1.5844, decode.acc_seg: 99.1372, loss: 1.7573
2023-11-25 18:03:02,177 - mmseg - INFO - Iter [400/5000]	lr: 9.351e-05, eta: 0:26:56, time: 0.332, data_time: 0.055, memory: 7443, decode.loss_focal: 0.1664, decode.loss_dice: 1.5773, decode.acc_seg: 99.2261, loss: 1.7436
2023-11-25 18:03:16,332 - mmseg - INFO - Iter [450/5000]	lr: 9.269e-05, eta: 0:26:04, time: 0.283, data_time: 0.004, memory: 7443, decode.loss_focal: 0.1601, decode.loss_dice: 1.5692, decode.acc_seg: 99.2269, loss: 1.7293
2023-11-25 18:03:32,918 - mmseg - INFO - Iter [500/5000]	lr: 9.187e-05, eta: 0:25:41, time: 0.332, data_time: 0.055, memory: 7443, decode.loss_focal: 0.1539, decode.loss_dice: 1.5601, decode.acc_seg: 99.3031, loss: 1.7140
2023-11-25 18:03:55,932 - mmseg - INFO - per class results:
2023-11-25 18:03:55,933 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 98.91 | 71.46 | 71.93 | 70.88 |  97.7 | 99.17  |    99.9   | 98.47  | 98.75 |
|  scratch   | 70.37 | 100.0 |  74.8 | 85.19 | 33.33 |  nan   |   55.56   | 55.56  | 33.33 |
|   stain    | 74.69 | 95.68 | 74.35 | 82.96 | 88.27 | 66.86  |   62.24   | 92.18  | 50.29 |
| edgeDamage | 71.31 | 99.06 |  74.7 | 84.71 | 86.53 | 58.29  |   56.98   | 91.02  | 37.44 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:03:55,933 - mmseg - INFO - Summary:
2023-11-25 18:03:55,934 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 98.91 | 78.82 | 91.55 | 73.95 | 80.93 | 76.46 |  74.77  |   68.67    |   84.3  | 54.95 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:03:55,952 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9891, mIoU: 0.7882, mVOE: 0.9155, mASD: 0.7395, mMSSD: 0.8093, mAcc: 0.7646, mFscore: 0.7477, mPrecision: 0.6867, mRecall: 0.8430, mDice: 0.5495, IoU.background: 0.9891, IoU.scratch: 0.7037, IoU.stain: 0.7469, IoU.edgeDamage: 0.7131, VOE.background: 0.7146, VOE.scratch: 1.0000, VOE.stain: 0.9568, VOE.edgeDamage: 0.9906, ASD.background: 0.7193, ASD.scratch: 0.7480, ASD.stain: 0.7435, ASD.edgeDamage: 0.7470, MSSD.background: 0.7088, MSSD.scratch: 0.8519, MSSD.stain: 0.8296, MSSD.edgeDamage: 0.8471, Acc.background: 0.9770, Acc.scratch: 0.3333, Acc.stain: 0.8827, Acc.edgeDamage: 0.8653, Fscore.background: 0.9917, Fscore.scratch: nan, Fscore.stain: 0.6686, Fscore.edgeDamage: 0.5829, Precision.background: 0.9990, Precision.scratch: 0.5556, Precision.stain: 0.6224, Precision.edgeDamage: 0.5698, Recall.background: 0.9847, Recall.scratch: 0.5556, Recall.stain: 0.9218, Recall.edgeDamage: 0.9102, Dice.background: 0.9875, Dice.scratch: 0.3333, Dice.stain: 0.5029, Dice.edgeDamage: 0.3744
2023-11-25 18:04:10,031 - mmseg - INFO - Iter [550/5000]	lr: 9.106e-05, eta: 0:28:05, time: 0.742, data_time: 0.465, memory: 7443, decode.loss_focal: 0.1476, decode.loss_dice: 1.5457, decode.acc_seg: 99.2363, loss: 1.6932
2023-11-25 18:04:26,720 - mmseg - INFO - Iter [600/5000]	lr: 9.024e-05, eta: 0:27:30, time: 0.334, data_time: 0.056, memory: 7443, decode.loss_focal: 0.1412, decode.loss_dice: 1.5438, decode.acc_seg: 99.2824, loss: 1.6849
2023-11-25 18:04:41,095 - mmseg - INFO - Iter [650/5000]	lr: 8.941e-05, eta: 0:26:42, time: 0.287, data_time: 0.010, memory: 7443, decode.loss_focal: 0.1351, decode.loss_dice: 1.5274, decode.acc_seg: 99.3089, loss: 1.6625
2023-11-25 18:04:58,087 - mmseg - INFO - Iter [700/5000]	lr: 8.859e-05, eta: 0:26:15, time: 0.340, data_time: 0.060, memory: 7443, decode.loss_focal: 0.1296, decode.loss_dice: 1.5232, decode.acc_seg: 99.2766, loss: 1.6528
2023-11-25 18:05:12,233 - mmseg - INFO - Iter [750/5000]	lr: 8.777e-05, eta: 0:25:33, time: 0.283, data_time: 0.006, memory: 7443, decode.loss_focal: 0.1244, decode.loss_dice: 1.5163, decode.acc_seg: 99.2701, loss: 1.6407
2023-11-25 18:05:28,885 - mmseg - INFO - Iter [800/5000]	lr: 8.695e-05, eta: 0:25:07, time: 0.333, data_time: 0.057, memory: 7443, decode.loss_focal: 0.1190, decode.loss_dice: 1.5071, decode.acc_seg: 99.3118, loss: 1.6261
2023-11-25 18:05:46,375 - mmseg - INFO - Iter [850/5000]	lr: 8.612e-05, eta: 0:24:47, time: 0.350, data_time: 0.072, memory: 7443, decode.loss_focal: 0.1143, decode.loss_dice: 1.4990, decode.acc_seg: 99.2745, loss: 1.6134
2023-11-25 18:06:00,460 - mmseg - INFO - Iter [900/5000]	lr: 8.530e-05, eta: 0:24:12, time: 0.282, data_time: 0.005, memory: 7443, decode.loss_focal: 0.1116, decode.loss_dice: 1.4891, decode.acc_seg: 99.1721, loss: 1.6007
2023-11-25 18:06:17,137 - mmseg - INFO - Iter [950/5000]	lr: 8.447e-05, eta: 0:23:50, time: 0.334, data_time: 0.056, memory: 7443, decode.loss_focal: 0.1106, decode.loss_dice: 1.4780, decode.acc_seg: 99.0833, loss: 1.5886
2023-11-25 18:06:32,144 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:06:32,145 - mmseg - INFO - Iter [1000/5000]	lr: 8.364e-05, eta: 0:23:21, time: 0.300, data_time: 0.020, memory: 7443, decode.loss_focal: 0.1066, decode.loss_dice: 1.4563, decode.acc_seg: 98.9268, loss: 1.5629
2023-11-25 18:06:53,075 - mmseg - INFO - per class results:
2023-11-25 18:06:53,076 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 98.96 | 71.41 | 71.93 | 70.86 |  97.8 | 99.21  |   99.91   | 98.53  | 98.81 |
|  scratch   | 72.71 | 97.66 |  74.4 | 83.19 | 44.07 | 62.07  |   61.53   | 62.71  | 43.11 |
|   stain    | 75.54 | 94.83 | 74.27 | 82.55 | 93.69 | 68.76  |   63.45   | 95.79  | 53.14 |
| edgeDamage | 71.34 | 99.04 |  74.7 |  84.7 | 82.71 | 58.36  |   57.02   | 88.47  | 37.54 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:06:53,076 - mmseg - INFO - Summary:
2023-11-25 18:06:53,077 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 98.96 | 79.64 | 90.73 | 73.82 | 80.33 | 79.57 |   72.1  |   70.48    |  86.38  | 58.15 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:06:53,092 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:06:53,092 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9896, mIoU: 0.7964, mVOE: 0.9073, mASD: 0.7382, mMSSD: 0.8033, mAcc: 0.7957, mFscore: 0.7210, mPrecision: 0.7048, mRecall: 0.8638, mDice: 0.5815, IoU.background: 0.9896, IoU.scratch: 0.7271, IoU.stain: 0.7554, IoU.edgeDamage: 0.7134, VOE.background: 0.7141, VOE.scratch: 0.9766, VOE.stain: 0.9483, VOE.edgeDamage: 0.9904, ASD.background: 0.7193, ASD.scratch: 0.7440, ASD.stain: 0.7427, ASD.edgeDamage: 0.7470, MSSD.background: 0.7086, MSSD.scratch: 0.8319, MSSD.stain: 0.8255, MSSD.edgeDamage: 0.8470, Acc.background: 0.9780, Acc.scratch: 0.4407, Acc.stain: 0.9369, Acc.edgeDamage: 0.8271, Fscore.background: 0.9921, Fscore.scratch: 0.6207, Fscore.stain: 0.6876, Fscore.edgeDamage: 0.5836, Precision.background: 0.9991, Precision.scratch: 0.6153, Precision.stain: 0.6345, Precision.edgeDamage: 0.5702, Recall.background: 0.9853, Recall.scratch: 0.6271, Recall.stain: 0.9579, Recall.edgeDamage: 0.8847, Dice.background: 0.9881, Dice.scratch: 0.4311, Dice.stain: 0.5314, Dice.edgeDamage: 0.3754
2023-11-25 18:07:09,973 - mmseg - INFO - Iter [1050/5000]	lr: 8.281e-05, eta: 0:24:20, time: 0.757, data_time: 0.479, memory: 7443, decode.loss_focal: 0.1010, decode.loss_dice: 1.4533, decode.acc_seg: 99.0738, loss: 1.5543
2023-11-25 18:07:24,153 - mmseg - INFO - Iter [1100/5000]	lr: 8.198e-05, eta: 0:23:47, time: 0.284, data_time: 0.006, memory: 7443, decode.loss_focal: 0.0962, decode.loss_dice: 1.4371, decode.acc_seg: 99.0513, loss: 1.5333
2023-11-25 18:07:41,213 - mmseg - INFO - Iter [1150/5000]	lr: 8.115e-05, eta: 0:23:24, time: 0.341, data_time: 0.063, memory: 7443, decode.loss_focal: 0.0915, decode.loss_dice: 1.4219, decode.acc_seg: 99.1563, loss: 1.5135
2023-11-25 18:07:56,069 - mmseg - INFO - Iter [1200/5000]	lr: 8.032e-05, eta: 0:22:55, time: 0.297, data_time: 0.018, memory: 7443, decode.loss_focal: 0.0870, decode.loss_dice: 1.4168, decode.acc_seg: 99.1413, loss: 1.5038
2023-11-25 18:08:12,801 - mmseg - INFO - Iter [1250/5000]	lr: 7.949e-05, eta: 0:22:33, time: 0.335, data_time: 0.057, memory: 7443, decode.loss_focal: 0.0832, decode.loss_dice: 1.3886, decode.acc_seg: 99.1227, loss: 1.4717
2023-11-25 18:08:26,985 - mmseg - INFO - Iter [1300/5000]	lr: 7.865e-05, eta: 0:22:04, time: 0.284, data_time: 0.005, memory: 7443, decode.loss_focal: 0.0789, decode.loss_dice: 1.3961, decode.acc_seg: 99.1908, loss: 1.4750
2023-11-25 18:08:43,933 - mmseg - INFO - Iter [1350/5000]	lr: 7.782e-05, eta: 0:21:43, time: 0.339, data_time: 0.060, memory: 7443, decode.loss_focal: 0.0757, decode.loss_dice: 1.3826, decode.acc_seg: 99.1431, loss: 1.4584
2023-11-25 18:08:58,224 - mmseg - INFO - Iter [1400/5000]	lr: 7.698e-05, eta: 0:21:16, time: 0.286, data_time: 0.008, memory: 7443, decode.loss_focal: 0.0754, decode.loss_dice: 1.3603, decode.acc_seg: 99.2213, loss: 1.4357
2023-11-25 18:09:15,262 - mmseg - INFO - Iter [1450/5000]	lr: 7.614e-05, eta: 0:20:57, time: 0.341, data_time: 0.062, memory: 7443, decode.loss_focal: 0.0744, decode.loss_dice: 1.3474, decode.acc_seg: 99.2783, loss: 1.4218
2023-11-25 18:09:29,306 - mmseg - INFO - Iter [1500/5000]	lr: 7.530e-05, eta: 0:20:31, time: 0.281, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0708, decode.loss_dice: 1.3240, decode.acc_seg: 99.2649, loss: 1.3948
2023-11-25 18:09:50,609 - mmseg - INFO - per class results:
2023-11-25 18:09:50,610 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 98.84 | 71.53 | 71.94 | 70.93 | 97.47 | 99.11  |   99.93   | 98.31  | 98.66 |
|  scratch   | 73.79 | 96.58 | 74.37 | 83.05 | 58.03 | 64.76  |   61.95   | 72.02  | 47.14 |
|   stain    | 77.24 | 93.13 | 74.08 |  81.6 | 89.38 | 72.28  |   66.33   | 92.92  | 58.41 |
| edgeDamage |  71.4 | 98.97 | 74.69 | 84.67 | 92.34 | 58.54  |    57.1   | 94.89  |  37.8 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:09:50,610 - mmseg - INFO - Summary:
2023-11-25 18:09:50,610 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 98.84 | 80.32 | 90.05 | 73.77 | 80.06 | 84.31 |  73.67  |   71.33    |  89.54  | 60.51 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:09:50,626 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9884, mIoU: 0.8032, mVOE: 0.9005, mASD: 0.7377, mMSSD: 0.8006, mAcc: 0.8431, mFscore: 0.7367, mPrecision: 0.7133, mRecall: 0.8954, mDice: 0.6051, IoU.background: 0.9884, IoU.scratch: 0.7379, IoU.stain: 0.7724, IoU.edgeDamage: 0.7140, VOE.background: 0.7153, VOE.scratch: 0.9658, VOE.stain: 0.9313, VOE.edgeDamage: 0.9897, ASD.background: 0.7194, ASD.scratch: 0.7437, ASD.stain: 0.7408, ASD.edgeDamage: 0.7469, MSSD.background: 0.7093, MSSD.scratch: 0.8305, MSSD.stain: 0.8160, MSSD.edgeDamage: 0.8467, Acc.background: 0.9747, Acc.scratch: 0.5803, Acc.stain: 0.8938, Acc.edgeDamage: 0.9234, Fscore.background: 0.9911, Fscore.scratch: 0.6476, Fscore.stain: 0.7228, Fscore.edgeDamage: 0.5854, Precision.background: 0.9993, Precision.scratch: 0.6195, Precision.stain: 0.6633, Precision.edgeDamage: 0.5710, Recall.background: 0.9831, Recall.scratch: 0.7202, Recall.stain: 0.9292, Recall.edgeDamage: 0.9489, Dice.background: 0.9866, Dice.scratch: 0.4714, Dice.stain: 0.5841, Dice.edgeDamage: 0.3780
2023-11-25 18:10:07,687 - mmseg - INFO - Iter [1550/5000]	lr: 7.446e-05, eta: 0:20:59, time: 0.768, data_time: 0.491, memory: 7443, decode.loss_focal: 0.0664, decode.loss_dice: 1.3176, decode.acc_seg: 99.3532, loss: 1.3840
2023-11-25 18:10:24,917 - mmseg - INFO - Iter [1600/5000]	lr: 7.362e-05, eta: 0:20:39, time: 0.345, data_time: 0.066, memory: 7443, decode.loss_focal: 0.0635, decode.loss_dice: 1.2905, decode.acc_seg: 99.3319, loss: 1.3541
2023-11-25 18:10:39,928 - mmseg - INFO - Iter [1650/5000]	lr: 7.278e-05, eta: 0:20:14, time: 0.300, data_time: 0.024, memory: 7443, decode.loss_focal: 0.0600, decode.loss_dice: 1.2882, decode.acc_seg: 99.3511, loss: 1.3483
2023-11-25 18:10:56,625 - mmseg - INFO - Iter [1700/5000]	lr: 7.194e-05, eta: 0:19:53, time: 0.334, data_time: 0.057, memory: 7443, decode.loss_focal: 0.0572, decode.loss_dice: 1.2773, decode.acc_seg: 99.4346, loss: 1.3345
2023-11-25 18:11:10,846 - mmseg - INFO - Iter [1750/5000]	lr: 7.109e-05, eta: 0:19:28, time: 0.284, data_time: 0.006, memory: 7443, decode.loss_focal: 0.0545, decode.loss_dice: 1.2546, decode.acc_seg: 99.4449, loss: 1.3091
2023-11-25 18:11:27,558 - mmseg - INFO - Iter [1800/5000]	lr: 7.025e-05, eta: 0:19:08, time: 0.334, data_time: 0.058, memory: 7443, decode.loss_focal: 0.0519, decode.loss_dice: 1.2378, decode.acc_seg: 99.4159, loss: 1.2897
2023-11-25 18:11:41,699 - mmseg - INFO - Iter [1850/5000]	lr: 6.940e-05, eta: 0:18:43, time: 0.283, data_time: 0.006, memory: 7443, decode.loss_focal: 0.0498, decode.loss_dice: 1.2364, decode.acc_seg: 99.4217, loss: 1.2861
2023-11-25 18:11:58,922 - mmseg - INFO - Iter [1900/5000]	lr: 6.855e-05, eta: 0:18:25, time: 0.344, data_time: 0.067, memory: 7443, decode.loss_focal: 0.0470, decode.loss_dice: 1.2276, decode.acc_seg: 99.5045, loss: 1.2746
2023-11-25 18:12:12,904 - mmseg - INFO - Iter [1950/5000]	lr: 6.770e-05, eta: 0:18:01, time: 0.280, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0453, decode.loss_dice: 1.2116, decode.acc_seg: 99.5068, loss: 1.2569
2023-11-25 18:12:29,523 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:12:29,523 - mmseg - INFO - Iter [2000/5000]	lr: 6.685e-05, eta: 0:17:41, time: 0.332, data_time: 0.056, memory: 7443, decode.loss_focal: 0.0439, decode.loss_dice: 1.1847, decode.acc_seg: 99.5058, loss: 1.2286
2023-11-25 18:12:50,115 - mmseg - INFO - per class results:
2023-11-25 18:12:50,116 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.07 |  71.3 | 71.92 | 70.81 | 98.01 | 99.29  |   99.92   | 98.67  | 98.93 |
|  scratch   | 77.39 | 92.98 | 73.89 | 80.67 | 53.66 | 72.58  |   78.45   | 69.11  | 58.87 |
|   stain    | 88.96 | 81.41 | 72.52 | 73.82 | 84.47 | 89.83  |   90.01   | 89.65  | 84.74 |
| edgeDamage | 71.46 | 98.91 | 74.69 | 84.64 | 90.24 |  58.7  |   57.19   | 93.49  | 38.05 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:12:50,116 - mmseg - INFO - Summary:
2023-11-25 18:12:50,116 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.07 | 84.22 | 86.15 | 73.26 | 77.49 | 81.59 |   80.1  |    81.4    |  87.73  | 70.15 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:12:50,132 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:12:50,132 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9907, mIoU: 0.8422, mVOE: 0.8615, mASD: 0.7326, mMSSD: 0.7749, mAcc: 0.8159, mFscore: 0.8010, mPrecision: 0.8140, mRecall: 0.8773, mDice: 0.7015, IoU.background: 0.9907, IoU.scratch: 0.7739, IoU.stain: 0.8896, IoU.edgeDamage: 0.7146, VOE.background: 0.7130, VOE.scratch: 0.9298, VOE.stain: 0.8141, VOE.edgeDamage: 0.9891, ASD.background: 0.7192, ASD.scratch: 0.7389, ASD.stain: 0.7252, ASD.edgeDamage: 0.7469, MSSD.background: 0.7081, MSSD.scratch: 0.8067, MSSD.stain: 0.7382, MSSD.edgeDamage: 0.8464, Acc.background: 0.9801, Acc.scratch: 0.5366, Acc.stain: 0.8447, Acc.edgeDamage: 0.9024, Fscore.background: 0.9929, Fscore.scratch: 0.7258, Fscore.stain: 0.8983, Fscore.edgeDamage: 0.5870, Precision.background: 0.9992, Precision.scratch: 0.7845, Precision.stain: 0.9001, Precision.edgeDamage: 0.5719, Recall.background: 0.9867, Recall.scratch: 0.6911, Recall.stain: 0.8965, Recall.edgeDamage: 0.9349, Dice.background: 0.9893, Dice.scratch: 0.5887, Dice.stain: 0.8474, Dice.edgeDamage: 0.3805
2023-11-25 18:13:04,397 - mmseg - INFO - Iter [2050/5000]	lr: 6.599e-05, eta: 0:17:48, time: 0.697, data_time: 0.421, memory: 7443, decode.loss_focal: 0.0424, decode.loss_dice: 1.1952, decode.acc_seg: 99.5042, loss: 1.2376
2023-11-25 18:13:21,294 - mmseg - INFO - Iter [2100/5000]	lr: 6.514e-05, eta: 0:17:29, time: 0.338, data_time: 0.061, memory: 7443, decode.loss_focal: 0.0406, decode.loss_dice: 1.1816, decode.acc_seg: 99.5158, loss: 1.2223
2023-11-25 18:13:35,285 - mmseg - INFO - Iter [2150/5000]	lr: 6.428e-05, eta: 0:17:05, time: 0.280, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0385, decode.loss_dice: 1.1667, decode.acc_seg: 99.5800, loss: 1.2052
2023-11-25 18:13:51,931 - mmseg - INFO - Iter [2200/5000]	lr: 6.343e-05, eta: 0:16:45, time: 0.333, data_time: 0.055, memory: 7443, decode.loss_focal: 0.0372, decode.loss_dice: 1.1284, decode.acc_seg: 99.5972, loss: 1.1656
2023-11-25 18:14:06,361 - mmseg - INFO - Iter [2250/5000]	lr: 6.257e-05, eta: 0:16:23, time: 0.289, data_time: 0.012, memory: 7443, decode.loss_focal: 0.0356, decode.loss_dice: 1.1489, decode.acc_seg: 99.5320, loss: 1.1845
2023-11-25 18:14:23,348 - mmseg - INFO - Iter [2300/5000]	lr: 6.171e-05, eta: 0:16:04, time: 0.340, data_time: 0.061, memory: 7443, decode.loss_focal: 0.0341, decode.loss_dice: 1.1392, decode.acc_seg: 99.6061, loss: 1.1732
2023-11-25 18:14:37,595 - mmseg - INFO - Iter [2350/5000]	lr: 6.084e-05, eta: 0:15:42, time: 0.285, data_time: 0.007, memory: 7443, decode.loss_focal: 0.0329, decode.loss_dice: 1.1296, decode.acc_seg: 99.5486, loss: 1.1625
2023-11-25 18:14:54,554 - mmseg - INFO - Iter [2400/5000]	lr: 5.998e-05, eta: 0:15:23, time: 0.339, data_time: 0.061, memory: 7443, decode.loss_focal: 0.0313, decode.loss_dice: 1.1237, decode.acc_seg: 99.6032, loss: 1.1551
2023-11-25 18:15:11,228 - mmseg - INFO - Iter [2450/5000]	lr: 5.911e-05, eta: 0:15:05, time: 0.333, data_time: 0.055, memory: 7443, decode.loss_focal: 0.0299, decode.loss_dice: 1.1091, decode.acc_seg: 99.6101, loss: 1.1390
2023-11-25 18:15:25,381 - mmseg - INFO - Iter [2500/5000]	lr: 5.825e-05, eta: 0:14:43, time: 0.283, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0285, decode.loss_dice: 1.1013, decode.acc_seg: 99.5840, loss: 1.1298
2023-11-25 18:15:47,088 - mmseg - INFO - per class results:
2023-11-25 18:15:47,090 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.06 | 71.31 | 71.92 | 70.82 | 97.99 | 99.29  |   99.93   | 98.66  | 98.93 |
|  scratch   | 77.62 | 92.75 | 73.73 | 79.84 |  57.4 | 73.03  |   74.74   |  71.6  | 59.55 |
|   stain    | 89.35 | 81.02 | 72.53 | 73.86 | 86.55 | 90.26  |   89.52   | 91.03  | 85.39 |
| edgeDamage | 71.48 | 98.89 | 74.68 | 84.63 | 91.57 | 58.77  |   57.23   | 94.38  | 38.16 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:15:47,090 - mmseg - INFO - Summary:
2023-11-25 18:15:47,090 - mmseg - INFO - 
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc |  mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.06 | 84.38 | 85.99 | 73.22 | 77.29 | 83.38 |  80.34  |   80.36    |  88.92  | 70.51 |
+-------+-------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:15:47,106 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9906, mIoU: 0.8438, mVOE: 0.8599, mASD: 0.7322, mMSSD: 0.7729, mAcc: 0.8338, mFscore: 0.8034, mPrecision: 0.8036, mRecall: 0.8892, mDice: 0.7051, IoU.background: 0.9906, IoU.scratch: 0.7762, IoU.stain: 0.8935, IoU.edgeDamage: 0.7148, VOE.background: 0.7131, VOE.scratch: 0.9275, VOE.stain: 0.8102, VOE.edgeDamage: 0.9889, ASD.background: 0.7192, ASD.scratch: 0.7373, ASD.stain: 0.7253, ASD.edgeDamage: 0.7468, MSSD.background: 0.7082, MSSD.scratch: 0.7984, MSSD.stain: 0.7386, MSSD.edgeDamage: 0.8463, Acc.background: 0.9799, Acc.scratch: 0.5740, Acc.stain: 0.8655, Acc.edgeDamage: 0.9157, Fscore.background: 0.9929, Fscore.scratch: 0.7303, Fscore.stain: 0.9026, Fscore.edgeDamage: 0.5877, Precision.background: 0.9993, Precision.scratch: 0.7474, Precision.stain: 0.8952, Precision.edgeDamage: 0.5723, Recall.background: 0.9866, Recall.scratch: 0.7160, Recall.stain: 0.9103, Recall.edgeDamage: 0.9438, Dice.background: 0.9893, Dice.scratch: 0.5955, Dice.stain: 0.8539, Dice.edgeDamage: 0.3816
2023-11-25 18:16:03,771 - mmseg - INFO - Iter [2550/5000]	lr: 5.738e-05, eta: 0:14:45, time: 0.768, data_time: 0.490, memory: 7443, decode.loss_focal: 0.0277, decode.loss_dice: 1.0865, decode.acc_seg: 99.6256, loss: 1.1142
2023-11-25 18:16:17,772 - mmseg - INFO - Iter [2600/5000]	lr: 5.651e-05, eta: 0:14:24, time: 0.280, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0269, decode.loss_dice: 1.0997, decode.acc_seg: 99.6115, loss: 1.1266
2023-11-25 18:16:34,468 - mmseg - INFO - Iter [2650/5000]	lr: 5.563e-05, eta: 0:14:04, time: 0.334, data_time: 0.056, memory: 7443, decode.loss_focal: 0.0262, decode.loss_dice: 1.0979, decode.acc_seg: 99.5943, loss: 1.1241
2023-11-25 18:16:48,502 - mmseg - INFO - Iter [2700/5000]	lr: 5.476e-05, eta: 0:13:43, time: 0.281, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0250, decode.loss_dice: 1.0655, decode.acc_seg: 99.6395, loss: 1.0904
2023-11-25 18:17:05,179 - mmseg - INFO - Iter [2750/5000]	lr: 5.388e-05, eta: 0:13:24, time: 0.334, data_time: 0.055, memory: 7443, decode.loss_focal: 0.0244, decode.loss_dice: 1.0923, decode.acc_seg: 99.6080, loss: 1.1167
2023-11-25 18:17:19,288 - mmseg - INFO - Iter [2800/5000]	lr: 5.301e-05, eta: 0:13:03, time: 0.282, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0235, decode.loss_dice: 1.0926, decode.acc_seg: 99.6268, loss: 1.1160
2023-11-25 18:17:36,326 - mmseg - INFO - Iter [2850/5000]	lr: 5.213e-05, eta: 0:12:45, time: 0.341, data_time: 0.063, memory: 7443, decode.loss_focal: 0.0221, decode.loss_dice: 1.0316, decode.acc_seg: 99.6908, loss: 1.0537
2023-11-25 18:17:50,530 - mmseg - INFO - Iter [2900/5000]	lr: 5.124e-05, eta: 0:12:25, time: 0.284, data_time: 0.005, memory: 7443, decode.loss_focal: 0.0219, decode.loss_dice: 1.0729, decode.acc_seg: 99.6225, loss: 1.0949
2023-11-25 18:18:07,333 - mmseg - INFO - Iter [2950/5000]	lr: 5.036e-05, eta: 0:12:06, time: 0.336, data_time: 0.058, memory: 7443, decode.loss_focal: 0.0212, decode.loss_dice: 1.0818, decode.acc_seg: 99.6447, loss: 1.1029
2023-11-25 18:18:21,658 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:18:21,659 - mmseg - INFO - Iter [3000/5000]	lr: 4.947e-05, eta: 0:11:46, time: 0.286, data_time: 0.008, memory: 7443, decode.loss_focal: 0.0209, decode.loss_dice: 1.0442, decode.acc_seg: 99.6211, loss: 1.0651
2023-11-25 18:18:42,679 - mmseg - INFO - per class results:
2023-11-25 18:18:42,680 - mmseg - INFO - 
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
|   Class    |  IoU  |  VOE  |  ASD  |  MSSD |  Acc  | Fscore | Precision | Recall |  Dice |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
| background | 99.08 | 71.29 | 71.92 | 70.81 | 98.03 |  99.3  |   99.94   | 98.68  | 98.95 |
|  scratch   | 78.68 | 91.69 | 73.55 | 78.95 | 61.38 | 75.02  |   75.85   | 74.26  | 62.53 |
|   stain    | 89.17 |  81.2 |  72.6 | 74.18 | 87.56 | 90.06  |   88.56   |  91.7  | 85.09 |
| edgeDamage | 71.48 | 98.89 | 74.68 | 84.63 | 90.06 | 58.76  |   57.23   | 93.37  | 38.14 |
+------------+-------+-------+-------+-------+-------+--------+-----------+--------+-------+
2023-11-25 18:18:42,681 - mmseg - INFO - Summary:
2023-11-25 18:18:42,681 - mmseg - INFO - 
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
|  aAcc | mIoU |  mVOE |  mASD | mMSSD |  mAcc | mFscore | mPrecision | mRecall | mDice |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
| 99.08 | 84.6 | 85.77 | 73.19 | 77.14 | 84.26 |  80.79  |   80.39    |   89.5  | 71.18 |
+-------+------+-------+-------+-------+-------+---------+------------+---------+-------+
2023-11-25 18:18:42,696 - mmseg - INFO - Exp name: transunet.py
2023-11-25 18:18:42,696 - mmseg - INFO - Iter(val) [105]	aAcc: 0.9908, mIoU: 0.8460, mVOE: 0.8577, mASD: 0.7319, mMSSD: 0.7714, mAcc: 0.8426, mFscore: 0.8079, mPrecision: 0.8039, mRecall: 0.8950, mDice: 0.7118, IoU.background: 0.9908, IoU.scratch: 0.7868, IoU.stain: 0.8917, IoU.edgeDamage: 0.7148, VOE.background: 0.7129, VOE.scratch: 0.9169, VOE.stain: 0.8120, VOE.edgeDamage: 0.9889, ASD.background: 0.7192, ASD.scratch: 0.7355, ASD.stain: 0.7260, ASD.edgeDamage: 0.7468, MSSD.background: 0.7081, MSSD.scratch: 0.7895, MSSD.stain: 0.7418, MSSD.edgeDamage: 0.8463, Acc.background: 0.9803, Acc.scratch: 0.6138, Acc.stain: 0.8756, Acc.edgeDamage: 0.9006, Fscore.background: 0.9930, Fscore.scratch: 0.7502, Fscore.stain: 0.9006, Fscore.edgeDamage: 0.5876, Precision.background: 0.9994, Precision.scratch: 0.7585, Precision.stain: 0.8856, Precision.edgeDamage: 0.5723, Recall.background: 0.9868, Recall.scratch: 0.7426, Recall.stain: 0.9170, Recall.edgeDamage: 0.9337, Dice.background: 0.9895, Dice.scratch: 0.6253, Dice.stain: 0.8509, Dice.edgeDamage: 0.3814
2023-11-25 18:18:59,803 - mmseg - INFO - Iter [3050/5000]	lr: 4.858e-05, eta: 0:11:42, time: 0.763, data_time: 0.486, memory: 7443, decode.loss_focal: 0.0200, decode.loss_dice: 1.0314, decode.acc_seg: 99.6581, loss: 1.0514
2023-11-25 18:19:14,767 - mmseg - INFO - Iter [3100/5000]	lr: 4.769e-05, eta: 0:11:22, time: 0.299, data_time: 0.022, memory: 7443, decode.loss_focal: 0.0196, decode.loss_dice: 1.0432, decode.acc_seg: 99.6531, loss: 1.0627
2023-11-25 18:19:31,822 - mmseg - INFO - Iter [3150/5000]	lr: 4.680e-05, eta: 0:11:03, time: 0.341, data_time: 0.062, memory: 7443, decode.loss_focal: 0.0188, decode.loss_dice: 1.0538, decode.acc_seg: 99.6637, loss: 1.0726
2023-11-25 18:19:48,589 - mmseg - INFO - Iter [3200/5000]	lr: 4.590e-05, eta: 0:10:45, time: 0.335, data_time: 0.058, memory: 7443, decode.loss_focal: 0.0184, decode.loss_dice: 1.0241, decode.acc_seg: 99.6509, loss: 1.0425
2023-11-25 18:20:02,740 - mmseg - INFO - Iter [3250/5000]	lr: 4.500e-05, eta: 0:10:25, time: 0.283, data_time: 0.005, memory: 7443, decode.loss_focal: 0.0178, decode.loss_dice: 1.0282, decode.acc_seg: 99.6601, loss: 1.0460
2023-11-25 18:20:19,362 - mmseg - INFO - Iter [3300/5000]	lr: 4.410e-05, eta: 0:10:06, time: 0.332, data_time: 0.055, memory: 7443, decode.loss_focal: 0.0174, decode.loss_dice: 1.0521, decode.acc_seg: 99.6646, loss: 1.0695
2023-11-25 18:20:33,444 - mmseg - INFO - Iter [3350/5000]	lr: 4.320e-05, eta: 0:09:46, time: 0.282, data_time: 0.004, memory: 7443, decode.loss_focal: 0.0170, decode.loss_dice: 1.0191, decode.acc_seg: 99.6632, loss: 1.0361
2023-11-25 18:20:50,076 - mmseg - INFO - Iter [3400/5000]	lr: 4.229e-05, eta: 0:09:28, time: 0.333, data_time: 0.055, memory: 7443, decode.loss_focal: 0.0167, decode.loss_dice: 1.0309, decode.acc_seg: 99.6621, loss: 1.0476
2023-11-25 18:21:04,228 - mmseg - INFO - Iter [3450/5000]	lr: 4.138e-05, eta: 0:09:09, time: 0.283, data_time: 0.005, memory: 7443, decode.loss_focal: 0.0163, decode.loss_dice: 1.0260, decode.acc_seg: 99.6480, loss: 1.0423
2023-11-25 18:21:21,071 - mmseg - INFO - Iter [3500/5000]	lr: 4.047e-05, eta: 0:08:51, time: 0.337, data_time: 0.059, memory: 7443, decode.loss_focal: 0.0158, decode.loss_dice: 1.0100, decode.acc_seg: 99.6729, loss: 1.0258
